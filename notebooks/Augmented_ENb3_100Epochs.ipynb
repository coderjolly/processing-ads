{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train for 50 epochs. First use only fine tuning on last layer\n",
    "## Then compare with fine-tuning entire network\n",
    "## TODO: \n",
    "## 0. Pre-process images\n",
    "##      Resize images\n",
    "##      Other pre-processing\n",
    "## 0.1. Check image colors\n",
    "## 1. Get mean and std of dataset - done\n",
    "## 2. Train on Resnet-34\n",
    "## 3. Train on efficient net b3 - done\n",
    "## 4. Train on mobilenet v3 large\n",
    "## 5. Write a script to plot loss + accuracy graph\n",
    "## 6. Get FLOPs\n",
    "## 7. Get num layers\n",
    "## 8. Add class weights - done\n",
    "## 9. Implement gradcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from multilabel.train import train_model\n",
    "from model import initialize_model\n",
    "from utils import set_requires_grad, save_model\n",
    "from multilabel.data import load_data\n",
    "from plotting import plot_data_loader\n",
    "from multilabel.eval import eval_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "0w24yf-Tj47H"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import time\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "from numpy.random import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.io import read_image\n",
    "import torchvision.transforms as T\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, models, transforms\n",
    "import torch.autograd.profiler as tprofiler\n",
    "import torch.utils.data as td\n",
    "\n",
    "plt.rcParams[\"savefig.bbox\"] = 'tight'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "O7W8BTtF3BN1"
   },
   "outputs": [],
   "source": [
    "seed = 42\n",
    "\n",
    "random.seed(seed)\n",
    "\n",
    "# pytorch RNGs\n",
    "torch.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "if torch.cuda.is_available(): torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "# numpy RNG\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "21_bts2Wj47M",
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_dir = \"../data\"\n",
    "images_dir = \"../data/processed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "nr7fQfkuj47u"
   },
   "outputs": [],
   "source": [
    "# Get best num_workers\n",
    "# for i in range(97):\n",
    "#     start = time.time()\n",
    "#     data_loader = load_data(images_dir,\n",
    "#                                                                    batch_size = 96, \n",
    "#                                                                    input_size = 299, \n",
    "#                                                                    norm_arr = ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "#                                                                    num_workers = i)\n",
    "#     iter(data_loader['train']).next()[0].shape\n",
    "#     print(f\"{i}: {time.time()-start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "96wB0P9Gj47u"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k-vpcOXE1pmg",
    "outputId": "25752964-a425-490c-d154-0cc8baab3b61"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Check if GPU is available.\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "# Models options: resnet50, resnet34, inceptionv3, vgg16, mobile_net_v3_large, efficient_net_b1, efficient_net_b0, efficient_net_b3.\n",
    "model_name = \"efficient_net_b3\"\n",
    "\n",
    "# Number of classes.\n",
    "num_classes = 20\n",
    "\n",
    "# Batch Size.\n",
    "batch_size = 32\n",
    "\n",
    "# Epochs to train for.\n",
    "num_epochs = 100\n",
    "\n",
    "# Number of workers for data loader.\n",
    "num_workers = 12\n",
    "\n",
    "# Imagenet norm array passed as default value.\n",
    "# norm_arr=([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "# Chest x-ray8 training dataset metrics \n",
    "norm_arr=((0.5989, 0.5510, 0.5175), (0.3358, 0.3330, 0.3377))\n",
    "\n",
    "# Feature extract flag: False - Tune the whole model,\n",
    "#                       True - Update only the reshaped layer parameters.\n",
    "feature_extract = True\n",
    "\n",
    "# Use pretrained flag: None - Use random weights\n",
    "#                      String - Use pretrained weights given by String\n",
    "use_pretrained = models.EfficientNet_B3_Weights.IMAGENET1K_V1\n",
    "\n",
    "# Initialize the model for this run.\n",
    "model_pyt, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=use_pretrained)\n",
    "\n",
    "# lr start and end points for training.\n",
    "lr_start = 0.01\n",
    "lr_end = 0.001\n",
    "\n",
    "# Print the model we just instantiated\n",
    "#print(model_ft)\n",
    "\n",
    "# Positive class weights.\n",
    "pos_weight=torch.as_tensor([ 2.3509,  6.4782, 76.3264, 23.6350, 46.7897, 18.5694, 14.4224, 24.4805,\n",
    "         1.1795,  0.6394,  9.1227, 80.2774,  0.8743,  2.1217,  7.2973, 87.3730,\n",
    "        12.8151, 23.7444, 28.1492, 29.6749], dtype=torch.float)\n",
    "pos_weight = pos_weight.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "e9FOwaso3LAc"
   },
   "outputs": [],
   "source": [
    "data_loaders = load_data(images_dir,\n",
    "                         batch_size = batch_size, \n",
    "                         input_size = input_size, \n",
    "                         norm_arr = norm_arr,\n",
    "                         num_workers = num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Active',\n",
       " 'Alert',\n",
       " 'Amazed',\n",
       " 'Amused',\n",
       " 'Calm',\n",
       " 'Cheerful',\n",
       " 'Confident',\n",
       " 'Conscious',\n",
       " 'Creative',\n",
       " 'Eager',\n",
       " 'Educated',\n",
       " 'Emotional',\n",
       " 'Fashionable',\n",
       " 'Feminine',\n",
       " 'Inspired',\n",
       " 'Loving',\n",
       " 'Manly',\n",
       " 'Persuaded',\n",
       " 'Thrifty',\n",
       " 'Youthful']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_loaders['train'].dataset.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_data_loader(data_loaders['train'], (2,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 392
    },
    "id": "vacZgHSCj47u",
    "outputId": "35a65cef-1d6d-4657-ff01-be15854ca24b"
   },
   "source": [
    "plot_data_loader(data_loader['train'], (2,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zRIOYWbV1cnS"
   },
   "source": [
    "plot_data_loader(data_loader['test'], (2,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "znBg5tkd1dXF"
   },
   "source": [
    "plot_data_loader(data_loader['val'], (2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "0rj7Qeg41wLm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params to learn:\n",
      "\t classifier.1.weight\n",
      "\t classifier.1.bias\n"
     ]
    }
   ],
   "source": [
    "#model_pyt = torch.compile(model_pyt)\n",
    "# Send model to GPU\n",
    "model_pyt = model_pyt.to(device)\n",
    "\n",
    "# Find parameters to be updated in this run.\n",
    "# parameters with requires_grad = True.\n",
    "params_to_update = model_pyt.parameters()\n",
    "print(\"Params to learn:\")\n",
    "if feature_extract:\n",
    "    params_to_update = []\n",
    "    for name,param in model_pyt.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            params_to_update.append(param)\n",
    "            print(\"\\t\",name)\n",
    "else:\n",
    "    for name,param in model_pyt.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            print(\"\\t\",name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "A4B1-pfYm0Ea"
   },
   "outputs": [],
   "source": [
    "# 17 min 1 epoch - 128 batch size - inception\n",
    "# Efficientnet b0 - batch 96 - epoch 50 - num_workers 2 - flip, auto cont, sharp - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8wBR8vcG2jcd",
    "outputId": "7d01aa07-d235-4cb6-dfaf-53ce0c5a577d",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "----------\n",
      "Epoch [1/100], Step [100/348], Loss: 0.7131, Accuracy: 82.66%\n",
      "Epoch [1/100], Step [200/348], Loss: 0.8750, Accuracy: 86.09%\n",
      "Epoch [1/100], Step [300/348], Loss: 0.7201, Accuracy: 84.69%\n",
      "train Loss: 0.9789 Acc: 83.75%\n",
      "Epoch [1/100], Step [100/348], Loss: 0.6116, Accuracy: 85.62%\n",
      "val Loss: 0.8557 Acc: 83.78%\n",
      "\n",
      "Epoch 2/100\n",
      "----------\n",
      "Epoch [2/100], Step [100/348], Loss: 0.5555, Accuracy: 82.03%\n",
      "Epoch [2/100], Step [200/348], Loss: 0.9404, Accuracy: 83.28%\n",
      "Epoch [2/100], Step [300/348], Loss: 0.7771, Accuracy: 82.97%\n",
      "train Loss: 0.9105 Acc: 83.14%\n",
      "Epoch [2/100], Step [100/348], Loss: 0.7027, Accuracy: 85.00%\n",
      "val Loss: 0.9111 Acc: 83.12%\n",
      "\n",
      "Epoch 3/100\n",
      "----------\n",
      "Epoch [3/100], Step [100/348], Loss: 0.5566, Accuracy: 84.38%\n",
      "Epoch [3/100], Step [200/348], Loss: 0.8562, Accuracy: 82.66%\n",
      "Epoch [3/100], Step [300/348], Loss: 0.7294, Accuracy: 79.84%\n",
      "train Loss: 0.9231 Acc: 82.58%\n",
      "Epoch [3/100], Step [100/348], Loss: 0.6095, Accuracy: 85.62%\n",
      "val Loss: 0.9140 Acc: 83.17%\n",
      "\n",
      "Epoch 4/100\n",
      "----------\n",
      "Epoch [4/100], Step [100/348], Loss: 1.0988, Accuracy: 80.62%\n",
      "Epoch [4/100], Step [200/348], Loss: 0.6357, Accuracy: 86.88%\n",
      "Epoch [4/100], Step [300/348], Loss: 0.8765, Accuracy: 84.69%\n",
      "train Loss: 0.9233 Acc: 83.01%\n",
      "Epoch [4/100], Step [100/348], Loss: 0.6121, Accuracy: 84.84%\n",
      "val Loss: 0.9260 Acc: 82.43%\n",
      "\n",
      "Epoch 5/100\n",
      "----------\n",
      "Epoch [5/100], Step [100/348], Loss: 0.9758, Accuracy: 87.81%\n",
      "Epoch [5/100], Step [200/348], Loss: 0.7077, Accuracy: 82.50%\n",
      "Epoch [5/100], Step [300/348], Loss: 1.0322, Accuracy: 81.09%\n",
      "train Loss: 0.9230 Acc: 83.09%\n",
      "Epoch [5/100], Step [100/348], Loss: 0.5911, Accuracy: 85.16%\n",
      "val Loss: 0.9521 Acc: 84.12%\n",
      "\n",
      "Epoch 6/100\n",
      "----------\n",
      "Epoch [6/100], Step [100/348], Loss: 0.5049, Accuracy: 83.28%\n",
      "Epoch [6/100], Step [200/348], Loss: 0.7588, Accuracy: 84.38%\n",
      "Epoch [6/100], Step [300/348], Loss: 0.9565, Accuracy: 84.22%\n",
      "train Loss: 0.9568 Acc: 82.76%\n",
      "Epoch [6/100], Step [100/348], Loss: 0.6656, Accuracy: 88.12%\n",
      "val Loss: 1.0217 Acc: 85.18%\n",
      "\n",
      "Epoch 7/100\n",
      "----------\n",
      "Epoch [7/100], Step [100/348], Loss: 0.6911, Accuracy: 84.22%\n",
      "Epoch [7/100], Step [200/348], Loss: 1.1592, Accuracy: 82.50%\n",
      "Epoch [7/100], Step [300/348], Loss: 0.6950, Accuracy: 81.41%\n",
      "train Loss: 0.9276 Acc: 83.12%\n",
      "Epoch [7/100], Step [100/348], Loss: 0.6628, Accuracy: 84.84%\n",
      "val Loss: 1.0304 Acc: 83.91%\n",
      "\n",
      "Epoch 8/100\n",
      "----------\n",
      "Epoch [8/100], Step [100/348], Loss: 0.9907, Accuracy: 81.56%\n",
      "Epoch [8/100], Step [200/348], Loss: 0.7922, Accuracy: 82.34%\n",
      "Epoch [8/100], Step [300/348], Loss: 0.6787, Accuracy: 85.16%\n",
      "train Loss: 0.9632 Acc: 82.99%\n",
      "Epoch [8/100], Step [100/348], Loss: 0.7130, Accuracy: 86.88%\n",
      "val Loss: 1.0367 Acc: 85.28%\n",
      "\n",
      "Epoch 9/100\n",
      "----------\n",
      "Epoch [9/100], Step [100/348], Loss: 0.8260, Accuracy: 79.38%\n",
      "Epoch [9/100], Step [200/348], Loss: 1.4160, Accuracy: 84.84%\n",
      "Epoch [9/100], Step [300/348], Loss: 0.9239, Accuracy: 77.97%\n",
      "train Loss: 0.9462 Acc: 83.19%\n",
      "Epoch [9/100], Step [100/348], Loss: 0.7081, Accuracy: 85.16%\n",
      "val Loss: 1.0118 Acc: 83.72%\n",
      "\n",
      "Epoch 10/100\n",
      "----------\n",
      "Epoch [10/100], Step [100/348], Loss: 1.6778, Accuracy: 82.50%\n",
      "Epoch [10/100], Step [200/348], Loss: 0.6987, Accuracy: 82.19%\n",
      "Epoch [10/100], Step [300/348], Loss: 0.9214, Accuracy: 81.72%\n",
      "train Loss: 0.9497 Acc: 83.12%\n",
      "Epoch [10/100], Step [100/348], Loss: 0.7215, Accuracy: 86.25%\n",
      "val Loss: 1.1822 Acc: 85.16%\n",
      "\n",
      "Epoch 11/100\n",
      "----------\n",
      "Epoch [11/100], Step [100/348], Loss: 0.7378, Accuracy: 82.03%\n",
      "Epoch [11/100], Step [200/348], Loss: 0.9317, Accuracy: 86.09%\n",
      "Epoch [11/100], Step [300/348], Loss: 1.1712, Accuracy: 81.41%\n",
      "train Loss: 0.9798 Acc: 83.10%\n",
      "Epoch [11/100], Step [100/348], Loss: 0.6918, Accuracy: 85.16%\n",
      "val Loss: 1.1487 Acc: 83.01%\n",
      "\n",
      "Epoch 12/100\n",
      "----------\n",
      "Epoch [12/100], Step [100/348], Loss: 0.8565, Accuracy: 82.50%\n",
      "Epoch [12/100], Step [200/348], Loss: 0.8304, Accuracy: 82.03%\n",
      "Epoch [12/100], Step [300/348], Loss: 1.9705, Accuracy: 85.00%\n",
      "train Loss: 0.9812 Acc: 83.05%\n",
      "Epoch [12/100], Step [100/348], Loss: 0.6450, Accuracy: 86.09%\n",
      "val Loss: 1.0828 Acc: 84.96%\n",
      "\n",
      "Epoch 13/100\n",
      "----------\n",
      "Epoch [13/100], Step [100/348], Loss: 0.7731, Accuracy: 84.38%\n",
      "Epoch [13/100], Step [200/348], Loss: 1.1648, Accuracy: 80.62%\n",
      "Epoch [13/100], Step [300/348], Loss: 0.6500, Accuracy: 85.94%\n",
      "train Loss: 0.9613 Acc: 83.08%\n",
      "Epoch [13/100], Step [100/348], Loss: 0.6066, Accuracy: 88.12%\n",
      "val Loss: 1.1395 Acc: 85.52%\n",
      "\n",
      "Epoch 14/100\n",
      "----------\n",
      "Epoch [14/100], Step [100/348], Loss: 0.7149, Accuracy: 86.41%\n",
      "Epoch [14/100], Step [200/348], Loss: 0.7707, Accuracy: 80.78%\n",
      "Epoch [14/100], Step [300/348], Loss: 0.7320, Accuracy: 82.81%\n",
      "train Loss: 0.9696 Acc: 83.18%\n",
      "Epoch [14/100], Step [100/348], Loss: 0.5123, Accuracy: 86.56%\n",
      "val Loss: 1.1128 Acc: 83.93%\n",
      "\n",
      "Epoch 15/100\n",
      "----------\n",
      "Epoch [15/100], Step [100/348], Loss: 1.6199, Accuracy: 81.88%\n",
      "Epoch [15/100], Step [200/348], Loss: 0.8528, Accuracy: 82.66%\n",
      "Epoch [15/100], Step [300/348], Loss: 1.2257, Accuracy: 80.47%\n",
      "train Loss: 0.9762 Acc: 83.00%\n",
      "Epoch [15/100], Step [100/348], Loss: 0.6587, Accuracy: 88.28%\n",
      "val Loss: 1.1574 Acc: 85.72%\n",
      "\n",
      "Epoch 16/100\n",
      "----------\n",
      "Epoch [16/100], Step [100/348], Loss: 0.9555, Accuracy: 84.38%\n",
      "Epoch [16/100], Step [200/348], Loss: 0.8957, Accuracy: 84.69%\n",
      "Epoch [16/100], Step [300/348], Loss: 1.1767, Accuracy: 81.56%\n",
      "train Loss: 0.9519 Acc: 83.52%\n",
      "Epoch [16/100], Step [100/348], Loss: 0.5073, Accuracy: 89.22%\n",
      "val Loss: 1.1249 Acc: 86.92%\n",
      "\n",
      "Epoch 17/100\n",
      "----------\n",
      "Epoch [17/100], Step [100/348], Loss: 0.8084, Accuracy: 84.69%\n",
      "Epoch [17/100], Step [200/348], Loss: 0.6508, Accuracy: 84.22%\n",
      "Epoch [17/100], Step [300/348], Loss: 0.6517, Accuracy: 84.69%\n",
      "train Loss: 0.9904 Acc: 83.19%\n",
      "Epoch [17/100], Step [100/348], Loss: 0.5408, Accuracy: 87.81%\n",
      "val Loss: 1.0556 Acc: 85.46%\n",
      "\n",
      "Epoch 18/100\n",
      "----------\n",
      "Epoch [18/100], Step [100/348], Loss: 1.4478, Accuracy: 84.84%\n",
      "Epoch [18/100], Step [200/348], Loss: 0.6431, Accuracy: 82.66%\n",
      "Epoch [18/100], Step [300/348], Loss: 1.0147, Accuracy: 80.16%\n",
      "train Loss: 0.9704 Acc: 83.34%\n",
      "Epoch [18/100], Step [100/348], Loss: 0.7166, Accuracy: 88.28%\n",
      "val Loss: 1.1148 Acc: 85.51%\n",
      "\n",
      "Epoch 19/100\n",
      "----------\n",
      "Epoch [19/100], Step [100/348], Loss: 0.7598, Accuracy: 80.94%\n",
      "Epoch [19/100], Step [200/348], Loss: 1.0833, Accuracy: 83.59%\n",
      "Epoch [19/100], Step [300/348], Loss: 1.4003, Accuracy: 80.47%\n",
      "train Loss: 0.9614 Acc: 83.33%\n",
      "Epoch [19/100], Step [100/348], Loss: 0.6540, Accuracy: 86.41%\n",
      "val Loss: 1.1700 Acc: 85.54%\n",
      "\n",
      "Epoch 20/100\n",
      "----------\n",
      "Epoch [20/100], Step [100/348], Loss: 1.0586, Accuracy: 82.34%\n",
      "Epoch [20/100], Step [200/348], Loss: 0.9851, Accuracy: 81.56%\n",
      "Epoch [20/100], Step [300/348], Loss: 0.5521, Accuracy: 86.72%\n",
      "train Loss: 0.9552 Acc: 83.41%\n",
      "Epoch [20/100], Step [100/348], Loss: 0.5862, Accuracy: 84.38%\n",
      "val Loss: 1.0905 Acc: 85.66%\n",
      "\n",
      "Epoch 21/100\n",
      "----------\n",
      "Epoch [21/100], Step [100/348], Loss: 1.2859, Accuracy: 81.88%\n",
      "Epoch [21/100], Step [200/348], Loss: 1.2642, Accuracy: 81.72%\n",
      "Epoch [21/100], Step [300/348], Loss: 1.0791, Accuracy: 84.38%\n",
      "train Loss: 0.9699 Acc: 83.42%\n",
      "Epoch [21/100], Step [100/348], Loss: 0.6769, Accuracy: 87.50%\n",
      "val Loss: 1.0812 Acc: 84.93%\n",
      "\n",
      "Epoch 22/100\n",
      "----------\n",
      "Epoch [22/100], Step [100/348], Loss: 1.1961, Accuracy: 83.28%\n",
      "Epoch [22/100], Step [200/348], Loss: 1.1380, Accuracy: 86.25%\n",
      "Epoch [22/100], Step [300/348], Loss: 1.1531, Accuracy: 84.06%\n",
      "train Loss: 0.9540 Acc: 83.43%\n",
      "Epoch [22/100], Step [100/348], Loss: 0.6802, Accuracy: 88.75%\n",
      "val Loss: 1.1455 Acc: 85.87%\n",
      "\n",
      "Epoch 23/100\n",
      "----------\n",
      "Epoch [23/100], Step [100/348], Loss: 1.0000, Accuracy: 85.62%\n",
      "Epoch [23/100], Step [200/348], Loss: 1.0195, Accuracy: 80.00%\n",
      "Epoch [23/100], Step [300/348], Loss: 1.3676, Accuracy: 81.09%\n",
      "train Loss: 0.9455 Acc: 83.70%\n",
      "Epoch [23/100], Step [100/348], Loss: 0.6318, Accuracy: 86.56%\n",
      "val Loss: 1.1218 Acc: 85.19%\n",
      "\n",
      "Epoch 24/100\n",
      "----------\n",
      "Epoch [24/100], Step [100/348], Loss: 0.9080, Accuracy: 79.84%\n",
      "Epoch [24/100], Step [200/348], Loss: 0.6905, Accuracy: 84.06%\n",
      "Epoch [24/100], Step [300/348], Loss: 1.8990, Accuracy: 85.31%\n",
      "train Loss: 0.9726 Acc: 83.45%\n",
      "Epoch [24/100], Step [100/348], Loss: 0.7948, Accuracy: 84.22%\n",
      "val Loss: 1.1109 Acc: 84.38%\n",
      "\n",
      "Epoch 25/100\n",
      "----------\n",
      "Epoch [25/100], Step [100/348], Loss: 0.8010, Accuracy: 84.53%\n",
      "Epoch [25/100], Step [200/348], Loss: 0.6744, Accuracy: 85.00%\n",
      "Epoch [25/100], Step [300/348], Loss: 0.8222, Accuracy: 85.47%\n",
      "train Loss: 0.9277 Acc: 83.73%\n",
      "Epoch [25/100], Step [100/348], Loss: 0.7117, Accuracy: 86.88%\n",
      "val Loss: 1.1990 Acc: 86.02%\n",
      "\n",
      "Epoch 26/100\n",
      "----------\n",
      "Epoch [26/100], Step [100/348], Loss: 0.9950, Accuracy: 82.03%\n",
      "Epoch [26/100], Step [200/348], Loss: 0.5941, Accuracy: 86.56%\n",
      "Epoch [26/100], Step [300/348], Loss: 0.8687, Accuracy: 81.72%\n",
      "train Loss: 0.9572 Acc: 83.61%\n",
      "Epoch [26/100], Step [100/348], Loss: 0.6634, Accuracy: 89.38%\n",
      "val Loss: 1.2329 Acc: 87.28%\n",
      "\n",
      "Epoch 27/100\n",
      "----------\n",
      "Epoch [27/100], Step [100/348], Loss: 1.5838, Accuracy: 85.31%\n",
      "Epoch [27/100], Step [200/348], Loss: 1.2647, Accuracy: 84.53%\n",
      "Epoch [27/100], Step [300/348], Loss: 0.7945, Accuracy: 82.97%\n",
      "train Loss: 0.9310 Acc: 83.79%\n",
      "Epoch [27/100], Step [100/348], Loss: 0.6300, Accuracy: 86.72%\n",
      "val Loss: 1.0686 Acc: 84.43%\n",
      "\n",
      "Epoch 28/100\n",
      "----------\n",
      "Epoch [28/100], Step [100/348], Loss: 1.0044, Accuracy: 83.59%\n",
      "Epoch [28/100], Step [200/348], Loss: 0.5922, Accuracy: 83.28%\n",
      "Epoch [28/100], Step [300/348], Loss: 0.9665, Accuracy: 82.81%\n",
      "train Loss: 0.9494 Acc: 83.68%\n",
      "Epoch [28/100], Step [100/348], Loss: 0.8815, Accuracy: 87.19%\n",
      "val Loss: 1.1770 Acc: 85.31%\n",
      "\n",
      "Epoch 29/100\n",
      "----------\n",
      "Epoch [29/100], Step [100/348], Loss: 0.6335, Accuracy: 85.78%\n",
      "Epoch [29/100], Step [200/348], Loss: 1.8014, Accuracy: 84.53%\n",
      "Epoch [29/100], Step [300/348], Loss: 0.9935, Accuracy: 82.03%\n",
      "train Loss: 0.9613 Acc: 83.59%\n",
      "Epoch [29/100], Step [100/348], Loss: 0.7760, Accuracy: 87.81%\n",
      "val Loss: 1.1852 Acc: 85.11%\n",
      "\n",
      "Epoch 30/100\n",
      "----------\n",
      "Epoch [30/100], Step [100/348], Loss: 0.7836, Accuracy: 85.94%\n",
      "Epoch [30/100], Step [200/348], Loss: 1.4777, Accuracy: 85.78%\n",
      "Epoch [30/100], Step [300/348], Loss: 0.7502, Accuracy: 84.22%\n",
      "train Loss: 0.9239 Acc: 84.16%\n",
      "Epoch [30/100], Step [100/348], Loss: 0.7425, Accuracy: 86.72%\n",
      "val Loss: 1.1289 Acc: 85.01%\n",
      "\n",
      "Epoch 31/100\n",
      "----------\n",
      "Epoch [31/100], Step [100/348], Loss: 0.8869, Accuracy: 85.62%\n",
      "Epoch [31/100], Step [200/348], Loss: 0.6668, Accuracy: 83.28%\n",
      "Epoch [31/100], Step [300/348], Loss: 2.0031, Accuracy: 82.81%\n",
      "train Loss: 0.9232 Acc: 83.89%\n",
      "Epoch [31/100], Step [100/348], Loss: 0.6484, Accuracy: 87.50%\n",
      "val Loss: 1.1262 Acc: 86.34%\n",
      "\n",
      "Epoch 32/100\n",
      "----------\n",
      "Epoch [32/100], Step [100/348], Loss: 0.7634, Accuracy: 82.97%\n",
      "Epoch [32/100], Step [200/348], Loss: 0.7679, Accuracy: 86.09%\n",
      "Epoch [32/100], Step [300/348], Loss: 0.8977, Accuracy: 84.06%\n",
      "train Loss: 0.9451 Acc: 83.80%\n",
      "Epoch [32/100], Step [100/348], Loss: 0.7246, Accuracy: 88.28%\n",
      "val Loss: 1.1826 Acc: 87.32%\n",
      "\n",
      "Epoch 33/100\n",
      "----------\n",
      "Epoch [33/100], Step [100/348], Loss: 0.6380, Accuracy: 84.69%\n",
      "Epoch [33/100], Step [200/348], Loss: 0.7988, Accuracy: 81.09%\n",
      "Epoch [33/100], Step [300/348], Loss: 1.1597, Accuracy: 80.94%\n",
      "train Loss: 0.9183 Acc: 84.02%\n",
      "Epoch [33/100], Step [100/348], Loss: 0.5403, Accuracy: 88.28%\n",
      "val Loss: 1.1076 Acc: 86.94%\n",
      "\n",
      "Epoch 34/100\n",
      "----------\n",
      "Epoch [34/100], Step [100/348], Loss: 0.6345, Accuracy: 86.56%\n",
      "Epoch [34/100], Step [200/348], Loss: 0.7962, Accuracy: 84.22%\n",
      "Epoch [34/100], Step [300/348], Loss: 0.6094, Accuracy: 86.09%\n",
      "train Loss: 0.9033 Acc: 84.22%\n",
      "Epoch [34/100], Step [100/348], Loss: 0.6434, Accuracy: 88.91%\n",
      "val Loss: 1.1871 Acc: 87.69%\n",
      "\n",
      "Epoch 35/100\n",
      "----------\n",
      "Epoch [35/100], Step [100/348], Loss: 0.6770, Accuracy: 82.81%\n",
      "Epoch [35/100], Step [200/348], Loss: 1.0792, Accuracy: 86.09%\n",
      "Epoch [35/100], Step [300/348], Loss: 0.9844, Accuracy: 81.88%\n",
      "train Loss: 0.8756 Acc: 84.71%\n",
      "Epoch [35/100], Step [100/348], Loss: 0.6023, Accuracy: 87.97%\n",
      "val Loss: 1.0926 Acc: 85.63%\n",
      "\n",
      "Epoch 36/100\n",
      "----------\n",
      "Epoch [36/100], Step [100/348], Loss: 2.1088, Accuracy: 84.69%\n",
      "Epoch [36/100], Step [200/348], Loss: 0.7250, Accuracy: 85.00%\n",
      "Epoch [36/100], Step [300/348], Loss: 0.5455, Accuracy: 86.56%\n",
      "train Loss: 0.9002 Acc: 84.56%\n",
      "Epoch [36/100], Step [100/348], Loss: 0.5107, Accuracy: 89.38%\n",
      "val Loss: 1.2032 Acc: 87.10%\n",
      "\n",
      "Epoch 37/100\n",
      "----------\n",
      "Epoch [37/100], Step [100/348], Loss: 0.5838, Accuracy: 84.53%\n",
      "Epoch [37/100], Step [200/348], Loss: 1.1166, Accuracy: 85.16%\n",
      "Epoch [37/100], Step [300/348], Loss: 0.7491, Accuracy: 84.69%\n",
      "train Loss: 0.8940 Acc: 84.38%\n",
      "Epoch [37/100], Step [100/348], Loss: 0.5101, Accuracy: 88.44%\n",
      "val Loss: 1.1211 Acc: 86.75%\n",
      "\n",
      "Epoch 38/100\n",
      "----------\n",
      "Epoch [38/100], Step [100/348], Loss: 0.7198, Accuracy: 85.62%\n",
      "Epoch [38/100], Step [200/348], Loss: 1.4451, Accuracy: 83.91%\n",
      "Epoch [38/100], Step [300/348], Loss: 0.5841, Accuracy: 85.78%\n",
      "train Loss: 0.8915 Acc: 84.32%\n",
      "Epoch [38/100], Step [100/348], Loss: 0.5208, Accuracy: 87.66%\n",
      "val Loss: 1.1725 Acc: 86.89%\n",
      "\n",
      "Epoch 39/100\n",
      "----------\n",
      "Epoch [39/100], Step [100/348], Loss: 0.6935, Accuracy: 85.62%\n",
      "Epoch [39/100], Step [200/348], Loss: 0.7996, Accuracy: 83.28%\n",
      "Epoch [39/100], Step [300/348], Loss: 0.9480, Accuracy: 85.00%\n",
      "train Loss: 0.8735 Acc: 84.70%\n",
      "Epoch [39/100], Step [100/348], Loss: 0.6035, Accuracy: 89.69%\n",
      "val Loss: 1.1354 Acc: 87.91%\n",
      "\n",
      "Epoch 40/100\n",
      "----------\n",
      "Epoch [40/100], Step [100/348], Loss: 0.6255, Accuracy: 87.66%\n",
      "Epoch [40/100], Step [200/348], Loss: 1.8115, Accuracy: 83.91%\n",
      "Epoch [40/100], Step [300/348], Loss: 0.6286, Accuracy: 84.06%\n",
      "train Loss: 0.8809 Acc: 84.53%\n",
      "Epoch [40/100], Step [100/348], Loss: 0.5732, Accuracy: 88.44%\n",
      "val Loss: 1.1501 Acc: 87.84%\n",
      "\n",
      "Epoch 41/100\n",
      "----------\n",
      "Epoch [41/100], Step [100/348], Loss: 0.6785, Accuracy: 82.19%\n",
      "Epoch [41/100], Step [200/348], Loss: 0.7604, Accuracy: 86.88%\n",
      "Epoch [41/100], Step [300/348], Loss: 0.6668, Accuracy: 85.31%\n",
      "train Loss: 0.8703 Acc: 84.62%\n",
      "Epoch [41/100], Step [100/348], Loss: 0.5414, Accuracy: 87.97%\n",
      "val Loss: 1.1644 Acc: 87.88%\n",
      "\n",
      "Epoch 42/100\n",
      "----------\n",
      "Epoch [42/100], Step [100/348], Loss: 0.9386, Accuracy: 84.69%\n",
      "Epoch [42/100], Step [200/348], Loss: 0.9992, Accuracy: 87.50%\n",
      "Epoch [42/100], Step [300/348], Loss: 0.9715, Accuracy: 86.56%\n",
      "train Loss: 0.8364 Acc: 85.07%\n",
      "Epoch [42/100], Step [100/348], Loss: 0.6239, Accuracy: 89.06%\n",
      "val Loss: 1.1280 Acc: 88.31%\n",
      "\n",
      "Epoch 43/100\n",
      "----------\n",
      "Epoch [43/100], Step [100/348], Loss: 0.6647, Accuracy: 83.75%\n",
      "Epoch [43/100], Step [200/348], Loss: 0.6151, Accuracy: 85.62%\n",
      "Epoch [43/100], Step [300/348], Loss: 0.6629, Accuracy: 82.19%\n",
      "train Loss: 0.8839 Acc: 84.86%\n",
      "Epoch [43/100], Step [100/348], Loss: 0.5953, Accuracy: 87.34%\n",
      "val Loss: 1.0561 Acc: 87.67%\n",
      "\n",
      "Epoch 44/100\n",
      "----------\n",
      "Epoch [44/100], Step [100/348], Loss: 0.9488, Accuracy: 83.44%\n",
      "Epoch [44/100], Step [200/348], Loss: 0.7884, Accuracy: 84.38%\n",
      "Epoch [44/100], Step [300/348], Loss: 0.6068, Accuracy: 85.16%\n",
      "train Loss: 0.8554 Acc: 84.79%\n",
      "Epoch [44/100], Step [100/348], Loss: 0.6151, Accuracy: 89.22%\n",
      "val Loss: 1.0928 Acc: 87.51%\n",
      "\n",
      "Epoch 45/100\n",
      "----------\n",
      "Epoch [45/100], Step [100/348], Loss: 1.9388, Accuracy: 85.31%\n",
      "Epoch [45/100], Step [200/348], Loss: 0.6950, Accuracy: 84.06%\n",
      "Epoch [45/100], Step [300/348], Loss: 0.7591, Accuracy: 85.47%\n",
      "train Loss: 0.8283 Acc: 85.14%\n",
      "Epoch [45/100], Step [100/348], Loss: 0.6512, Accuracy: 87.81%\n",
      "val Loss: 1.0951 Acc: 87.67%\n",
      "\n",
      "Epoch 46/100\n",
      "----------\n",
      "Epoch [46/100], Step [100/348], Loss: 0.8834, Accuracy: 85.16%\n",
      "Epoch [46/100], Step [200/348], Loss: 1.0717, Accuracy: 83.44%\n",
      "Epoch [46/100], Step [300/348], Loss: 0.9231, Accuracy: 86.25%\n",
      "train Loss: 0.8404 Acc: 85.11%\n",
      "Epoch [46/100], Step [100/348], Loss: 0.5467, Accuracy: 88.12%\n",
      "val Loss: 1.0111 Acc: 87.31%\n",
      "\n",
      "Epoch 47/100\n",
      "----------\n",
      "Epoch [47/100], Step [100/348], Loss: 0.8630, Accuracy: 85.16%\n",
      "Epoch [47/100], Step [200/348], Loss: 2.1247, Accuracy: 85.16%\n",
      "Epoch [47/100], Step [300/348], Loss: 1.0303, Accuracy: 85.94%\n",
      "train Loss: 0.8215 Acc: 85.28%\n",
      "Epoch [47/100], Step [100/348], Loss: 0.4601, Accuracy: 90.31%\n",
      "val Loss: 1.0165 Acc: 88.32%\n",
      "\n",
      "Epoch 48/100\n",
      "----------\n",
      "Epoch [48/100], Step [100/348], Loss: 0.6818, Accuracy: 83.91%\n",
      "Epoch [48/100], Step [200/348], Loss: 0.5001, Accuracy: 86.25%\n",
      "Epoch [48/100], Step [300/348], Loss: 0.5543, Accuracy: 86.09%\n",
      "train Loss: 0.8129 Acc: 85.26%\n",
      "Epoch [48/100], Step [100/348], Loss: 0.5830, Accuracy: 89.38%\n",
      "val Loss: 1.0252 Acc: 87.33%\n",
      "\n",
      "Epoch 49/100\n",
      "----------\n",
      "Epoch [49/100], Step [100/348], Loss: 0.6006, Accuracy: 86.56%\n",
      "Epoch [49/100], Step [200/348], Loss: 1.0709, Accuracy: 86.72%\n",
      "Epoch [49/100], Step [300/348], Loss: 0.6536, Accuracy: 85.47%\n",
      "train Loss: 0.8226 Acc: 85.36%\n",
      "Epoch [49/100], Step [100/348], Loss: 0.5280, Accuracy: 88.59%\n",
      "val Loss: 1.0395 Acc: 87.17%\n",
      "\n",
      "Epoch 50/100\n",
      "----------\n",
      "Epoch [50/100], Step [100/348], Loss: 1.0017, Accuracy: 86.56%\n",
      "Epoch [50/100], Step [200/348], Loss: 0.9393, Accuracy: 83.75%\n",
      "Epoch [50/100], Step [300/348], Loss: 0.7870, Accuracy: 86.41%\n",
      "train Loss: 0.8059 Acc: 85.40%\n",
      "Epoch [50/100], Step [100/348], Loss: 0.4894, Accuracy: 89.84%\n",
      "val Loss: 1.1564 Acc: 89.06%\n",
      "\n",
      "Epoch 51/100\n",
      "----------\n",
      "Epoch [51/100], Step [100/348], Loss: 0.5738, Accuracy: 86.09%\n",
      "Epoch [51/100], Step [200/348], Loss: 0.9882, Accuracy: 84.53%\n",
      "Epoch [51/100], Step [300/348], Loss: 1.1927, Accuracy: 85.00%\n",
      "train Loss: 0.8179 Acc: 85.70%\n",
      "Epoch [51/100], Step [100/348], Loss: 0.5804, Accuracy: 89.69%\n",
      "val Loss: 1.0372 Acc: 88.03%\n",
      "\n",
      "Epoch 52/100\n",
      "----------\n",
      "Epoch [52/100], Step [100/348], Loss: 0.4109, Accuracy: 88.44%\n",
      "Epoch [52/100], Step [200/348], Loss: 0.5852, Accuracy: 87.97%\n",
      "Epoch [52/100], Step [300/348], Loss: 0.5354, Accuracy: 87.34%\n",
      "train Loss: 0.8080 Acc: 85.49%\n",
      "Epoch [52/100], Step [100/348], Loss: 0.5744, Accuracy: 90.00%\n",
      "val Loss: 1.0902 Acc: 88.57%\n",
      "\n",
      "Epoch 53/100\n",
      "----------\n",
      "Epoch [53/100], Step [100/348], Loss: 0.6972, Accuracy: 84.38%\n",
      "Epoch [53/100], Step [200/348], Loss: 1.1776, Accuracy: 84.06%\n",
      "Epoch [53/100], Step [300/348], Loss: 0.5409, Accuracy: 86.09%\n",
      "train Loss: 0.8087 Acc: 85.37%\n",
      "Epoch [53/100], Step [100/348], Loss: 0.6398, Accuracy: 87.81%\n",
      "val Loss: 1.0726 Acc: 87.52%\n",
      "\n",
      "Epoch 54/100\n",
      "----------\n",
      "Epoch [54/100], Step [100/348], Loss: 0.5032, Accuracy: 85.62%\n",
      "Epoch [54/100], Step [200/348], Loss: 0.7728, Accuracy: 85.94%\n",
      "Epoch [54/100], Step [300/348], Loss: 0.6252, Accuracy: 83.28%\n",
      "train Loss: 0.8051 Acc: 85.54%\n",
      "Epoch [54/100], Step [100/348], Loss: 0.5683, Accuracy: 89.84%\n",
      "val Loss: 1.0007 Acc: 87.91%\n",
      "\n",
      "Epoch 55/100\n",
      "----------\n",
      "Epoch [55/100], Step [100/348], Loss: 0.6812, Accuracy: 85.16%\n",
      "Epoch [55/100], Step [200/348], Loss: 1.1364, Accuracy: 84.84%\n",
      "Epoch [55/100], Step [300/348], Loss: 0.6300, Accuracy: 86.09%\n",
      "train Loss: 0.7830 Acc: 85.78%\n",
      "Epoch [55/100], Step [100/348], Loss: 0.4921, Accuracy: 91.41%\n",
      "val Loss: 1.0940 Acc: 88.97%\n",
      "\n",
      "Epoch 56/100\n",
      "----------\n",
      "Epoch [56/100], Step [100/348], Loss: 0.5025, Accuracy: 87.81%\n",
      "Epoch [56/100], Step [200/348], Loss: 0.6794, Accuracy: 84.53%\n",
      "Epoch [56/100], Step [300/348], Loss: 2.0123, Accuracy: 85.00%\n",
      "train Loss: 0.7881 Acc: 85.89%\n",
      "Epoch [56/100], Step [100/348], Loss: 0.5402, Accuracy: 90.31%\n",
      "val Loss: 0.9464 Acc: 87.00%\n",
      "\n",
      "Epoch 57/100\n",
      "----------\n",
      "Epoch [57/100], Step [100/348], Loss: 1.6475, Accuracy: 83.28%\n",
      "Epoch [57/100], Step [200/348], Loss: 0.6103, Accuracy: 86.56%\n",
      "Epoch [57/100], Step [300/348], Loss: 0.5745, Accuracy: 85.16%\n",
      "train Loss: 0.7874 Acc: 85.77%\n",
      "Epoch [57/100], Step [100/348], Loss: 0.6259, Accuracy: 91.09%\n",
      "val Loss: 1.0634 Acc: 89.99%\n",
      "\n",
      "Epoch 58/100\n",
      "----------\n",
      "Epoch [58/100], Step [100/348], Loss: 0.6257, Accuracy: 86.56%\n",
      "Epoch [58/100], Step [200/348], Loss: 0.5888, Accuracy: 88.28%\n",
      "Epoch [58/100], Step [300/348], Loss: 0.5472, Accuracy: 87.66%\n",
      "train Loss: 0.7836 Acc: 85.97%\n",
      "Epoch [58/100], Step [100/348], Loss: 0.5398, Accuracy: 91.41%\n",
      "val Loss: 0.9950 Acc: 88.40%\n",
      "\n",
      "Epoch 59/100\n",
      "----------\n",
      "Epoch [59/100], Step [100/348], Loss: 0.9258, Accuracy: 86.56%\n",
      "Epoch [59/100], Step [200/348], Loss: 0.5712, Accuracy: 83.28%\n",
      "Epoch [59/100], Step [300/348], Loss: 0.6595, Accuracy: 86.72%\n",
      "train Loss: 0.7590 Acc: 86.27%\n",
      "Epoch [59/100], Step [100/348], Loss: 0.4742, Accuracy: 92.03%\n",
      "val Loss: 1.0088 Acc: 88.75%\n",
      "\n",
      "Epoch 60/100\n",
      "----------\n",
      "Epoch [60/100], Step [100/348], Loss: 0.4306, Accuracy: 87.81%\n",
      "Epoch [60/100], Step [200/348], Loss: 0.7508, Accuracy: 84.84%\n",
      "Epoch [60/100], Step [300/348], Loss: 0.5253, Accuracy: 87.50%\n",
      "train Loss: 0.7595 Acc: 86.27%\n",
      "Epoch [60/100], Step [100/348], Loss: 0.5520, Accuracy: 89.22%\n",
      "val Loss: 0.9498 Acc: 87.02%\n",
      "\n",
      "Epoch 61/100\n",
      "----------\n",
      "Epoch [61/100], Step [100/348], Loss: 0.8224, Accuracy: 88.12%\n",
      "Epoch [61/100], Step [200/348], Loss: 0.7902, Accuracy: 89.84%\n",
      "Epoch [61/100], Step [300/348], Loss: 0.4837, Accuracy: 85.94%\n",
      "train Loss: 0.7275 Acc: 86.54%\n",
      "Epoch [61/100], Step [100/348], Loss: 0.5108, Accuracy: 91.09%\n",
      "val Loss: 0.9870 Acc: 89.36%\n",
      "\n",
      "Epoch 62/100\n",
      "----------\n",
      "Epoch [62/100], Step [100/348], Loss: 0.7475, Accuracy: 85.62%\n",
      "Epoch [62/100], Step [200/348], Loss: 0.5376, Accuracy: 85.31%\n",
      "Epoch [62/100], Step [300/348], Loss: 0.7526, Accuracy: 86.72%\n",
      "train Loss: 0.7348 Acc: 86.58%\n",
      "Epoch [62/100], Step [100/348], Loss: 0.5062, Accuracy: 90.47%\n",
      "val Loss: 0.9593 Acc: 88.86%\n",
      "\n",
      "Epoch 63/100\n",
      "----------\n",
      "Epoch [63/100], Step [100/348], Loss: 0.5541, Accuracy: 88.28%\n",
      "Epoch [63/100], Step [200/348], Loss: 0.6644, Accuracy: 89.69%\n",
      "Epoch [63/100], Step [300/348], Loss: 1.0988, Accuracy: 84.84%\n",
      "train Loss: 0.7612 Acc: 86.29%\n",
      "Epoch [63/100], Step [100/348], Loss: 0.5064, Accuracy: 91.25%\n",
      "val Loss: 0.9592 Acc: 88.98%\n",
      "\n",
      "Epoch 64/100\n",
      "----------\n",
      "Epoch [64/100], Step [100/348], Loss: 0.5889, Accuracy: 88.12%\n",
      "Epoch [64/100], Step [200/348], Loss: 0.9025, Accuracy: 85.94%\n",
      "Epoch [64/100], Step [300/348], Loss: 0.7784, Accuracy: 85.00%\n",
      "train Loss: 0.7500 Acc: 86.44%\n",
      "Epoch [64/100], Step [100/348], Loss: 0.5374, Accuracy: 89.22%\n",
      "val Loss: 0.9657 Acc: 89.05%\n",
      "\n",
      "Epoch 65/100\n",
      "----------\n",
      "Epoch [65/100], Step [100/348], Loss: 0.7521, Accuracy: 85.47%\n",
      "Epoch [65/100], Step [200/348], Loss: 0.6819, Accuracy: 86.88%\n",
      "Epoch [65/100], Step [300/348], Loss: 0.6708, Accuracy: 85.94%\n",
      "train Loss: 0.7240 Acc: 86.76%\n",
      "Epoch [65/100], Step [100/348], Loss: 0.4894, Accuracy: 90.47%\n",
      "val Loss: 0.9625 Acc: 89.16%\n",
      "\n",
      "Epoch 66/100\n",
      "----------\n",
      "Epoch [66/100], Step [100/348], Loss: 0.4744, Accuracy: 86.09%\n",
      "Epoch [66/100], Step [200/348], Loss: 0.5889, Accuracy: 88.75%\n",
      "Epoch [66/100], Step [300/348], Loss: 0.7755, Accuracy: 87.81%\n",
      "train Loss: 0.7257 Acc: 86.81%\n",
      "Epoch [66/100], Step [100/348], Loss: 0.4547, Accuracy: 90.62%\n",
      "val Loss: 0.9539 Acc: 88.20%\n",
      "\n",
      "Epoch 67/100\n",
      "----------\n",
      "Epoch [67/100], Step [100/348], Loss: 1.3388, Accuracy: 88.44%\n",
      "Epoch [67/100], Step [200/348], Loss: 0.5969, Accuracy: 85.62%\n",
      "Epoch [67/100], Step [300/348], Loss: 0.7693, Accuracy: 86.88%\n",
      "train Loss: 0.7011 Acc: 87.08%\n",
      "Epoch [67/100], Step [100/348], Loss: 0.5132, Accuracy: 91.25%\n",
      "val Loss: 0.9941 Acc: 88.94%\n",
      "\n",
      "Epoch 68/100\n",
      "----------\n",
      "Epoch [68/100], Step [100/348], Loss: 1.2953, Accuracy: 85.78%\n",
      "Epoch [68/100], Step [200/348], Loss: 0.5041, Accuracy: 87.66%\n",
      "Epoch [68/100], Step [300/348], Loss: 1.2461, Accuracy: 86.56%\n",
      "train Loss: 0.7209 Acc: 86.92%\n",
      "Epoch [68/100], Step [100/348], Loss: 0.5118, Accuracy: 91.72%\n",
      "val Loss: 1.0347 Acc: 90.18%\n",
      "\n",
      "Epoch 69/100\n",
      "----------\n",
      "Epoch [69/100], Step [100/348], Loss: 0.4313, Accuracy: 87.97%\n",
      "Epoch [69/100], Step [200/348], Loss: 1.6517, Accuracy: 87.97%\n",
      "Epoch [69/100], Step [300/348], Loss: 0.4400, Accuracy: 86.72%\n",
      "train Loss: 0.6967 Acc: 87.28%\n",
      "Epoch [69/100], Step [100/348], Loss: 0.5037, Accuracy: 90.78%\n",
      "val Loss: 0.9893 Acc: 89.54%\n",
      "\n",
      "Epoch 70/100\n",
      "----------\n",
      "Epoch [70/100], Step [100/348], Loss: 0.5799, Accuracy: 88.44%\n",
      "Epoch [70/100], Step [200/348], Loss: 0.6421, Accuracy: 88.91%\n",
      "Epoch [70/100], Step [300/348], Loss: 0.6720, Accuracy: 87.50%\n",
      "train Loss: 0.7158 Acc: 87.15%\n",
      "Epoch [70/100], Step [100/348], Loss: 0.4863, Accuracy: 90.47%\n",
      "val Loss: 0.9372 Acc: 88.88%\n",
      "\n",
      "Epoch 71/100\n",
      "----------\n",
      "Epoch [71/100], Step [100/348], Loss: 0.9944, Accuracy: 85.78%\n",
      "Epoch [71/100], Step [200/348], Loss: 0.6069, Accuracy: 87.34%\n",
      "Epoch [71/100], Step [300/348], Loss: 0.4908, Accuracy: 87.50%\n",
      "train Loss: 0.6783 Acc: 87.36%\n",
      "Epoch [71/100], Step [100/348], Loss: 0.4982, Accuracy: 91.72%\n",
      "val Loss: 0.9408 Acc: 89.64%\n",
      "\n",
      "Epoch 72/100\n",
      "----------\n",
      "Epoch [72/100], Step [100/348], Loss: 0.6423, Accuracy: 89.06%\n",
      "Epoch [72/100], Step [200/348], Loss: 0.5643, Accuracy: 85.16%\n",
      "Epoch [72/100], Step [300/348], Loss: 0.7634, Accuracy: 88.28%\n",
      "train Loss: 0.7036 Acc: 87.19%\n",
      "Epoch [72/100], Step [100/348], Loss: 0.5693, Accuracy: 91.09%\n",
      "val Loss: 0.9548 Acc: 89.88%\n",
      "\n",
      "Epoch 73/100\n",
      "----------\n",
      "Epoch [73/100], Step [100/348], Loss: 0.8180, Accuracy: 89.53%\n",
      "Epoch [73/100], Step [200/348], Loss: 0.5261, Accuracy: 86.56%\n",
      "Epoch [73/100], Step [300/348], Loss: 1.1492, Accuracy: 85.16%\n",
      "train Loss: 0.6900 Acc: 87.39%\n",
      "Epoch [73/100], Step [100/348], Loss: 0.5527, Accuracy: 91.72%\n",
      "val Loss: 0.9536 Acc: 89.45%\n",
      "\n",
      "Epoch 74/100\n",
      "----------\n",
      "Epoch [74/100], Step [100/348], Loss: 0.8507, Accuracy: 87.50%\n",
      "Epoch [74/100], Step [200/348], Loss: 0.5448, Accuracy: 89.69%\n",
      "Epoch [74/100], Step [300/348], Loss: 0.5399, Accuracy: 84.53%\n",
      "train Loss: 0.7108 Acc: 87.26%\n",
      "Epoch [74/100], Step [100/348], Loss: 0.5808, Accuracy: 92.03%\n",
      "val Loss: 0.9113 Acc: 89.53%\n",
      "\n",
      "Epoch 75/100\n",
      "----------\n",
      "Epoch [75/100], Step [100/348], Loss: 1.2398, Accuracy: 86.09%\n",
      "Epoch [75/100], Step [200/348], Loss: 0.5208, Accuracy: 89.22%\n",
      "Epoch [75/100], Step [300/348], Loss: 0.7058, Accuracy: 88.12%\n",
      "train Loss: 0.6871 Acc: 87.60%\n",
      "Epoch [75/100], Step [100/348], Loss: 0.5917, Accuracy: 90.47%\n",
      "val Loss: 0.9111 Acc: 89.20%\n",
      "\n",
      "Epoch 76/100\n",
      "----------\n",
      "Epoch [76/100], Step [100/348], Loss: 0.5792, Accuracy: 87.97%\n",
      "Epoch [76/100], Step [200/348], Loss: 0.6416, Accuracy: 88.75%\n",
      "Epoch [76/100], Step [300/348], Loss: 0.5999, Accuracy: 86.88%\n",
      "train Loss: 0.6699 Acc: 87.80%\n",
      "Epoch [76/100], Step [100/348], Loss: 0.5224, Accuracy: 91.25%\n",
      "val Loss: 0.9234 Acc: 89.45%\n",
      "\n",
      "Epoch 77/100\n",
      "----------\n",
      "Epoch [77/100], Step [100/348], Loss: 0.5226, Accuracy: 86.72%\n",
      "Epoch [77/100], Step [200/348], Loss: 0.7250, Accuracy: 90.31%\n",
      "Epoch [77/100], Step [300/348], Loss: 0.7678, Accuracy: 86.72%\n",
      "train Loss: 0.6954 Acc: 87.57%\n",
      "Epoch [77/100], Step [100/348], Loss: 0.5251, Accuracy: 91.88%\n",
      "val Loss: 0.9198 Acc: 89.55%\n",
      "\n",
      "Epoch 78/100\n",
      "----------\n",
      "Epoch [78/100], Step [100/348], Loss: 0.7414, Accuracy: 89.22%\n",
      "Epoch [78/100], Step [200/348], Loss: 0.4847, Accuracy: 87.66%\n",
      "Epoch [78/100], Step [300/348], Loss: 0.7109, Accuracy: 89.53%\n",
      "train Loss: 0.6754 Acc: 87.85%\n",
      "Epoch [78/100], Step [100/348], Loss: 0.5452, Accuracy: 91.72%\n",
      "val Loss: 0.9245 Acc: 90.01%\n",
      "\n",
      "Epoch 79/100\n",
      "----------\n",
      "Epoch [79/100], Step [100/348], Loss: 0.6562, Accuracy: 88.44%\n",
      "Epoch [79/100], Step [200/348], Loss: 0.4374, Accuracy: 87.97%\n",
      "Epoch [79/100], Step [300/348], Loss: 0.6524, Accuracy: 87.97%\n",
      "train Loss: 0.6609 Acc: 87.99%\n",
      "Epoch [79/100], Step [100/348], Loss: 0.5319, Accuracy: 91.09%\n",
      "val Loss: 0.9445 Acc: 89.60%\n",
      "\n",
      "Epoch 80/100\n",
      "----------\n",
      "Epoch [80/100], Step [100/348], Loss: 0.5293, Accuracy: 89.84%\n",
      "Epoch [80/100], Step [200/348], Loss: 0.5833, Accuracy: 87.03%\n",
      "Epoch [80/100], Step [300/348], Loss: 0.5096, Accuracy: 87.34%\n",
      "train Loss: 0.6717 Acc: 87.91%\n",
      "Epoch [80/100], Step [100/348], Loss: 0.5035, Accuracy: 91.88%\n",
      "val Loss: 0.9042 Acc: 90.15%\n",
      "\n",
      "Epoch 81/100\n",
      "----------\n",
      "Epoch [81/100], Step [100/348], Loss: 0.7183, Accuracy: 88.44%\n",
      "Epoch [81/100], Step [200/348], Loss: 0.4611, Accuracy: 89.69%\n",
      "Epoch [81/100], Step [300/348], Loss: 0.7220, Accuracy: 87.03%\n",
      "train Loss: 0.6648 Acc: 88.12%\n",
      "Epoch [81/100], Step [100/348], Loss: 0.5143, Accuracy: 90.78%\n",
      "val Loss: 0.8953 Acc: 89.38%\n",
      "\n",
      "Epoch 82/100\n",
      "----------\n",
      "Epoch [82/100], Step [100/348], Loss: 0.5720, Accuracy: 89.53%\n",
      "Epoch [82/100], Step [200/348], Loss: 0.5653, Accuracy: 88.28%\n",
      "Epoch [82/100], Step [300/348], Loss: 0.3256, Accuracy: 91.09%\n",
      "train Loss: 0.6694 Acc: 87.87%\n",
      "Epoch [82/100], Step [100/348], Loss: 0.4861, Accuracy: 91.41%\n",
      "val Loss: 0.9133 Acc: 89.70%\n",
      "\n",
      "Epoch 83/100\n",
      "----------\n",
      "Epoch [83/100], Step [100/348], Loss: 0.7268, Accuracy: 84.69%\n",
      "Epoch [83/100], Step [200/348], Loss: 0.5948, Accuracy: 86.88%\n",
      "Epoch [83/100], Step [300/348], Loss: 0.5915, Accuracy: 88.28%\n",
      "train Loss: 0.6363 Acc: 88.30%\n",
      "Epoch [83/100], Step [100/348], Loss: 0.5200, Accuracy: 90.78%\n",
      "val Loss: 0.8912 Acc: 89.75%\n",
      "\n",
      "Epoch 84/100\n",
      "----------\n",
      "Epoch [84/100], Step [100/348], Loss: 0.6779, Accuracy: 87.97%\n",
      "Epoch [84/100], Step [200/348], Loss: 0.5892, Accuracy: 90.47%\n",
      "Epoch [84/100], Step [300/348], Loss: 0.5151, Accuracy: 88.59%\n",
      "train Loss: 0.6449 Acc: 88.30%\n",
      "Epoch [84/100], Step [100/348], Loss: 0.4980, Accuracy: 91.41%\n",
      "val Loss: 0.8892 Acc: 89.82%\n",
      "\n",
      "Epoch 85/100\n",
      "----------\n",
      "Epoch [85/100], Step [100/348], Loss: 0.6177, Accuracy: 87.97%\n",
      "Epoch [85/100], Step [200/348], Loss: 0.7506, Accuracy: 88.12%\n",
      "Epoch [85/100], Step [300/348], Loss: 0.5091, Accuracy: 87.50%\n",
      "train Loss: 0.6475 Acc: 88.23%\n",
      "Epoch [85/100], Step [100/348], Loss: 0.4539, Accuracy: 91.41%\n",
      "val Loss: 0.9175 Acc: 89.99%\n",
      "\n",
      "Epoch 86/100\n",
      "----------\n",
      "Epoch [86/100], Step [100/348], Loss: 0.4474, Accuracy: 88.75%\n",
      "Epoch [86/100], Step [200/348], Loss: 0.5252, Accuracy: 89.53%\n",
      "Epoch [86/100], Step [300/348], Loss: 0.5026, Accuracy: 88.12%\n",
      "train Loss: 0.6368 Acc: 88.31%\n",
      "Epoch [86/100], Step [100/348], Loss: 0.4638, Accuracy: 92.03%\n",
      "val Loss: 0.9319 Acc: 90.79%\n",
      "\n",
      "Epoch 87/100\n",
      "----------\n",
      "Epoch [87/100], Step [100/348], Loss: 0.4340, Accuracy: 88.75%\n",
      "Epoch [87/100], Step [200/348], Loss: 0.8484, Accuracy: 88.28%\n",
      "Epoch [87/100], Step [300/348], Loss: 0.5377, Accuracy: 89.22%\n",
      "train Loss: 0.6491 Acc: 88.45%\n",
      "Epoch [87/100], Step [100/348], Loss: 0.5026, Accuracy: 91.72%\n",
      "val Loss: 0.9093 Acc: 89.87%\n",
      "\n",
      "Epoch 88/100\n",
      "----------\n",
      "Epoch [88/100], Step [100/348], Loss: 0.6278, Accuracy: 86.09%\n",
      "Epoch [88/100], Step [200/348], Loss: 0.5292, Accuracy: 88.44%\n",
      "Epoch [88/100], Step [300/348], Loss: 0.5884, Accuracy: 88.12%\n",
      "train Loss: 0.6387 Acc: 88.29%\n",
      "Epoch [88/100], Step [100/348], Loss: 0.4572, Accuracy: 92.50%\n",
      "val Loss: 0.9335 Acc: 90.65%\n",
      "\n",
      "Epoch 89/100\n",
      "----------\n",
      "Epoch [89/100], Step [100/348], Loss: 0.7186, Accuracy: 87.03%\n",
      "Epoch [89/100], Step [200/348], Loss: 0.9532, Accuracy: 87.81%\n",
      "Epoch [89/100], Step [300/348], Loss: 0.6921, Accuracy: 88.59%\n",
      "train Loss: 0.6501 Acc: 88.46%\n",
      "Epoch [89/100], Step [100/348], Loss: 0.4593, Accuracy: 92.81%\n",
      "val Loss: 0.8984 Acc: 90.57%\n",
      "\n",
      "Epoch 90/100\n",
      "----------\n",
      "Epoch [90/100], Step [100/348], Loss: 0.6201, Accuracy: 88.44%\n",
      "Epoch [90/100], Step [200/348], Loss: 0.5237, Accuracy: 88.59%\n",
      "Epoch [90/100], Step [300/348], Loss: 0.4988, Accuracy: 88.12%\n",
      "train Loss: 0.6382 Acc: 88.48%\n",
      "Epoch [90/100], Step [100/348], Loss: 0.4423, Accuracy: 92.81%\n",
      "val Loss: 0.9000 Acc: 90.40%\n",
      "\n",
      "Epoch 91/100\n",
      "----------\n",
      "Epoch [91/100], Step [100/348], Loss: 0.4999, Accuracy: 86.88%\n",
      "Epoch [91/100], Step [200/348], Loss: 0.4583, Accuracy: 89.38%\n",
      "Epoch [91/100], Step [300/348], Loss: 0.5010, Accuracy: 87.03%\n",
      "train Loss: 0.6505 Acc: 88.30%\n",
      "Epoch [91/100], Step [100/348], Loss: 0.4468, Accuracy: 93.28%\n",
      "val Loss: 0.8553 Acc: 89.88%\n",
      "\n",
      "Epoch 92/100\n",
      "----------\n",
      "Epoch [92/100], Step [100/348], Loss: 0.5888, Accuracy: 88.44%\n",
      "Epoch [92/100], Step [200/348], Loss: 0.6892, Accuracy: 88.28%\n",
      "Epoch [92/100], Step [300/348], Loss: 0.7297, Accuracy: 89.22%\n",
      "train Loss: 0.6277 Acc: 88.67%\n",
      "Epoch [92/100], Step [100/348], Loss: 0.4802, Accuracy: 92.81%\n",
      "val Loss: 0.8798 Acc: 90.34%\n",
      "\n",
      "Epoch 93/100\n",
      "----------\n",
      "Epoch [93/100], Step [100/348], Loss: 0.7208, Accuracy: 86.56%\n",
      "Epoch [93/100], Step [200/348], Loss: 0.4359, Accuracy: 90.47%\n",
      "Epoch [93/100], Step [300/348], Loss: 0.6150, Accuracy: 86.41%\n",
      "train Loss: 0.6455 Acc: 88.43%\n",
      "Epoch [93/100], Step [100/348], Loss: 0.4734, Accuracy: 92.66%\n",
      "val Loss: 0.8961 Acc: 90.47%\n",
      "\n",
      "Epoch 94/100\n",
      "----------\n",
      "Epoch [94/100], Step [100/348], Loss: 1.6200, Accuracy: 89.84%\n",
      "Epoch [94/100], Step [200/348], Loss: 0.4290, Accuracy: 88.59%\n",
      "Epoch [94/100], Step [300/348], Loss: 0.6760, Accuracy: 88.59%\n",
      "train Loss: 0.6344 Acc: 88.67%\n",
      "Epoch [94/100], Step [100/348], Loss: 0.4691, Accuracy: 92.81%\n",
      "val Loss: 0.9056 Acc: 90.52%\n",
      "\n",
      "Epoch 95/100\n",
      "----------\n",
      "Epoch [95/100], Step [100/348], Loss: 0.6266, Accuracy: 89.22%\n",
      "Epoch [95/100], Step [200/348], Loss: 0.4566, Accuracy: 90.00%\n",
      "Epoch [95/100], Step [300/348], Loss: 0.5136, Accuracy: 90.00%\n",
      "train Loss: 0.6223 Acc: 88.79%\n",
      "Epoch [95/100], Step [100/348], Loss: 0.4727, Accuracy: 92.50%\n",
      "val Loss: 0.8957 Acc: 90.68%\n",
      "\n",
      "Epoch 96/100\n",
      "----------\n",
      "Epoch [96/100], Step [100/348], Loss: 0.6354, Accuracy: 87.03%\n",
      "Epoch [96/100], Step [200/348], Loss: 0.8963, Accuracy: 89.38%\n",
      "Epoch [96/100], Step [300/348], Loss: 0.5790, Accuracy: 88.59%\n",
      "train Loss: 0.6336 Acc: 88.77%\n",
      "Epoch [96/100], Step [100/348], Loss: 0.4423, Accuracy: 92.19%\n",
      "val Loss: 0.9132 Acc: 90.46%\n",
      "\n",
      "Epoch 97/100\n",
      "----------\n",
      "Epoch [97/100], Step [100/348], Loss: 0.5386, Accuracy: 87.34%\n",
      "Epoch [97/100], Step [200/348], Loss: 0.4794, Accuracy: 88.75%\n",
      "Epoch [97/100], Step [300/348], Loss: 0.6314, Accuracy: 89.84%\n",
      "train Loss: 0.6260 Acc: 88.84%\n",
      "Epoch [97/100], Step [100/348], Loss: 0.4567, Accuracy: 92.03%\n",
      "val Loss: 0.8971 Acc: 90.62%\n",
      "\n",
      "Epoch 98/100\n",
      "----------\n",
      "Epoch [98/100], Step [100/348], Loss: 0.7555, Accuracy: 90.47%\n",
      "Epoch [98/100], Step [200/348], Loss: 0.5622, Accuracy: 89.22%\n",
      "Epoch [98/100], Step [300/348], Loss: 0.5366, Accuracy: 88.12%\n",
      "train Loss: 0.6376 Acc: 88.72%\n",
      "Epoch [98/100], Step [100/348], Loss: 0.4597, Accuracy: 92.66%\n",
      "val Loss: 0.8941 Acc: 90.84%\n",
      "\n",
      "Epoch 99/100\n",
      "----------\n",
      "Epoch [99/100], Step [100/348], Loss: 0.4209, Accuracy: 88.28%\n",
      "Epoch [99/100], Step [200/348], Loss: 0.6759, Accuracy: 90.31%\n",
      "Epoch [99/100], Step [300/348], Loss: 0.5742, Accuracy: 88.91%\n",
      "train Loss: 0.6292 Acc: 88.94%\n",
      "Epoch [99/100], Step [100/348], Loss: 0.4381, Accuracy: 91.72%\n",
      "val Loss: 0.8919 Acc: 90.33%\n",
      "\n",
      "Epoch 100/100\n",
      "----------\n",
      "Epoch [100/100], Step [100/348], Loss: 0.5003, Accuracy: 87.03%\n",
      "Epoch [100/100], Step [200/348], Loss: 0.4864, Accuracy: 89.53%\n",
      "Epoch [100/100], Step [300/348], Loss: 0.5193, Accuracy: 88.59%\n",
      "train Loss: 0.6339 Acc: 88.72%\n",
      "Epoch [100/100], Step [100/348], Loss: 0.4317, Accuracy: 92.34%\n",
      "val Loss: 0.8785 Acc: 90.61%\n",
      "\n",
      "Training complete in 254m 34s\n",
      "Best val Acc: 0.898761\n",
      "Best loss: 0.855327\n"
     ]
    }
   ],
   "source": [
    "# Observe that all parameters are being optimized\n",
    "optimizer = optim.Adam(params_to_update, lr=lr_start)\n",
    "\n",
    "# Learning rate scheduler.\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs, eta_min=lr_end,\n",
    "                                                 last_epoch=-1)\n",
    "\n",
    "\n",
    "# Setup the loss fxn\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "\n",
    "# Train and evaluate\n",
    "model_pyt, prof, val_history, train_history = train_model(device, model_pyt, data_loaders, \n",
    "                                                            optimizer, scheduler,\n",
    "                                                            criterion, \n",
    "                                                            num_epochs=num_epochs,\n",
    "                                                            num_classes=num_classes,\n",
    "                                                            is_inception=(model_name==\"inceptionv3\"),\n",
    "                                                            profiler=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'ads'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "zM-dorQBJAZb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_model(model_pyt.state_dict(), '../models/', \n",
    "           f'{model_name}_{dataset_name}_{num_epochs}_{batch_size}_{lr_start}_{lr_end}_model_weights.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_metrics = eval_model(device=device, model=model_pyt, test_loader=data_loaders['test'], is_inception=(model_name==\"inceptionv3\"), num_classes=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 2.573429802955665\n",
      "f1: 0.1884049865516239\n",
      "cm: [[[3139   60]\n",
      "  [ 423   90]]\n",
      "\n",
      " [[3314  169]\n",
      "  [ 198   31]]\n",
      "\n",
      " [[3422  265]\n",
      "  [  17    8]]\n",
      "\n",
      " [[3479  173]\n",
      "  [  49   11]]\n",
      "\n",
      " [[3516  152]\n",
      "  [  38    6]]\n",
      "\n",
      " [[3406  221]\n",
      "  [  77    8]]\n",
      "\n",
      " [[3409  184]\n",
      "  [ 112    7]]\n",
      "\n",
      " [[3377  264]\n",
      "  [  59   12]]\n",
      "\n",
      " [[2906   21]\n",
      "  [ 733   52]]\n",
      "\n",
      " [[2728   33]\n",
      "  [ 713  238]]\n",
      "\n",
      " [[3325  230]\n",
      "  [ 109   48]]\n",
      "\n",
      " [[3279  412]\n",
      "  [  17    4]]\n",
      "\n",
      " [[2817   74]\n",
      "  [ 511  310]]\n",
      "\n",
      " [[3054  156]\n",
      "  [ 221  281]]\n",
      "\n",
      " [[3327  168]\n",
      "  [ 155   62]]\n",
      "\n",
      " [[3349  342]\n",
      "  [  14    7]]\n",
      "\n",
      " [[3416  167]\n",
      "  [  77   52]]\n",
      "\n",
      " [[3361  263]\n",
      "  [  67   21]]\n",
      "\n",
      " [[3488  165]\n",
      "  [  21   38]]\n",
      "\n",
      " [[3456  200]\n",
      "  [  42   14]]]\n",
      "outputs: [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]]\n",
      "targets: [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "for i, v in eval_metrics.items():\n",
    "    print(f\"{i}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'../models/val_history_{model_name}_{dataset_name}_{num_epochs}_{batch_size}_{lr_start}_{lr_end}_.pickle', 'wb') as handle:\n",
    "    pickle.dump(val_history, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open(f'../models/train_history_{model_name}_{dataset_name}_{num_epochs}_{batch_size}_{lr_start}_{lr_end}_.pickle', 'wb') as handle:\n",
    "    pickle.dump(train_history, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open(f'../models/eval_metrics_{model_name}_{dataset_name}_{num_epochs}_{batch_size}_{lr_start}_{lr_end}_.pickle', 'wb') as handle:\n",
    "    pickle.dump(eval_metrics, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "#with open('filename.pickle', 'rb') as handle:\n",
    "#    b = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WvFygat_aiDN"
   },
   "outputs": [],
   "source": [
    "#print(prof.key_averages(group_by_stack_n=5).table(sort_by='self_cpu_time_total', row_limit=50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "EQ6hb3iO2mXv"
   },
   "outputs": [],
   "source": [
    "# Plot the training curves of validation accuracy vs. number\n",
    "#  of training epochs for the transfer learning method and\n",
    "#  the model trained from scratch\n",
    "# vhist = []\n",
    "# vhist = [h.cpu().numpy() for h in val_acc_history]\n",
    "# thist = []\n",
    "# thist = [h.cpu().numpy() for h in train_acc_history]\n",
    "\n",
    "# plt.title(\"Accuracy vs. Number of Training Epochs\")\n",
    "# plt.xlabel(\"Training Epochs\")\n",
    "# plt.ylabel(\"Accuracy\")\n",
    "# #plt.plot(range(1,num_epochs+1),ohist,label=\"Pretrained\")\n",
    "# plt.plot(range(1,num_epochs+1),vhist,label=\"Validation\")\n",
    "# plt.plot(range(1,num_epochs+1),thist,label=\"Training\")\n",
    "# plt.ylim((0,1.))\n",
    "# plt.xticks(np.arange(1, num_epochs+1, 1.0))\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "aXpHASjTUE_Q"
   },
   "outputs": [],
   "source": [
    "# Plot the training curves of validation accuracy vs. number\n",
    "#  of training epochs for the transfer learning method and\n",
    "#  the model trained from scratch\n",
    "# vhist = []\n",
    "# vhist = [h for h in val_loss_history]\n",
    "# thist = []\n",
    "# thist = [h for h in train_loss_history]\n",
    "\n",
    "# plt.title(\"Loss vs. Number of Training Epochs\")\n",
    "# plt.xlabel(\"Training Epochs\")\n",
    "# plt.ylabel(\"Loss\")\n",
    "# #plt.plot(range(1,num_epochs+1),ohist,label=\"Pretrained\")\n",
    "# plt.plot(range(1,num_epochs+1),vhist,label=\"Validation\")\n",
    "# plt.plot(range(1,num_epochs+1),thist,label=\"Training\")\n",
    "# plt.ylim((0,1.))\n",
    "# plt.xticks(np.arange(1, num_epochs+1, 1.0))\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3.9.13 ('dl')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "8663be1127523d7121742bbf948a8b1c8dd9a63c15e224e5108ff87b090569d5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
