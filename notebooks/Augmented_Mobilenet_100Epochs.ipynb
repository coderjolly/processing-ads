{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train for 50 epochs. First use only fine tuning on last layer\n",
    "## Then compare with fine-tuning entire network\n",
    "## TODO: \n",
    "## 0. Pre-process images\n",
    "##      Resize images\n",
    "##      Other pre-processing\n",
    "## 0.1. Check image colors\n",
    "## 1. Get mean and std of dataset - done\n",
    "## Data augmentation - done\n",
    "## 2. Train on Resnet-34\n",
    "## 3. Train on efficient net b3\n",
    "## 4. Train on mobilenet v3 large\n",
    "## 5. Write a script to plot loss + accuracy graph\n",
    "## 6. Get FLOPs\n",
    "## 7. Get num layers - not needed?\n",
    "## 8. Add class weights - done\n",
    "## 9. Implement gradcam - done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from multilabel.train import train_model\n",
    "from model import initialize_model\n",
    "from utils import set_requires_grad, save_model\n",
    "from multilabel.data import load_data\n",
    "from plotting import plot_data_loader\n",
    "from multilabel.eval import eval_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "0w24yf-Tj47H"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import time\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "from numpy.random import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.io import read_image\n",
    "import torchvision.transforms as T\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, models, transforms\n",
    "import torch.autograd.profiler as tprofiler\n",
    "import torch.utils.data as td\n",
    "\n",
    "plt.rcParams[\"savefig.bbox\"] = 'tight'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "O7W8BTtF3BN1"
   },
   "outputs": [],
   "source": [
    "seed = 42\n",
    "\n",
    "random.seed(seed)\n",
    "\n",
    "# pytorch RNGs\n",
    "torch.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "if torch.cuda.is_available(): torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "# numpy RNG\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "21_bts2Wj47M",
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_dir = \"../data\"\n",
    "images_dir = \"../data/processed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "nr7fQfkuj47u"
   },
   "outputs": [],
   "source": [
    "# Get best num_workers\n",
    "# for i in range(97):\n",
    "#     start = time.time()\n",
    "#     data_loader = load_data(images_dir,\n",
    "#                                                                    batch_size = 96, \n",
    "#                                                                    input_size = 299, \n",
    "#                                                                    norm_arr = ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "#                                                                    num_workers = i)\n",
    "#     iter(data_loader['train']).next()[0].shape\n",
    "#     print(f\"{i}: {time.time()-start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "96wB0P9Gj47u"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k-vpcOXE1pmg",
    "outputId": "25752964-a425-490c-d154-0cc8baab3b61"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Check if GPU is available.\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "# Models options: resnet50, resnet34, inceptionv3, vgg16, mobile_net_v3_large, efficient_net_b1, efficient_net_b0, efficient_net_b3.\n",
    "model_name = \"mobile_net_v3_large\"\n",
    "\n",
    "# Number of classes.\n",
    "num_classes = 20\n",
    "\n",
    "# Batch Size.\n",
    "batch_size = 32\n",
    "\n",
    "# Epochs to train for.\n",
    "num_epochs = 100\n",
    "\n",
    "# Number of workers for data loader.\n",
    "num_workers = 12\n",
    "\n",
    "# Imagenet norm array passed as default value.\n",
    "# norm_arr=([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "# Chest x-ray8 training dataset metrics \n",
    "norm_arr=((0.5989, 0.5510, 0.5175), (0.3358, 0.3330, 0.3377))\n",
    "\n",
    "# Feature extract flag: False - Tune the whole model,\n",
    "#                       True - Update only the reshaped layer parameters.\n",
    "feature_extract = True\n",
    "\n",
    "# Use pretrained flag: None - Use random weights\n",
    "#                      String - Use pretrained weights given by String\n",
    "#use_pretrained = models.EfficientNet_B3_Weights.IMAGENET1K_V1\n",
    "use_pretrained = models.MobileNet_V3_Large_Weights.IMAGENET1K_V2\n",
    "\n",
    "# Initialize the model for this run.\n",
    "model_pyt, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=use_pretrained)\n",
    "\n",
    "# lr start and end points for training.\n",
    "lr_start = 0.01\n",
    "lr_end = 0.001\n",
    "\n",
    "# Print the model we just instantiated\n",
    "#print(model_ft)\n",
    "\n",
    "# Positive class weights.\n",
    "pos_weight=torch.as_tensor([ 2.3509,  6.4782, 76.3264, 23.6350, 46.7897, 18.5694, 14.4224, 24.4805,\n",
    "         1.1795,  0.6394,  9.1227, 80.2774,  0.8743,  2.1217,  7.2973, 87.3730,\n",
    "        12.8151, 23.7444, 28.1492, 29.6749], dtype=torch.float)\n",
    "pos_weight = pos_weight.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "e9FOwaso3LAc"
   },
   "outputs": [],
   "source": [
    "data_loaders = load_data(images_dir,\n",
    "                         batch_size = batch_size, \n",
    "                         input_size = input_size, \n",
    "                         norm_arr = norm_arr,\n",
    "                         num_workers = num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Active',\n",
       " 'Alert',\n",
       " 'Amazed',\n",
       " 'Amused',\n",
       " 'Calm',\n",
       " 'Cheerful',\n",
       " 'Confident',\n",
       " 'Conscious',\n",
       " 'Creative',\n",
       " 'Eager',\n",
       " 'Educated',\n",
       " 'Emotional',\n",
       " 'Fashionable',\n",
       " 'Feminine',\n",
       " 'Inspired',\n",
       " 'Loving',\n",
       " 'Manly',\n",
       " 'Persuaded',\n",
       " 'Thrifty',\n",
       " 'Youthful']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_loaders['train'].dataset.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_data_loader(data_loaders['train'], (2,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 392
    },
    "id": "vacZgHSCj47u",
    "outputId": "35a65cef-1d6d-4657-ff01-be15854ca24b"
   },
   "source": [
    "plot_data_loader(data_loader['train'], (2,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zRIOYWbV1cnS"
   },
   "source": [
    "plot_data_loader(data_loader['test'], (2,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "znBg5tkd1dXF"
   },
   "source": [
    "plot_data_loader(data_loader['val'], (2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "0rj7Qeg41wLm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params to learn:\n",
      "\t classifier.3.weight\n",
      "\t classifier.3.bias\n"
     ]
    }
   ],
   "source": [
    "#model_pyt = torch.compile(model_pyt)\n",
    "# Send model to GPU\n",
    "model_pyt = model_pyt.to(device)\n",
    "\n",
    "# Find parameters to be updated in this run.\n",
    "# parameters with requires_grad = True.\n",
    "params_to_update = model_pyt.parameters()\n",
    "print(\"Params to learn:\")\n",
    "if feature_extract:\n",
    "    params_to_update = []\n",
    "    for name,param in model_pyt.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            params_to_update.append(param)\n",
    "            print(\"\\t\",name)\n",
    "else:\n",
    "    for name,param in model_pyt.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            print(\"\\t\",name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "A4B1-pfYm0Ea"
   },
   "outputs": [],
   "source": [
    "# 17 min 1 epoch - 128 batch size - inception\n",
    "# Efficientnet b0 - batch 96 - epoch 50 - num_workers 2 - flip, auto cont, sharp - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8wBR8vcG2jcd",
    "outputId": "7d01aa07-d235-4cb6-dfaf-53ce0c5a577d",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "----------\n",
      "Epoch [1/100], Step [100/348], Loss: 1.1874, Accuracy: 86.56%\n",
      "Epoch [1/100], Step [200/348], Loss: 0.6908, Accuracy: 85.78%\n",
      "Epoch [1/100], Step [300/348], Loss: 0.9048, Accuracy: 82.50%\n",
      "train Loss: 0.9026 Acc: 84.70%\n",
      "Epoch [1/100], Step [100/348], Loss: 0.8373, Accuracy: 85.78%\n",
      "val Loss: 0.9438 Acc: 83.96%\n",
      "\n",
      "Epoch 2/100\n",
      "----------\n",
      "Epoch [2/100], Step [100/348], Loss: 0.6757, Accuracy: 81.25%\n",
      "Epoch [2/100], Step [200/348], Loss: 0.8419, Accuracy: 84.06%\n",
      "Epoch [2/100], Step [300/348], Loss: 0.9459, Accuracy: 80.94%\n",
      "train Loss: 0.8839 Acc: 83.41%\n",
      "Epoch [2/100], Step [100/348], Loss: 0.6907, Accuracy: 87.19%\n",
      "val Loss: 0.9818 Acc: 85.16%\n",
      "\n",
      "Epoch 3/100\n",
      "----------\n",
      "Epoch [3/100], Step [100/348], Loss: 0.8125, Accuracy: 82.50%\n",
      "Epoch [3/100], Step [200/348], Loss: 0.8811, Accuracy: 85.31%\n",
      "Epoch [3/100], Step [300/348], Loss: 0.8539, Accuracy: 82.81%\n",
      "train Loss: 0.8930 Acc: 83.33%\n",
      "Epoch [3/100], Step [100/348], Loss: 0.6185, Accuracy: 85.31%\n",
      "val Loss: 0.9950 Acc: 84.65%\n",
      "\n",
      "Epoch 4/100\n",
      "----------\n",
      "Epoch [4/100], Step [100/348], Loss: 0.6972, Accuracy: 82.66%\n",
      "Epoch [4/100], Step [200/348], Loss: 0.8832, Accuracy: 82.81%\n",
      "Epoch [4/100], Step [300/348], Loss: 1.0042, Accuracy: 84.22%\n",
      "train Loss: 0.9041 Acc: 83.29%\n",
      "Epoch [4/100], Step [100/348], Loss: 0.8703, Accuracy: 85.62%\n",
      "val Loss: 1.0589 Acc: 84.59%\n",
      "\n",
      "Epoch 5/100\n",
      "----------\n",
      "Epoch [5/100], Step [100/348], Loss: 1.3564, Accuracy: 86.25%\n",
      "Epoch [5/100], Step [200/348], Loss: 0.6835, Accuracy: 79.69%\n",
      "Epoch [5/100], Step [300/348], Loss: 0.8373, Accuracy: 84.22%\n",
      "train Loss: 0.9191 Acc: 82.99%\n",
      "Epoch [5/100], Step [100/348], Loss: 0.8685, Accuracy: 85.16%\n",
      "val Loss: 1.1102 Acc: 82.48%\n",
      "\n",
      "Epoch 6/100\n",
      "----------\n",
      "Epoch [6/100], Step [100/348], Loss: 0.6205, Accuracy: 85.16%\n",
      "Epoch [6/100], Step [200/348], Loss: 1.1923, Accuracy: 82.03%\n",
      "Epoch [6/100], Step [300/348], Loss: 1.1718, Accuracy: 85.94%\n",
      "train Loss: 0.8960 Acc: 83.11%\n",
      "Epoch [6/100], Step [100/348], Loss: 0.8464, Accuracy: 85.00%\n",
      "val Loss: 1.1310 Acc: 84.69%\n",
      "\n",
      "Epoch 7/100\n",
      "----------\n",
      "Epoch [7/100], Step [100/348], Loss: 0.9292, Accuracy: 83.28%\n",
      "Epoch [7/100], Step [200/348], Loss: 0.7059, Accuracy: 84.84%\n",
      "Epoch [7/100], Step [300/348], Loss: 0.7615, Accuracy: 85.00%\n",
      "train Loss: 0.9227 Acc: 83.12%\n",
      "Epoch [7/100], Step [100/348], Loss: 0.7806, Accuracy: 87.66%\n",
      "val Loss: 1.1407 Acc: 85.91%\n",
      "\n",
      "Epoch 8/100\n",
      "----------\n",
      "Epoch [8/100], Step [100/348], Loss: 0.9795, Accuracy: 82.81%\n",
      "Epoch [8/100], Step [200/348], Loss: 0.5526, Accuracy: 85.62%\n",
      "Epoch [8/100], Step [300/348], Loss: 0.7097, Accuracy: 81.41%\n",
      "train Loss: 0.9244 Acc: 83.22%\n",
      "Epoch [8/100], Step [100/348], Loss: 0.6902, Accuracy: 87.81%\n",
      "val Loss: 1.2109 Acc: 84.82%\n",
      "\n",
      "Epoch 9/100\n",
      "----------\n",
      "Epoch [9/100], Step [100/348], Loss: 0.7813, Accuracy: 82.03%\n",
      "Epoch [9/100], Step [200/348], Loss: 0.5394, Accuracy: 84.53%\n",
      "Epoch [9/100], Step [300/348], Loss: 1.2894, Accuracy: 82.66%\n",
      "train Loss: 0.9186 Acc: 83.09%\n",
      "Epoch [9/100], Step [100/348], Loss: 0.7151, Accuracy: 87.97%\n",
      "val Loss: 1.2019 Acc: 84.93%\n",
      "\n",
      "Epoch 10/100\n",
      "----------\n",
      "Epoch [10/100], Step [100/348], Loss: 0.5979, Accuracy: 82.81%\n",
      "Epoch [10/100], Step [200/348], Loss: 1.0691, Accuracy: 82.34%\n",
      "Epoch [10/100], Step [300/348], Loss: 0.7213, Accuracy: 84.53%\n",
      "train Loss: 0.9244 Acc: 83.31%\n",
      "Epoch [10/100], Step [100/348], Loss: 0.8151, Accuracy: 88.12%\n",
      "val Loss: 1.1596 Acc: 84.52%\n",
      "\n",
      "Epoch 11/100\n",
      "----------\n",
      "Epoch [11/100], Step [100/348], Loss: 1.2506, Accuracy: 82.03%\n",
      "Epoch [11/100], Step [200/348], Loss: 0.9132, Accuracy: 84.69%\n",
      "Epoch [11/100], Step [300/348], Loss: 1.0830, Accuracy: 82.66%\n",
      "train Loss: 0.9153 Acc: 83.12%\n",
      "Epoch [11/100], Step [100/348], Loss: 0.7046, Accuracy: 85.94%\n",
      "val Loss: 1.1443 Acc: 84.31%\n",
      "\n",
      "Epoch 12/100\n",
      "----------\n",
      "Epoch [12/100], Step [100/348], Loss: 0.7979, Accuracy: 79.53%\n",
      "Epoch [12/100], Step [200/348], Loss: 1.1988, Accuracy: 83.59%\n",
      "Epoch [12/100], Step [300/348], Loss: 0.9798, Accuracy: 81.88%\n",
      "train Loss: 0.9149 Acc: 83.37%\n",
      "Epoch [12/100], Step [100/348], Loss: 0.7647, Accuracy: 87.34%\n",
      "val Loss: 1.1758 Acc: 85.13%\n",
      "\n",
      "Epoch 13/100\n",
      "----------\n",
      "Epoch [13/100], Step [100/348], Loss: 0.9149, Accuracy: 81.56%\n",
      "Epoch [13/100], Step [200/348], Loss: 0.9892, Accuracy: 81.56%\n",
      "Epoch [13/100], Step [300/348], Loss: 1.1326, Accuracy: 83.12%\n",
      "train Loss: 0.9434 Acc: 83.18%\n",
      "Epoch [13/100], Step [100/348], Loss: 0.6997, Accuracy: 86.72%\n",
      "val Loss: 1.2061 Acc: 85.59%\n",
      "\n",
      "Epoch 14/100\n",
      "----------\n",
      "Epoch [14/100], Step [100/348], Loss: 0.6752, Accuracy: 82.50%\n",
      "Epoch [14/100], Step [200/348], Loss: 0.9309, Accuracy: 86.09%\n",
      "Epoch [14/100], Step [300/348], Loss: 1.2333, Accuracy: 82.34%\n",
      "train Loss: 0.9314 Acc: 83.23%\n",
      "Epoch [14/100], Step [100/348], Loss: 0.7642, Accuracy: 85.00%\n",
      "val Loss: 1.1483 Acc: 83.52%\n",
      "\n",
      "Epoch 15/100\n",
      "----------\n",
      "Epoch [15/100], Step [100/348], Loss: 0.6674, Accuracy: 84.53%\n",
      "Epoch [15/100], Step [200/348], Loss: 0.8121, Accuracy: 82.66%\n",
      "Epoch [15/100], Step [300/348], Loss: 1.3221, Accuracy: 81.09%\n",
      "train Loss: 0.9214 Acc: 83.53%\n",
      "Epoch [15/100], Step [100/348], Loss: 0.8495, Accuracy: 86.72%\n",
      "val Loss: 1.1813 Acc: 85.28%\n",
      "\n",
      "Epoch 16/100\n",
      "----------\n",
      "Epoch [16/100], Step [100/348], Loss: 0.5312, Accuracy: 81.56%\n",
      "Epoch [16/100], Step [200/348], Loss: 2.0000, Accuracy: 82.19%\n",
      "Epoch [16/100], Step [300/348], Loss: 1.0492, Accuracy: 79.84%\n",
      "train Loss: 0.9074 Acc: 83.49%\n",
      "Epoch [16/100], Step [100/348], Loss: 0.7578, Accuracy: 87.81%\n",
      "val Loss: 1.2124 Acc: 85.02%\n",
      "\n",
      "Epoch 17/100\n",
      "----------\n",
      "Epoch [17/100], Step [100/348], Loss: 0.6538, Accuracy: 87.34%\n",
      "Epoch [17/100], Step [200/348], Loss: 0.7185, Accuracy: 83.75%\n",
      "Epoch [17/100], Step [300/348], Loss: 1.1965, Accuracy: 81.56%\n",
      "train Loss: 0.8911 Acc: 83.74%\n",
      "Epoch [17/100], Step [100/348], Loss: 0.5578, Accuracy: 86.72%\n",
      "val Loss: 1.2103 Acc: 84.37%\n",
      "\n",
      "Epoch 18/100\n",
      "----------\n",
      "Epoch [18/100], Step [100/348], Loss: 0.6567, Accuracy: 85.94%\n",
      "Epoch [18/100], Step [200/348], Loss: 1.3228, Accuracy: 82.81%\n",
      "Epoch [18/100], Step [300/348], Loss: 0.6341, Accuracy: 82.97%\n",
      "train Loss: 0.9097 Acc: 83.68%\n",
      "Epoch [18/100], Step [100/348], Loss: 0.6187, Accuracy: 87.66%\n",
      "val Loss: 1.2183 Acc: 85.02%\n",
      "\n",
      "Epoch 19/100\n",
      "----------\n",
      "Epoch [19/100], Step [100/348], Loss: 1.7828, Accuracy: 82.34%\n",
      "Epoch [19/100], Step [200/348], Loss: 1.1712, Accuracy: 83.91%\n",
      "Epoch [19/100], Step [300/348], Loss: 0.8420, Accuracy: 83.28%\n",
      "train Loss: 0.9175 Acc: 83.48%\n",
      "Epoch [19/100], Step [100/348], Loss: 0.6752, Accuracy: 88.59%\n",
      "val Loss: 1.2209 Acc: 84.53%\n",
      "\n",
      "Epoch 20/100\n",
      "----------\n",
      "Epoch [20/100], Step [100/348], Loss: 1.2470, Accuracy: 85.16%\n",
      "Epoch [20/100], Step [200/348], Loss: 0.7517, Accuracy: 82.50%\n",
      "Epoch [20/100], Step [300/348], Loss: 0.7598, Accuracy: 85.31%\n",
      "train Loss: 0.8861 Acc: 83.73%\n",
      "Epoch [20/100], Step [100/348], Loss: 0.6373, Accuracy: 88.59%\n",
      "val Loss: 1.2714 Acc: 84.44%\n",
      "\n",
      "Epoch 21/100\n",
      "----------\n",
      "Epoch [21/100], Step [100/348], Loss: 0.7166, Accuracy: 84.22%\n",
      "Epoch [21/100], Step [200/348], Loss: 0.8600, Accuracy: 85.00%\n",
      "Epoch [21/100], Step [300/348], Loss: 1.0000, Accuracy: 82.50%\n",
      "train Loss: 0.9160 Acc: 83.73%\n",
      "Epoch [21/100], Step [100/348], Loss: 0.6146, Accuracy: 86.25%\n",
      "val Loss: 1.2378 Acc: 85.03%\n",
      "\n",
      "Epoch 22/100\n",
      "----------\n",
      "Epoch [22/100], Step [100/348], Loss: 0.6401, Accuracy: 85.16%\n",
      "Epoch [22/100], Step [200/348], Loss: 1.5563, Accuracy: 84.22%\n",
      "Epoch [22/100], Step [300/348], Loss: 0.7467, Accuracy: 82.81%\n",
      "train Loss: 0.8943 Acc: 83.75%\n",
      "Epoch [22/100], Step [100/348], Loss: 0.6873, Accuracy: 89.69%\n",
      "val Loss: 1.2019 Acc: 85.82%\n",
      "\n",
      "Epoch 23/100\n",
      "----------\n",
      "Epoch [23/100], Step [100/348], Loss: 0.6135, Accuracy: 84.53%\n",
      "Epoch [23/100], Step [200/348], Loss: 0.8589, Accuracy: 84.53%\n",
      "Epoch [23/100], Step [300/348], Loss: 0.7134, Accuracy: 83.28%\n",
      "train Loss: 0.8901 Acc: 83.95%\n",
      "Epoch [23/100], Step [100/348], Loss: 0.7549, Accuracy: 86.09%\n",
      "val Loss: 1.2306 Acc: 85.06%\n",
      "\n",
      "Epoch 24/100\n",
      "----------\n",
      "Epoch [24/100], Step [100/348], Loss: 0.6634, Accuracy: 81.88%\n",
      "Epoch [24/100], Step [200/348], Loss: 0.5512, Accuracy: 82.34%\n",
      "Epoch [24/100], Step [300/348], Loss: 1.2596, Accuracy: 81.72%\n",
      "train Loss: 0.8899 Acc: 83.83%\n",
      "Epoch [24/100], Step [100/348], Loss: 1.0231, Accuracy: 87.50%\n",
      "val Loss: 1.2655 Acc: 85.59%\n",
      "\n",
      "Epoch 25/100\n",
      "----------\n",
      "Epoch [25/100], Step [100/348], Loss: 0.7822, Accuracy: 82.34%\n",
      "Epoch [25/100], Step [200/348], Loss: 0.9405, Accuracy: 83.75%\n",
      "Epoch [25/100], Step [300/348], Loss: 2.1802, Accuracy: 82.97%\n",
      "train Loss: 0.9051 Acc: 83.64%\n",
      "Epoch [25/100], Step [100/348], Loss: 0.8098, Accuracy: 87.19%\n",
      "val Loss: 1.2586 Acc: 85.57%\n",
      "\n",
      "Epoch 26/100\n",
      "----------\n",
      "Epoch [26/100], Step [100/348], Loss: 0.6500, Accuracy: 83.91%\n",
      "Epoch [26/100], Step [200/348], Loss: 0.9147, Accuracy: 83.75%\n",
      "Epoch [26/100], Step [300/348], Loss: 0.6351, Accuracy: 85.00%\n",
      "train Loss: 0.8777 Acc: 83.96%\n",
      "Epoch [26/100], Step [100/348], Loss: 0.8270, Accuracy: 86.88%\n",
      "val Loss: 1.2738 Acc: 86.36%\n",
      "\n",
      "Epoch 27/100\n",
      "----------\n",
      "Epoch [27/100], Step [100/348], Loss: 0.7150, Accuracy: 80.31%\n",
      "Epoch [27/100], Step [200/348], Loss: 0.8817, Accuracy: 83.28%\n",
      "Epoch [27/100], Step [300/348], Loss: 1.0521, Accuracy: 83.59%\n",
      "train Loss: 0.9116 Acc: 83.82%\n",
      "Epoch [27/100], Step [100/348], Loss: 0.7191, Accuracy: 87.81%\n",
      "val Loss: 1.2178 Acc: 84.66%\n",
      "\n",
      "Epoch 28/100\n",
      "----------\n",
      "Epoch [28/100], Step [100/348], Loss: 0.9430, Accuracy: 83.59%\n",
      "Epoch [28/100], Step [200/348], Loss: 0.8889, Accuracy: 84.84%\n",
      "Epoch [28/100], Step [300/348], Loss: 0.8066, Accuracy: 83.91%\n",
      "train Loss: 0.8869 Acc: 83.98%\n",
      "Epoch [28/100], Step [100/348], Loss: 0.6130, Accuracy: 88.59%\n",
      "val Loss: 1.2995 Acc: 85.42%\n",
      "\n",
      "Epoch 29/100\n",
      "----------\n",
      "Epoch [29/100], Step [100/348], Loss: 0.5446, Accuracy: 86.41%\n",
      "Epoch [29/100], Step [200/348], Loss: 0.8292, Accuracy: 82.97%\n",
      "Epoch [29/100], Step [300/348], Loss: 0.6672, Accuracy: 83.75%\n",
      "train Loss: 0.8680 Acc: 84.25%\n",
      "Epoch [29/100], Step [100/348], Loss: 0.7003, Accuracy: 87.03%\n",
      "val Loss: 1.2214 Acc: 85.20%\n",
      "\n",
      "Epoch 30/100\n",
      "----------\n",
      "Epoch [30/100], Step [100/348], Loss: 0.6134, Accuracy: 86.09%\n",
      "Epoch [30/100], Step [200/348], Loss: 0.5284, Accuracy: 84.69%\n",
      "Epoch [30/100], Step [300/348], Loss: 0.6534, Accuracy: 86.09%\n",
      "train Loss: 0.8801 Acc: 84.14%\n",
      "Epoch [30/100], Step [100/348], Loss: 0.8777, Accuracy: 87.03%\n",
      "val Loss: 1.2369 Acc: 84.85%\n",
      "\n",
      "Epoch 31/100\n",
      "----------\n",
      "Epoch [31/100], Step [100/348], Loss: 1.2805, Accuracy: 83.91%\n",
      "Epoch [31/100], Step [200/348], Loss: 1.3118, Accuracy: 85.00%\n",
      "Epoch [31/100], Step [300/348], Loss: 0.8714, Accuracy: 85.31%\n",
      "train Loss: 0.8791 Acc: 84.09%\n",
      "Epoch [31/100], Step [100/348], Loss: 0.6672, Accuracy: 88.44%\n",
      "val Loss: 1.2703 Acc: 84.77%\n",
      "\n",
      "Epoch 32/100\n",
      "----------\n",
      "Epoch [32/100], Step [100/348], Loss: 0.6710, Accuracy: 85.94%\n",
      "Epoch [32/100], Step [200/348], Loss: 0.7771, Accuracy: 84.53%\n",
      "Epoch [32/100], Step [300/348], Loss: 0.8458, Accuracy: 84.38%\n",
      "train Loss: 0.8666 Acc: 84.18%\n",
      "Epoch [32/100], Step [100/348], Loss: 0.6436, Accuracy: 89.38%\n",
      "val Loss: 1.2555 Acc: 86.51%\n",
      "\n",
      "Epoch 33/100\n",
      "----------\n",
      "Epoch [33/100], Step [100/348], Loss: 1.0837, Accuracy: 86.41%\n",
      "Epoch [33/100], Step [200/348], Loss: 0.6677, Accuracy: 82.34%\n",
      "Epoch [33/100], Step [300/348], Loss: 0.7805, Accuracy: 81.88%\n",
      "train Loss: 0.8677 Acc: 84.07%\n",
      "Epoch [33/100], Step [100/348], Loss: 0.7910, Accuracy: 87.50%\n",
      "val Loss: 1.2683 Acc: 84.95%\n",
      "\n",
      "Epoch 34/100\n",
      "----------\n",
      "Epoch [34/100], Step [100/348], Loss: 0.8338, Accuracy: 82.34%\n",
      "Epoch [34/100], Step [200/348], Loss: 0.9907, Accuracy: 82.66%\n",
      "Epoch [34/100], Step [300/348], Loss: 0.7390, Accuracy: 85.00%\n",
      "train Loss: 0.8681 Acc: 84.17%\n",
      "Epoch [34/100], Step [100/348], Loss: 0.6762, Accuracy: 89.84%\n",
      "val Loss: 1.2488 Acc: 86.97%\n",
      "\n",
      "Epoch 35/100\n",
      "----------\n",
      "Epoch [35/100], Step [100/348], Loss: 0.8983, Accuracy: 81.72%\n",
      "Epoch [35/100], Step [200/348], Loss: 0.7404, Accuracy: 86.09%\n",
      "Epoch [35/100], Step [300/348], Loss: 0.4919, Accuracy: 85.31%\n",
      "train Loss: 0.8429 Acc: 84.51%\n",
      "Epoch [35/100], Step [100/348], Loss: 0.6520, Accuracy: 87.81%\n",
      "val Loss: 1.2998 Acc: 85.79%\n",
      "\n",
      "Epoch 36/100\n",
      "----------\n",
      "Epoch [36/100], Step [100/348], Loss: 0.6654, Accuracy: 87.50%\n",
      "Epoch [36/100], Step [200/348], Loss: 1.3083, Accuracy: 83.59%\n",
      "Epoch [36/100], Step [300/348], Loss: 0.7714, Accuracy: 84.53%\n",
      "train Loss: 0.8568 Acc: 84.53%\n",
      "Epoch [36/100], Step [100/348], Loss: 0.6649, Accuracy: 86.72%\n",
      "val Loss: 1.2415 Acc: 85.15%\n",
      "\n",
      "Epoch 37/100\n",
      "----------\n",
      "Epoch [37/100], Step [100/348], Loss: 0.5341, Accuracy: 83.75%\n",
      "Epoch [37/100], Step [200/348], Loss: 1.0460, Accuracy: 83.75%\n",
      "Epoch [37/100], Step [300/348], Loss: 0.6263, Accuracy: 86.72%\n",
      "train Loss: 0.8489 Acc: 84.41%\n",
      "Epoch [37/100], Step [100/348], Loss: 0.5878, Accuracy: 89.53%\n",
      "val Loss: 1.3243 Acc: 87.37%\n",
      "\n",
      "Epoch 38/100\n",
      "----------\n",
      "Epoch [38/100], Step [100/348], Loss: 0.6315, Accuracy: 87.81%\n",
      "Epoch [38/100], Step [200/348], Loss: 0.5757, Accuracy: 83.28%\n",
      "Epoch [38/100], Step [300/348], Loss: 1.3555, Accuracy: 84.22%\n",
      "train Loss: 0.8378 Acc: 84.78%\n",
      "Epoch [38/100], Step [100/348], Loss: 0.8804, Accuracy: 87.97%\n",
      "val Loss: 1.2907 Acc: 86.49%\n",
      "\n",
      "Epoch 39/100\n",
      "----------\n",
      "Epoch [39/100], Step [100/348], Loss: 0.6726, Accuracy: 84.53%\n",
      "Epoch [39/100], Step [200/348], Loss: 0.5517, Accuracy: 84.69%\n",
      "Epoch [39/100], Step [300/348], Loss: 0.6828, Accuracy: 84.22%\n",
      "train Loss: 0.8490 Acc: 84.76%\n",
      "Epoch [39/100], Step [100/348], Loss: 0.7570, Accuracy: 86.88%\n",
      "val Loss: 1.2719 Acc: 85.57%\n",
      "\n",
      "Epoch 40/100\n",
      "----------\n",
      "Epoch [40/100], Step [100/348], Loss: 0.9496, Accuracy: 85.16%\n",
      "Epoch [40/100], Step [200/348], Loss: 0.9774, Accuracy: 84.53%\n",
      "Epoch [40/100], Step [300/348], Loss: 0.8253, Accuracy: 85.00%\n",
      "train Loss: 0.8397 Acc: 84.56%\n",
      "Epoch [40/100], Step [100/348], Loss: 0.7039, Accuracy: 90.16%\n",
      "val Loss: 1.3066 Acc: 87.46%\n",
      "\n",
      "Epoch 41/100\n",
      "----------\n",
      "Epoch [41/100], Step [100/348], Loss: 1.3930, Accuracy: 85.31%\n",
      "Epoch [41/100], Step [200/348], Loss: 0.4619, Accuracy: 85.00%\n",
      "Epoch [41/100], Step [300/348], Loss: 0.8610, Accuracy: 85.78%\n",
      "train Loss: 0.8278 Acc: 85.03%\n",
      "Epoch [41/100], Step [100/348], Loss: 0.6381, Accuracy: 87.50%\n",
      "val Loss: 1.2428 Acc: 85.13%\n",
      "\n",
      "Epoch 42/100\n",
      "----------\n",
      "Epoch [42/100], Step [100/348], Loss: 1.1442, Accuracy: 85.31%\n",
      "Epoch [42/100], Step [200/348], Loss: 1.6382, Accuracy: 85.94%\n",
      "Epoch [42/100], Step [300/348], Loss: 0.7316, Accuracy: 82.50%\n",
      "train Loss: 0.8174 Acc: 84.92%\n",
      "Epoch [42/100], Step [100/348], Loss: 0.5994, Accuracy: 88.28%\n",
      "val Loss: 1.2854 Acc: 85.60%\n",
      "\n",
      "Epoch 43/100\n",
      "----------\n",
      "Epoch [43/100], Step [100/348], Loss: 0.4408, Accuracy: 88.59%\n",
      "Epoch [43/100], Step [200/348], Loss: 0.5645, Accuracy: 84.22%\n",
      "Epoch [43/100], Step [300/348], Loss: 0.6297, Accuracy: 85.94%\n",
      "train Loss: 0.8046 Acc: 84.97%\n",
      "Epoch [43/100], Step [100/348], Loss: 0.7158, Accuracy: 89.06%\n",
      "val Loss: 1.2731 Acc: 87.14%\n",
      "\n",
      "Epoch 44/100\n",
      "----------\n",
      "Epoch [44/100], Step [100/348], Loss: 0.7178, Accuracy: 85.16%\n",
      "Epoch [44/100], Step [200/348], Loss: 1.2059, Accuracy: 85.62%\n",
      "Epoch [44/100], Step [300/348], Loss: 0.5311, Accuracy: 86.09%\n",
      "train Loss: 0.8243 Acc: 85.18%\n",
      "Epoch [44/100], Step [100/348], Loss: 0.6417, Accuracy: 89.53%\n",
      "val Loss: 1.2078 Acc: 86.24%\n",
      "\n",
      "Epoch 45/100\n",
      "----------\n",
      "Epoch [45/100], Step [100/348], Loss: 0.6928, Accuracy: 86.09%\n",
      "Epoch [45/100], Step [200/348], Loss: 1.0952, Accuracy: 85.47%\n",
      "Epoch [45/100], Step [300/348], Loss: 0.6940, Accuracy: 86.25%\n",
      "train Loss: 0.8112 Acc: 85.02%\n",
      "Epoch [45/100], Step [100/348], Loss: 0.6086, Accuracy: 88.59%\n",
      "val Loss: 1.1926 Acc: 85.98%\n",
      "\n",
      "Epoch 46/100\n",
      "----------\n",
      "Epoch [46/100], Step [100/348], Loss: 0.8600, Accuracy: 84.38%\n",
      "Epoch [46/100], Step [200/348], Loss: 0.9615, Accuracy: 85.31%\n",
      "Epoch [46/100], Step [300/348], Loss: 0.7255, Accuracy: 85.16%\n",
      "train Loss: 0.8160 Acc: 85.17%\n",
      "Epoch [46/100], Step [100/348], Loss: 0.5229, Accuracy: 90.16%\n",
      "val Loss: 1.2327 Acc: 87.22%\n",
      "\n",
      "Epoch 47/100\n",
      "----------\n",
      "Epoch [47/100], Step [100/348], Loss: 0.7179, Accuracy: 87.03%\n",
      "Epoch [47/100], Step [200/348], Loss: 0.7218, Accuracy: 85.31%\n",
      "Epoch [47/100], Step [300/348], Loss: 1.3941, Accuracy: 86.56%\n",
      "train Loss: 0.7998 Acc: 85.24%\n",
      "Epoch [47/100], Step [100/348], Loss: 0.6183, Accuracy: 89.53%\n",
      "val Loss: 1.1937 Acc: 87.25%\n",
      "\n",
      "Epoch 48/100\n",
      "----------\n",
      "Epoch [48/100], Step [100/348], Loss: 0.6702, Accuracy: 86.09%\n",
      "Epoch [48/100], Step [200/348], Loss: 0.7344, Accuracy: 84.69%\n",
      "Epoch [48/100], Step [300/348], Loss: 0.7007, Accuracy: 82.81%\n",
      "train Loss: 0.8226 Acc: 85.17%\n",
      "Epoch [48/100], Step [100/348], Loss: 0.6334, Accuracy: 89.06%\n",
      "val Loss: 1.1558 Acc: 86.35%\n",
      "\n",
      "Epoch 49/100\n",
      "----------\n",
      "Epoch [49/100], Step [100/348], Loss: 0.9750, Accuracy: 85.31%\n",
      "Epoch [49/100], Step [200/348], Loss: 0.8319, Accuracy: 85.31%\n",
      "Epoch [49/100], Step [300/348], Loss: 0.7518, Accuracy: 86.72%\n",
      "train Loss: 0.7898 Acc: 85.41%\n",
      "Epoch [49/100], Step [100/348], Loss: 0.6064, Accuracy: 89.38%\n",
      "val Loss: 1.1557 Acc: 86.69%\n",
      "\n",
      "Epoch 50/100\n",
      "----------\n",
      "Epoch [50/100], Step [100/348], Loss: 0.8104, Accuracy: 85.00%\n",
      "Epoch [50/100], Step [200/348], Loss: 1.3921, Accuracy: 85.94%\n",
      "Epoch [50/100], Step [300/348], Loss: 0.5349, Accuracy: 87.97%\n",
      "train Loss: 0.7798 Acc: 85.64%\n",
      "Epoch [50/100], Step [100/348], Loss: 0.5947, Accuracy: 89.22%\n",
      "val Loss: 1.1410 Acc: 87.22%\n",
      "\n",
      "Epoch 51/100\n",
      "----------\n",
      "Epoch [51/100], Step [100/348], Loss: 0.6732, Accuracy: 85.00%\n",
      "Epoch [51/100], Step [200/348], Loss: 0.7296, Accuracy: 87.19%\n",
      "Epoch [51/100], Step [300/348], Loss: 0.5557, Accuracy: 86.72%\n",
      "train Loss: 0.7717 Acc: 85.68%\n",
      "Epoch [51/100], Step [100/348], Loss: 0.5278, Accuracy: 88.59%\n",
      "val Loss: 1.1475 Acc: 86.50%\n",
      "\n",
      "Epoch 52/100\n",
      "----------\n",
      "Epoch [52/100], Step [100/348], Loss: 1.2359, Accuracy: 84.84%\n",
      "Epoch [52/100], Step [200/348], Loss: 0.7056, Accuracy: 86.41%\n",
      "Epoch [52/100], Step [300/348], Loss: 0.5261, Accuracy: 84.84%\n",
      "train Loss: 0.7816 Acc: 85.53%\n",
      "Epoch [52/100], Step [100/348], Loss: 0.4695, Accuracy: 91.25%\n",
      "val Loss: 1.1975 Acc: 88.25%\n",
      "\n",
      "Epoch 53/100\n",
      "----------\n",
      "Epoch [53/100], Step [100/348], Loss: 0.5479, Accuracy: 84.69%\n",
      "Epoch [53/100], Step [200/348], Loss: 0.8387, Accuracy: 84.22%\n",
      "Epoch [53/100], Step [300/348], Loss: 0.5650, Accuracy: 87.66%\n",
      "train Loss: 0.7837 Acc: 85.61%\n",
      "Epoch [53/100], Step [100/348], Loss: 0.5049, Accuracy: 90.78%\n",
      "val Loss: 1.1157 Acc: 88.08%\n",
      "\n",
      "Epoch 54/100\n",
      "----------\n",
      "Epoch [54/100], Step [100/348], Loss: 0.9552, Accuracy: 85.94%\n",
      "Epoch [54/100], Step [200/348], Loss: 0.7086, Accuracy: 87.34%\n",
      "Epoch [54/100], Step [300/348], Loss: 1.2432, Accuracy: 85.16%\n",
      "train Loss: 0.7441 Acc: 86.23%\n",
      "Epoch [54/100], Step [100/348], Loss: 0.5461, Accuracy: 90.47%\n",
      "val Loss: 1.1211 Acc: 88.24%\n",
      "\n",
      "Epoch 55/100\n",
      "----------\n",
      "Epoch [55/100], Step [100/348], Loss: 0.6929, Accuracy: 86.72%\n",
      "Epoch [55/100], Step [200/348], Loss: 1.1229, Accuracy: 85.62%\n",
      "Epoch [55/100], Step [300/348], Loss: 0.7839, Accuracy: 85.00%\n",
      "train Loss: 0.7586 Acc: 86.01%\n",
      "Epoch [55/100], Step [100/348], Loss: 0.5776, Accuracy: 89.69%\n",
      "val Loss: 1.0939 Acc: 87.58%\n",
      "\n",
      "Epoch 56/100\n",
      "----------\n",
      "Epoch [56/100], Step [100/348], Loss: 0.4765, Accuracy: 87.03%\n",
      "Epoch [56/100], Step [200/348], Loss: 0.4700, Accuracy: 88.28%\n",
      "Epoch [56/100], Step [300/348], Loss: 0.8433, Accuracy: 86.09%\n",
      "train Loss: 0.7616 Acc: 86.07%\n",
      "Epoch [56/100], Step [100/348], Loss: 0.5662, Accuracy: 90.16%\n",
      "val Loss: 1.1022 Acc: 86.78%\n",
      "\n",
      "Epoch 57/100\n",
      "----------\n",
      "Epoch [57/100], Step [100/348], Loss: 0.7958, Accuracy: 87.19%\n",
      "Epoch [57/100], Step [200/348], Loss: 0.7733, Accuracy: 84.38%\n",
      "Epoch [57/100], Step [300/348], Loss: 0.5778, Accuracy: 84.84%\n",
      "train Loss: 0.7615 Acc: 85.92%\n",
      "Epoch [57/100], Step [100/348], Loss: 0.5802, Accuracy: 89.38%\n",
      "val Loss: 1.0808 Acc: 87.28%\n",
      "\n",
      "Epoch 58/100\n",
      "----------\n",
      "Epoch [58/100], Step [100/348], Loss: 1.1510, Accuracy: 85.78%\n",
      "Epoch [58/100], Step [200/348], Loss: 0.7659, Accuracy: 86.56%\n",
      "Epoch [58/100], Step [300/348], Loss: 0.6977, Accuracy: 83.28%\n",
      "train Loss: 0.7741 Acc: 85.96%\n",
      "Epoch [58/100], Step [100/348], Loss: 0.5594, Accuracy: 90.78%\n",
      "val Loss: 1.0998 Acc: 87.55%\n",
      "\n",
      "Epoch 59/100\n",
      "----------\n",
      "Epoch [59/100], Step [100/348], Loss: 0.7206, Accuracy: 85.62%\n",
      "Epoch [59/100], Step [200/348], Loss: 0.5699, Accuracy: 85.94%\n",
      "Epoch [59/100], Step [300/348], Loss: 1.1267, Accuracy: 84.69%\n",
      "train Loss: 0.7436 Acc: 86.37%\n",
      "Epoch [59/100], Step [100/348], Loss: 0.5431, Accuracy: 91.09%\n",
      "val Loss: 1.1195 Acc: 87.74%\n",
      "\n",
      "Epoch 60/100\n",
      "----------\n",
      "Epoch [60/100], Step [100/348], Loss: 0.6102, Accuracy: 85.31%\n",
      "Epoch [60/100], Step [200/348], Loss: 0.5335, Accuracy: 86.25%\n",
      "Epoch [60/100], Step [300/348], Loss: 0.8339, Accuracy: 84.22%\n",
      "train Loss: 0.7297 Acc: 86.26%\n",
      "Epoch [60/100], Step [100/348], Loss: 0.5228, Accuracy: 90.62%\n",
      "val Loss: 1.0900 Acc: 87.36%\n",
      "\n",
      "Epoch 61/100\n",
      "----------\n",
      "Epoch [61/100], Step [100/348], Loss: 1.2515, Accuracy: 85.62%\n",
      "Epoch [61/100], Step [200/348], Loss: 0.6613, Accuracy: 88.44%\n",
      "Epoch [61/100], Step [300/348], Loss: 0.8113, Accuracy: 85.31%\n",
      "train Loss: 0.7280 Acc: 86.64%\n",
      "Epoch [61/100], Step [100/348], Loss: 0.5276, Accuracy: 90.94%\n",
      "val Loss: 1.1230 Acc: 88.79%\n",
      "\n",
      "Epoch 62/100\n",
      "----------\n",
      "Epoch [62/100], Step [100/348], Loss: 0.7097, Accuracy: 86.41%\n",
      "Epoch [62/100], Step [200/348], Loss: 0.7059, Accuracy: 84.38%\n",
      "Epoch [62/100], Step [300/348], Loss: 0.5776, Accuracy: 84.69%\n",
      "train Loss: 0.7198 Acc: 86.57%\n",
      "Epoch [62/100], Step [100/348], Loss: 0.5728, Accuracy: 91.09%\n",
      "val Loss: 1.1338 Acc: 88.63%\n",
      "\n",
      "Epoch 63/100\n",
      "----------\n",
      "Epoch [63/100], Step [100/348], Loss: 0.9751, Accuracy: 86.72%\n",
      "Epoch [63/100], Step [200/348], Loss: 1.0564, Accuracy: 85.78%\n",
      "Epoch [63/100], Step [300/348], Loss: 0.6792, Accuracy: 85.94%\n",
      "train Loss: 0.7264 Acc: 86.55%\n",
      "Epoch [63/100], Step [100/348], Loss: 0.5275, Accuracy: 90.16%\n",
      "val Loss: 1.1353 Acc: 88.70%\n",
      "\n",
      "Epoch 64/100\n",
      "----------\n",
      "Epoch [64/100], Step [100/348], Loss: 0.4842, Accuracy: 85.31%\n",
      "Epoch [64/100], Step [200/348], Loss: 0.6887, Accuracy: 85.78%\n",
      "Epoch [64/100], Step [300/348], Loss: 1.0428, Accuracy: 87.50%\n",
      "train Loss: 0.7201 Acc: 86.83%\n",
      "Epoch [64/100], Step [100/348], Loss: 0.5168, Accuracy: 91.09%\n",
      "val Loss: 1.0733 Acc: 87.70%\n",
      "\n",
      "Epoch 65/100\n",
      "----------\n",
      "Epoch [65/100], Step [100/348], Loss: 0.6415, Accuracy: 85.78%\n",
      "Epoch [65/100], Step [200/348], Loss: 0.6834, Accuracy: 87.50%\n",
      "Epoch [65/100], Step [300/348], Loss: 0.7482, Accuracy: 85.62%\n",
      "train Loss: 0.7210 Acc: 86.71%\n",
      "Epoch [65/100], Step [100/348], Loss: 0.5096, Accuracy: 90.47%\n",
      "val Loss: 1.1082 Acc: 88.23%\n",
      "\n",
      "Epoch 66/100\n",
      "----------\n",
      "Epoch [66/100], Step [100/348], Loss: 0.7112, Accuracy: 88.75%\n",
      "Epoch [66/100], Step [200/348], Loss: 0.6037, Accuracy: 87.50%\n",
      "Epoch [66/100], Step [300/348], Loss: 1.1911, Accuracy: 85.31%\n",
      "train Loss: 0.7091 Acc: 86.93%\n",
      "Epoch [66/100], Step [100/348], Loss: 0.5114, Accuracy: 91.25%\n",
      "val Loss: 1.0323 Acc: 87.71%\n",
      "\n",
      "Epoch 67/100\n",
      "----------\n",
      "Epoch [67/100], Step [100/348], Loss: 0.5081, Accuracy: 88.12%\n",
      "Epoch [67/100], Step [200/348], Loss: 0.6828, Accuracy: 87.66%\n",
      "Epoch [67/100], Step [300/348], Loss: 1.1071, Accuracy: 86.56%\n",
      "train Loss: 0.7108 Acc: 86.94%\n",
      "Epoch [67/100], Step [100/348], Loss: 0.5077, Accuracy: 90.47%\n",
      "val Loss: 1.0478 Acc: 88.26%\n",
      "\n",
      "Epoch 68/100\n",
      "----------\n",
      "Epoch [68/100], Step [100/348], Loss: 0.4421, Accuracy: 88.75%\n",
      "Epoch [68/100], Step [200/348], Loss: 0.4492, Accuracy: 86.72%\n",
      "Epoch [68/100], Step [300/348], Loss: 0.5682, Accuracy: 88.44%\n",
      "train Loss: 0.7078 Acc: 87.03%\n",
      "Epoch [68/100], Step [100/348], Loss: 0.4842, Accuracy: 90.47%\n",
      "val Loss: 1.0763 Acc: 89.54%\n",
      "\n",
      "Epoch 69/100\n",
      "----------\n",
      "Epoch [69/100], Step [100/348], Loss: 0.6697, Accuracy: 84.38%\n",
      "Epoch [69/100], Step [200/348], Loss: 0.5227, Accuracy: 88.75%\n",
      "Epoch [69/100], Step [300/348], Loss: 0.7844, Accuracy: 85.00%\n",
      "train Loss: 0.7074 Acc: 87.08%\n",
      "Epoch [69/100], Step [100/348], Loss: 0.4981, Accuracy: 89.53%\n",
      "val Loss: 1.0468 Acc: 88.59%\n",
      "\n",
      "Epoch 70/100\n",
      "----------\n",
      "Epoch [70/100], Step [100/348], Loss: 0.5397, Accuracy: 87.50%\n",
      "Epoch [70/100], Step [200/348], Loss: 0.6066, Accuracy: 85.47%\n",
      "Epoch [70/100], Step [300/348], Loss: 0.6408, Accuracy: 86.88%\n",
      "train Loss: 0.6931 Acc: 87.13%\n",
      "Epoch [70/100], Step [100/348], Loss: 0.5334, Accuracy: 91.56%\n",
      "val Loss: 1.0872 Acc: 89.11%\n",
      "\n",
      "Epoch 71/100\n",
      "----------\n",
      "Epoch [71/100], Step [100/348], Loss: 1.6951, Accuracy: 88.28%\n",
      "Epoch [71/100], Step [200/348], Loss: 0.5454, Accuracy: 88.75%\n",
      "Epoch [71/100], Step [300/348], Loss: 0.6787, Accuracy: 87.19%\n",
      "train Loss: 0.6990 Acc: 87.40%\n",
      "Epoch [71/100], Step [100/348], Loss: 0.5522, Accuracy: 90.62%\n",
      "val Loss: 1.0152 Acc: 88.57%\n",
      "\n",
      "Epoch 72/100\n",
      "----------\n",
      "Epoch [72/100], Step [100/348], Loss: 0.7323, Accuracy: 85.16%\n",
      "Epoch [72/100], Step [200/348], Loss: 0.6800, Accuracy: 88.44%\n",
      "Epoch [72/100], Step [300/348], Loss: 0.6050, Accuracy: 87.34%\n",
      "train Loss: 0.6854 Acc: 87.45%\n",
      "Epoch [72/100], Step [100/348], Loss: 0.5055, Accuracy: 91.09%\n",
      "val Loss: 1.0187 Acc: 88.53%\n",
      "\n",
      "Epoch 73/100\n",
      "----------\n",
      "Epoch [73/100], Step [100/348], Loss: 0.6490, Accuracy: 88.91%\n",
      "Epoch [73/100], Step [200/348], Loss: 1.0309, Accuracy: 87.03%\n",
      "Epoch [73/100], Step [300/348], Loss: 0.5401, Accuracy: 88.28%\n",
      "train Loss: 0.6858 Acc: 87.44%\n",
      "Epoch [73/100], Step [100/348], Loss: 0.4564, Accuracy: 91.41%\n",
      "val Loss: 1.0368 Acc: 88.93%\n",
      "\n",
      "Epoch 74/100\n",
      "----------\n",
      "Epoch [74/100], Step [100/348], Loss: 1.4719, Accuracy: 86.72%\n",
      "Epoch [74/100], Step [200/348], Loss: 0.5723, Accuracy: 89.53%\n",
      "Epoch [74/100], Step [300/348], Loss: 0.5905, Accuracy: 88.28%\n",
      "train Loss: 0.6851 Acc: 87.62%\n",
      "Epoch [74/100], Step [100/348], Loss: 0.4886, Accuracy: 91.25%\n",
      "val Loss: 1.0148 Acc: 89.14%\n",
      "\n",
      "Epoch 75/100\n",
      "----------\n",
      "Epoch [75/100], Step [100/348], Loss: 0.7838, Accuracy: 89.38%\n",
      "Epoch [75/100], Step [200/348], Loss: 0.7243, Accuracy: 87.97%\n",
      "Epoch [75/100], Step [300/348], Loss: 1.0303, Accuracy: 89.38%\n",
      "train Loss: 0.6818 Acc: 87.71%\n",
      "Epoch [75/100], Step [100/348], Loss: 0.5348, Accuracy: 91.72%\n",
      "val Loss: 1.0249 Acc: 89.75%\n",
      "\n",
      "Epoch 76/100\n",
      "----------\n",
      "Epoch [76/100], Step [100/348], Loss: 0.8346, Accuracy: 87.97%\n",
      "Epoch [76/100], Step [200/348], Loss: 0.6620, Accuracy: 87.97%\n",
      "Epoch [76/100], Step [300/348], Loss: 0.7779, Accuracy: 89.06%\n",
      "train Loss: 0.6711 Acc: 87.78%\n",
      "Epoch [76/100], Step [100/348], Loss: 0.5138, Accuracy: 91.41%\n",
      "val Loss: 1.0261 Acc: 89.42%\n",
      "\n",
      "Epoch 77/100\n",
      "----------\n",
      "Epoch [77/100], Step [100/348], Loss: 0.5549, Accuracy: 87.34%\n",
      "Epoch [77/100], Step [200/348], Loss: 0.4754, Accuracy: 89.69%\n",
      "Epoch [77/100], Step [300/348], Loss: 0.5224, Accuracy: 87.81%\n",
      "train Loss: 0.6649 Acc: 87.96%\n",
      "Epoch [77/100], Step [100/348], Loss: 0.5558, Accuracy: 90.78%\n",
      "val Loss: 1.0091 Acc: 89.14%\n",
      "\n",
      "Epoch 78/100\n",
      "----------\n",
      "Epoch [78/100], Step [100/348], Loss: 0.4758, Accuracy: 87.50%\n",
      "Epoch [78/100], Step [200/348], Loss: 0.6603, Accuracy: 86.72%\n",
      "Epoch [78/100], Step [300/348], Loss: 0.5874, Accuracy: 87.50%\n",
      "train Loss: 0.6597 Acc: 87.74%\n",
      "Epoch [78/100], Step [100/348], Loss: 0.5269, Accuracy: 92.50%\n",
      "val Loss: 1.0303 Acc: 89.53%\n",
      "\n",
      "Epoch 79/100\n",
      "----------\n",
      "Epoch [79/100], Step [100/348], Loss: 0.5235, Accuracy: 88.59%\n",
      "Epoch [79/100], Step [200/348], Loss: 0.5902, Accuracy: 87.66%\n",
      "Epoch [79/100], Step [300/348], Loss: 0.5780, Accuracy: 86.88%\n",
      "train Loss: 0.6659 Acc: 88.05%\n",
      "Epoch [79/100], Step [100/348], Loss: 0.5188, Accuracy: 90.78%\n",
      "val Loss: 1.0090 Acc: 89.33%\n",
      "\n",
      "Epoch 80/100\n",
      "----------\n",
      "Epoch [80/100], Step [100/348], Loss: 0.6641, Accuracy: 90.00%\n",
      "Epoch [80/100], Step [200/348], Loss: 1.3751, Accuracy: 89.38%\n",
      "Epoch [80/100], Step [300/348], Loss: 0.6339, Accuracy: 88.44%\n",
      "train Loss: 0.6559 Acc: 88.06%\n",
      "Epoch [80/100], Step [100/348], Loss: 0.5121, Accuracy: 91.72%\n",
      "val Loss: 0.9927 Acc: 89.53%\n",
      "\n",
      "Epoch 81/100\n",
      "----------\n",
      "Epoch [81/100], Step [100/348], Loss: 1.0879, Accuracy: 85.31%\n",
      "Epoch [81/100], Step [200/348], Loss: 0.6388, Accuracy: 89.22%\n",
      "Epoch [81/100], Step [300/348], Loss: 0.6842, Accuracy: 87.66%\n",
      "train Loss: 0.6462 Acc: 88.17%\n",
      "Epoch [81/100], Step [100/348], Loss: 0.5382, Accuracy: 91.41%\n",
      "val Loss: 0.9966 Acc: 89.76%\n",
      "\n",
      "Epoch 82/100\n",
      "----------\n",
      "Epoch [82/100], Step [100/348], Loss: 0.4162, Accuracy: 87.19%\n",
      "Epoch [82/100], Step [200/348], Loss: 0.5736, Accuracy: 87.97%\n",
      "Epoch [82/100], Step [300/348], Loss: 0.7974, Accuracy: 87.81%\n",
      "train Loss: 0.6504 Acc: 88.26%\n",
      "Epoch [82/100], Step [100/348], Loss: 0.4927, Accuracy: 91.88%\n",
      "val Loss: 0.9866 Acc: 89.68%\n",
      "\n",
      "Epoch 83/100\n",
      "----------\n",
      "Epoch [83/100], Step [100/348], Loss: 0.6623, Accuracy: 86.88%\n",
      "Epoch [83/100], Step [200/348], Loss: 0.7672, Accuracy: 88.28%\n",
      "Epoch [83/100], Step [300/348], Loss: 0.5591, Accuracy: 89.22%\n",
      "train Loss: 0.6531 Acc: 88.25%\n",
      "Epoch [83/100], Step [100/348], Loss: 0.5173, Accuracy: 91.41%\n",
      "val Loss: 0.9813 Acc: 89.25%\n",
      "\n",
      "Epoch 84/100\n",
      "----------\n",
      "Epoch [84/100], Step [100/348], Loss: 0.6132, Accuracy: 87.34%\n",
      "Epoch [84/100], Step [200/348], Loss: 0.7217, Accuracy: 87.97%\n",
      "Epoch [84/100], Step [300/348], Loss: 0.5990, Accuracy: 89.84%\n",
      "train Loss: 0.6519 Acc: 88.32%\n",
      "Epoch [84/100], Step [100/348], Loss: 0.5019, Accuracy: 91.72%\n",
      "val Loss: 0.9705 Acc: 89.49%\n",
      "\n",
      "Epoch 85/100\n",
      "----------\n",
      "Epoch [85/100], Step [100/348], Loss: 1.0779, Accuracy: 86.41%\n",
      "Epoch [85/100], Step [200/348], Loss: 0.5444, Accuracy: 87.19%\n",
      "Epoch [85/100], Step [300/348], Loss: 0.6865, Accuracy: 88.12%\n",
      "train Loss: 0.6477 Acc: 88.33%\n",
      "Epoch [85/100], Step [100/348], Loss: 0.4979, Accuracy: 91.41%\n",
      "val Loss: 0.9768 Acc: 89.38%\n",
      "\n",
      "Epoch 86/100\n",
      "----------\n",
      "Epoch [86/100], Step [100/348], Loss: 0.9798, Accuracy: 85.94%\n",
      "Epoch [86/100], Step [200/348], Loss: 0.5074, Accuracy: 89.69%\n",
      "Epoch [86/100], Step [300/348], Loss: 0.6083, Accuracy: 87.66%\n",
      "train Loss: 0.6391 Acc: 88.54%\n",
      "Epoch [86/100], Step [100/348], Loss: 0.4925, Accuracy: 91.88%\n",
      "val Loss: 0.9872 Acc: 89.85%\n",
      "\n",
      "Epoch 87/100\n",
      "----------\n",
      "Epoch [87/100], Step [100/348], Loss: 0.9169, Accuracy: 87.97%\n",
      "Epoch [87/100], Step [200/348], Loss: 0.5561, Accuracy: 86.56%\n",
      "Epoch [87/100], Step [300/348], Loss: 0.5845, Accuracy: 89.53%\n",
      "train Loss: 0.6426 Acc: 88.55%\n",
      "Epoch [87/100], Step [100/348], Loss: 0.5116, Accuracy: 92.03%\n",
      "val Loss: 0.9791 Acc: 89.82%\n",
      "\n",
      "Epoch 88/100\n",
      "----------\n",
      "Epoch [88/100], Step [100/348], Loss: 0.6615, Accuracy: 90.31%\n",
      "Epoch [88/100], Step [200/348], Loss: 0.5631, Accuracy: 89.22%\n",
      "Epoch [88/100], Step [300/348], Loss: 0.4544, Accuracy: 90.31%\n",
      "train Loss: 0.6345 Acc: 88.56%\n",
      "Epoch [88/100], Step [100/348], Loss: 0.5224, Accuracy: 92.50%\n",
      "val Loss: 0.9920 Acc: 90.22%\n",
      "\n",
      "Epoch 89/100\n",
      "----------\n",
      "Epoch [89/100], Step [100/348], Loss: 0.6928, Accuracy: 88.59%\n",
      "Epoch [89/100], Step [200/348], Loss: 0.5697, Accuracy: 90.78%\n",
      "Epoch [89/100], Step [300/348], Loss: 0.5150, Accuracy: 88.44%\n",
      "train Loss: 0.6406 Acc: 88.70%\n",
      "Epoch [89/100], Step [100/348], Loss: 0.5071, Accuracy: 92.03%\n",
      "val Loss: 0.9727 Acc: 90.02%\n",
      "\n",
      "Epoch 90/100\n",
      "----------\n",
      "Epoch [90/100], Step [100/348], Loss: 0.5241, Accuracy: 90.00%\n",
      "Epoch [90/100], Step [200/348], Loss: 0.5291, Accuracy: 87.50%\n",
      "Epoch [90/100], Step [300/348], Loss: 0.9112, Accuracy: 88.75%\n",
      "train Loss: 0.6491 Acc: 88.49%\n",
      "Epoch [90/100], Step [100/348], Loss: 0.4987, Accuracy: 92.03%\n",
      "val Loss: 0.9535 Acc: 89.77%\n",
      "\n",
      "Epoch 91/100\n",
      "----------\n",
      "Epoch [91/100], Step [100/348], Loss: 0.4811, Accuracy: 88.59%\n",
      "Epoch [91/100], Step [200/348], Loss: 0.7802, Accuracy: 89.84%\n",
      "Epoch [91/100], Step [300/348], Loss: 0.5812, Accuracy: 86.56%\n",
      "train Loss: 0.6468 Acc: 88.64%\n",
      "Epoch [91/100], Step [100/348], Loss: 0.4990, Accuracy: 91.09%\n",
      "val Loss: 0.9547 Acc: 89.66%\n",
      "\n",
      "Epoch 92/100\n",
      "----------\n",
      "Epoch [92/100], Step [100/348], Loss: 0.9905, Accuracy: 88.44%\n",
      "Epoch [92/100], Step [200/348], Loss: 0.4915, Accuracy: 89.84%\n",
      "Epoch [92/100], Step [300/348], Loss: 0.6846, Accuracy: 86.56%\n",
      "train Loss: 0.6234 Acc: 88.73%\n",
      "Epoch [92/100], Step [100/348], Loss: 0.5051, Accuracy: 91.88%\n",
      "val Loss: 0.9704 Acc: 90.16%\n",
      "\n",
      "Epoch 93/100\n",
      "----------\n",
      "Epoch [93/100], Step [100/348], Loss: 0.5015, Accuracy: 89.84%\n",
      "Epoch [93/100], Step [200/348], Loss: 0.6136, Accuracy: 89.22%\n",
      "Epoch [93/100], Step [300/348], Loss: 0.8114, Accuracy: 89.69%\n",
      "train Loss: 0.6367 Acc: 88.92%\n",
      "Epoch [93/100], Step [100/348], Loss: 0.5225, Accuracy: 92.19%\n",
      "val Loss: 0.9599 Acc: 89.88%\n",
      "\n",
      "Epoch 94/100\n",
      "----------\n",
      "Epoch [94/100], Step [100/348], Loss: 0.5966, Accuracy: 90.62%\n",
      "Epoch [94/100], Step [200/348], Loss: 0.6950, Accuracy: 87.97%\n",
      "Epoch [94/100], Step [300/348], Loss: 0.6487, Accuracy: 87.81%\n",
      "train Loss: 0.6249 Acc: 88.68%\n",
      "Epoch [94/100], Step [100/348], Loss: 0.5154, Accuracy: 92.03%\n",
      "val Loss: 0.9712 Acc: 90.19%\n",
      "\n",
      "Epoch 95/100\n",
      "----------\n",
      "Epoch [95/100], Step [100/348], Loss: 1.2124, Accuracy: 90.16%\n",
      "Epoch [95/100], Step [200/348], Loss: 0.6343, Accuracy: 90.47%\n",
      "Epoch [95/100], Step [300/348], Loss: 0.5825, Accuracy: 88.75%\n",
      "train Loss: 0.6324 Acc: 88.74%\n",
      "Epoch [95/100], Step [100/348], Loss: 0.5217, Accuracy: 92.19%\n",
      "val Loss: 0.9654 Acc: 90.26%\n",
      "\n",
      "Epoch 96/100\n",
      "----------\n",
      "Epoch [96/100], Step [100/348], Loss: 0.7874, Accuracy: 88.91%\n",
      "Epoch [96/100], Step [200/348], Loss: 0.5818, Accuracy: 89.84%\n",
      "Epoch [96/100], Step [300/348], Loss: 0.4695, Accuracy: 89.69%\n",
      "train Loss: 0.6330 Acc: 89.07%\n",
      "Epoch [96/100], Step [100/348], Loss: 0.4898, Accuracy: 92.03%\n",
      "val Loss: 0.9487 Acc: 89.96%\n",
      "\n",
      "Epoch 97/100\n",
      "----------\n",
      "Epoch [97/100], Step [100/348], Loss: 0.5878, Accuracy: 88.44%\n",
      "Epoch [97/100], Step [200/348], Loss: 0.5814, Accuracy: 89.38%\n",
      "Epoch [97/100], Step [300/348], Loss: 0.8803, Accuracy: 86.88%\n",
      "train Loss: 0.6291 Acc: 88.80%\n",
      "Epoch [97/100], Step [100/348], Loss: 0.5019, Accuracy: 92.50%\n",
      "val Loss: 0.9496 Acc: 90.09%\n",
      "\n",
      "Epoch 98/100\n",
      "----------\n",
      "Epoch [98/100], Step [100/348], Loss: 0.5439, Accuracy: 90.31%\n",
      "Epoch [98/100], Step [200/348], Loss: 0.6997, Accuracy: 90.16%\n",
      "Epoch [98/100], Step [300/348], Loss: 0.5534, Accuracy: 87.81%\n",
      "train Loss: 0.6289 Acc: 88.75%\n",
      "Epoch [98/100], Step [100/348], Loss: 0.4849, Accuracy: 92.50%\n",
      "val Loss: 0.9546 Acc: 90.41%\n",
      "\n",
      "Epoch 99/100\n",
      "----------\n",
      "Epoch [99/100], Step [100/348], Loss: 0.4815, Accuracy: 86.25%\n",
      "Epoch [99/100], Step [200/348], Loss: 0.5910, Accuracy: 87.19%\n",
      "Epoch [99/100], Step [300/348], Loss: 0.6561, Accuracy: 87.34%\n",
      "train Loss: 0.6244 Acc: 88.93%\n",
      "Epoch [99/100], Step [100/348], Loss: 0.4931, Accuracy: 92.34%\n",
      "val Loss: 0.9428 Acc: 90.13%\n",
      "\n",
      "Epoch 100/100\n",
      "----------\n",
      "Epoch [100/100], Step [100/348], Loss: 0.6424, Accuracy: 87.66%\n",
      "Epoch [100/100], Step [200/348], Loss: 1.1055, Accuracy: 87.97%\n",
      "Epoch [100/100], Step [300/348], Loss: 0.5389, Accuracy: 90.16%\n",
      "train Loss: 0.6130 Acc: 88.97%\n",
      "Epoch [100/100], Step [100/348], Loss: 0.4778, Accuracy: 92.03%\n",
      "val Loss: 0.9496 Acc: 90.30%\n",
      "\n",
      "Training complete in 133m 38s\n",
      "Best val Acc: 0.901266\n",
      "Best loss: 0.942759\n"
     ]
    }
   ],
   "source": [
    "# Observe that all parameters are being optimized\n",
    "optimizer = optim.Adam(params_to_update, lr=lr_start)\n",
    "\n",
    "# Learning rate scheduler.\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs, eta_min=lr_end,\n",
    "                                                 last_epoch=-1)\n",
    "\n",
    "\n",
    "# Setup the loss fxn\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "\n",
    "# Train and evaluate\n",
    "model_pyt, prof, val_history, train_history = train_model(device, model_pyt, data_loaders, \n",
    "                                                            optimizer, scheduler,\n",
    "                                                            criterion, \n",
    "                                                            num_epochs=num_epochs,\n",
    "                                                            num_classes=num_classes,\n",
    "                                                            is_inception=(model_name==\"inceptionv3\"),\n",
    "                                                            profiler=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'ads'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "zM-dorQBJAZb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_model(model_pyt.state_dict(), '../models/', \n",
    "           f'augmented_{model_name}_{dataset_name}_{num_epochs}_{batch_size}_{lr_start}_{lr_end}_model_weights.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_metrics = eval_model(device=device, model=model_pyt, test_loader=data_loaders['test'], is_inception=(model_name==\"inceptionv3\"), num_classes=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 2.5702355295566504\n",
      "f1: 0.1685007280607184\n",
      "cm: [[[3170   29]\n",
      "  [ 461   52]]\n",
      "\n",
      " [[3226  257]\n",
      "  [ 186   43]]\n",
      "\n",
      " [[3472  215]\n",
      "  [  20    5]]\n",
      "\n",
      " [[3513  139]\n",
      "  [  55    5]]\n",
      "\n",
      " [[3441  227]\n",
      "  [  39    5]]\n",
      "\n",
      " [[3384  243]\n",
      "  [  75   10]]\n",
      "\n",
      " [[3487  106]\n",
      "  [ 116    3]]\n",
      "\n",
      " [[3383  258]\n",
      "  [  65    6]]\n",
      "\n",
      " [[2900   27]\n",
      "  [ 758   27]]\n",
      "\n",
      " [[2722   39]\n",
      "  [ 698  253]]\n",
      "\n",
      " [[3281  274]\n",
      "  [ 102   55]]\n",
      "\n",
      " [[3455  236]\n",
      "  [  16    5]]\n",
      "\n",
      " [[2809   82]\n",
      "  [ 503  318]]\n",
      "\n",
      " [[3058  152]\n",
      "  [ 259  243]]\n",
      "\n",
      " [[3246  249]\n",
      "  [ 144   73]]\n",
      "\n",
      " [[3336  355]\n",
      "  [  16    5]]\n",
      "\n",
      " [[3426  157]\n",
      "  [  94   35]]\n",
      "\n",
      " [[3453  171]\n",
      "  [  76   12]]\n",
      "\n",
      " [[3432  221]\n",
      "  [  16   43]]\n",
      "\n",
      " [[3372  284]\n",
      "  [  35   21]]]\n",
      "outputs: [[0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "targets: [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "for i, v in eval_metrics.items():\n",
    "    print(f\"{i}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'../models/val_history_augmented_{model_name}_{dataset_name}_{num_epochs}_{batch_size}_{lr_start}_{lr_end}_.pickle', 'wb') as handle:\n",
    "    pickle.dump(val_history, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open(f'../models/train_history_augmented_{model_name}_{dataset_name}_{num_epochs}_{batch_size}_{lr_start}_{lr_end}_.pickle', 'wb') as handle:\n",
    "    pickle.dump(train_history, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open(f'../models/eval_metrics_augmented_{model_name}_{dataset_name}_{num_epochs}_{batch_size}_{lr_start}_{lr_end}_.pickle', 'wb') as handle:\n",
    "    pickle.dump(eval_metrics, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "#with open('filename.pickle', 'rb') as handle:\n",
    "#    b = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WvFygat_aiDN"
   },
   "outputs": [],
   "source": [
    "#print(prof.key_averages(group_by_stack_n=5).table(sort_by='self_cpu_time_total', row_limit=50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "EQ6hb3iO2mXv"
   },
   "outputs": [],
   "source": [
    "# Plot the training curves of validation accuracy vs. number\n",
    "#  of training epochs for the transfer learning method and\n",
    "#  the model trained from scratch\n",
    "# vhist = []\n",
    "# vhist = [h.cpu().numpy() for h in val_acc_history]\n",
    "# thist = []\n",
    "# thist = [h.cpu().numpy() for h in train_acc_history]\n",
    "\n",
    "# plt.title(\"Accuracy vs. Number of Training Epochs\")\n",
    "# plt.xlabel(\"Training Epochs\")\n",
    "# plt.ylabel(\"Accuracy\")\n",
    "# #plt.plot(range(1,num_epochs+1),ohist,label=\"Pretrained\")\n",
    "# plt.plot(range(1,num_epochs+1),vhist,label=\"Validation\")\n",
    "# plt.plot(range(1,num_epochs+1),thist,label=\"Training\")\n",
    "# plt.ylim((0,1.))\n",
    "# plt.xticks(np.arange(1, num_epochs+1, 1.0))\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "aXpHASjTUE_Q"
   },
   "outputs": [],
   "source": [
    "# Plot the training curves of validation accuracy vs. number\n",
    "#  of training epochs for the transfer learning method and\n",
    "#  the model trained from scratch\n",
    "# vhist = []\n",
    "# vhist = [h for h in val_loss_history]\n",
    "# thist = []\n",
    "# thist = [h for h in train_loss_history]\n",
    "\n",
    "# plt.title(\"Loss vs. Number of Training Epochs\")\n",
    "# plt.xlabel(\"Training Epochs\")\n",
    "# plt.ylabel(\"Loss\")\n",
    "# #plt.plot(range(1,num_epochs+1),ohist,label=\"Pretrained\")\n",
    "# plt.plot(range(1,num_epochs+1),vhist,label=\"Validation\")\n",
    "# plt.plot(range(1,num_epochs+1),thist,label=\"Training\")\n",
    "# plt.ylim((0,1.))\n",
    "# plt.xticks(np.arange(1, num_epochs+1, 1.0))\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3.9.13 ('dl')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "8663be1127523d7121742bbf948a8b1c8dd9a63c15e224e5108ff87b090569d5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
