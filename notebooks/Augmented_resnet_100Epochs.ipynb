{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train for 50 epochs. First use only fine tuning on last layer\n",
    "## Then compare with fine-tuning entire network\n",
    "## TODO: \n",
    "## 0. Pre-process images\n",
    "##      Resize images\n",
    "##      Other pre-processing\n",
    "## 0.1. Check image colors\n",
    "## 1. Get mean and std of dataset - done\n",
    "## Data augmentation?\n",
    "## 2. Train on Resnet-34\n",
    "## 3. Train on efficient net b3 - done\n",
    "## 4. Train on mobilenet v3 large\n",
    "## 5. Write a script to plot loss + accuracy graph\n",
    "## 6. Get FLOPs\n",
    "## 7. Get num layers\n",
    "## 8. Add class weights - done\n",
    "## 9. Implement gradcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from multilabel.train import train_model\n",
    "from model import initialize_model\n",
    "from utils import set_requires_grad, save_model\n",
    "from multilabel.data import load_data\n",
    "from plotting import plot_data_loader\n",
    "from multilabel.eval import eval_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "0w24yf-Tj47H"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import time\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "from numpy.random import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.io import read_image\n",
    "import torchvision.transforms as T\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, models, transforms\n",
    "import torch.autograd.profiler as tprofiler\n",
    "import torch.utils.data as td\n",
    "\n",
    "plt.rcParams[\"savefig.bbox\"] = 'tight'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "O7W8BTtF3BN1"
   },
   "outputs": [],
   "source": [
    "seed = 42\n",
    "\n",
    "random.seed(seed)\n",
    "\n",
    "# pytorch RNGs\n",
    "torch.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "if torch.cuda.is_available(): torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "# numpy RNG\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "21_bts2Wj47M",
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_dir = \"../data\"\n",
    "images_dir = \"../data/processed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "nr7fQfkuj47u"
   },
   "outputs": [],
   "source": [
    "# Get best num_workers\n",
    "# for i in range(97):\n",
    "#     start = time.time()\n",
    "#     data_loader = load_data(images_dir,\n",
    "#                                                                    batch_size = 96, \n",
    "#                                                                    input_size = 299, \n",
    "#                                                                    norm_arr = ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "#                                                                    num_workers = i)\n",
    "#     iter(data_loader['train']).next()[0].shape\n",
    "#     print(f\"{i}: {time.time()-start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "96wB0P9Gj47u"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k-vpcOXE1pmg",
    "outputId": "25752964-a425-490c-d154-0cc8baab3b61"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to C:\\Users\\ro_chopr/.cache\\torch\\hub\\checkpoints\\resnet50-11ad3fa6.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37ff0589f7d942559cfdf07d2c0f85f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/97.8M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check if GPU is available.\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "# Models options: resnet50, resnet34, inceptionv3, vgg16, mobile_net_v3_large, efficient_net_b1, efficient_net_b0, efficient_net_b3.\n",
    "model_name = \"resnet50\"\n",
    "\n",
    "# Number of classes.\n",
    "num_classes = 20\n",
    "\n",
    "# Batch Size.\n",
    "batch_size = 32\n",
    "\n",
    "# Epochs to train for.\n",
    "num_epochs = 100\n",
    "\n",
    "# Number of workers for data loader.\n",
    "num_workers = 12\n",
    "\n",
    "# Imagenet norm array passed as default value.\n",
    "# norm_arr=([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "# Chest x-ray8 training dataset metrics \n",
    "norm_arr=((0.5989, 0.5510, 0.5175), (0.3358, 0.3330, 0.3377))\n",
    "\n",
    "# Feature extract flag: False - Tune the whole model,\n",
    "#                       True - Update only the reshaped layer parameters.\n",
    "feature_extract = True\n",
    "\n",
    "# Use pretrained flag: None - Use random weights\n",
    "#                      String - Use pretrained weights given by String\n",
    "#use_pretrained = models.EfficientNet_B3_Weights.IMAGENET1K_V1\n",
    "#use_pretrained = models.MobileNet_V3_Large_Weights.IMAGENET1K_V\n",
    "use_pretrained = models.ResNet50_Weights.IMAGENET1K_V2\n",
    "\n",
    "# Initialize the model for this run.\n",
    "model_pyt, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=use_pretrained)\n",
    "\n",
    "# lr start and end points for training.\n",
    "lr_start = 0.01\n",
    "lr_end = 0.001\n",
    "\n",
    "# Print the model we just instantiated\n",
    "#print(model_ft)\n",
    "\n",
    "# Positive class weights.\n",
    "pos_weight=torch.as_tensor([ 2.3509,  6.4782, 76.3264, 23.6350, 46.7897, 18.5694, 14.4224, 24.4805,\n",
    "         1.1795,  0.6394,  9.1227, 80.2774,  0.8743,  2.1217,  7.2973, 87.3730,\n",
    "        12.8151, 23.7444, 28.1492, 29.6749], dtype=torch.float)\n",
    "pos_weight = pos_weight.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "e9FOwaso3LAc"
   },
   "outputs": [],
   "source": [
    "data_loaders = load_data(images_dir,\n",
    "                         batch_size = batch_size, \n",
    "                         input_size = input_size, \n",
    "                         norm_arr = norm_arr,\n",
    "                         num_workers = num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Active',\n",
       " 'Alert',\n",
       " 'Amazed',\n",
       " 'Amused',\n",
       " 'Calm',\n",
       " 'Cheerful',\n",
       " 'Confident',\n",
       " 'Conscious',\n",
       " 'Creative',\n",
       " 'Eager',\n",
       " 'Educated',\n",
       " 'Emotional',\n",
       " 'Fashionable',\n",
       " 'Feminine',\n",
       " 'Inspired',\n",
       " 'Loving',\n",
       " 'Manly',\n",
       " 'Persuaded',\n",
       " 'Thrifty',\n",
       " 'Youthful']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_loaders['train'].dataset.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_data_loader(data_loaders['train'], (2,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 392
    },
    "id": "vacZgHSCj47u",
    "outputId": "35a65cef-1d6d-4657-ff01-be15854ca24b"
   },
   "source": [
    "plot_data_loader(data_loader['train'], (2,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zRIOYWbV1cnS"
   },
   "source": [
    "plot_data_loader(data_loader['test'], (2,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "znBg5tkd1dXF"
   },
   "source": [
    "plot_data_loader(data_loader['val'], (2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "0rj7Qeg41wLm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params to learn:\n",
      "\t fc.weight\n",
      "\t fc.bias\n"
     ]
    }
   ],
   "source": [
    "#model_pyt = torch.compile(model_pyt)\n",
    "# Send model to GPU\n",
    "model_pyt = model_pyt.to(device)\n",
    "\n",
    "# Find parameters to be updated in this run.\n",
    "# parameters with requires_grad = True.\n",
    "params_to_update = model_pyt.parameters()\n",
    "print(\"Params to learn:\")\n",
    "if feature_extract:\n",
    "    params_to_update = []\n",
    "    for name,param in model_pyt.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            params_to_update.append(param)\n",
    "            print(\"\\t\",name)\n",
    "else:\n",
    "    for name,param in model_pyt.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            print(\"\\t\",name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "A4B1-pfYm0Ea"
   },
   "outputs": [],
   "source": [
    "# 17 min 1 epoch - 128 batch size - inception\n",
    "# Efficientnet b0 - batch 96 - epoch 50 - num_workers 2 - flip, auto cont, sharp - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8wBR8vcG2jcd",
    "outputId": "7d01aa07-d235-4cb6-dfaf-53ce0c5a577d",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "----------\n",
      "Epoch [1/100], Step [100/348], Loss: 1.2258, Accuracy: 85.31%\n",
      "Epoch [1/100], Step [200/348], Loss: 0.5219, Accuracy: 87.81%\n",
      "Epoch [1/100], Step [300/348], Loss: 0.6134, Accuracy: 85.94%\n",
      "train Loss: 0.9199 Acc: 85.00%\n",
      "Epoch [1/100], Step [100/348], Loss: 0.5358, Accuracy: 89.22%\n",
      "val Loss: 0.8714 Acc: 86.10%\n",
      "\n",
      "Epoch 2/100\n",
      "----------\n",
      "Epoch [2/100], Step [100/348], Loss: 0.4962, Accuracy: 88.75%\n",
      "Epoch [2/100], Step [200/348], Loss: 0.6203, Accuracy: 87.97%\n",
      "Epoch [2/100], Step [300/348], Loss: 0.8580, Accuracy: 82.97%\n",
      "train Loss: 0.7973 Acc: 85.72%\n",
      "Epoch [2/100], Step [100/348], Loss: 0.6478, Accuracy: 86.25%\n",
      "val Loss: 0.9957 Acc: 83.93%\n",
      "\n",
      "Epoch 3/100\n",
      "----------\n",
      "Epoch [3/100], Step [100/348], Loss: 0.8802, Accuracy: 83.75%\n",
      "Epoch [3/100], Step [200/348], Loss: 0.5294, Accuracy: 87.03%\n",
      "Epoch [3/100], Step [300/348], Loss: 0.5793, Accuracy: 88.75%\n",
      "train Loss: 0.7811 Acc: 85.39%\n",
      "Epoch [3/100], Step [100/348], Loss: 0.8004, Accuracy: 85.47%\n",
      "val Loss: 0.9390 Acc: 83.96%\n",
      "\n",
      "Epoch 4/100\n",
      "----------\n",
      "Epoch [4/100], Step [100/348], Loss: 0.4931, Accuracy: 88.28%\n",
      "Epoch [4/100], Step [200/348], Loss: 0.6559, Accuracy: 82.66%\n",
      "Epoch [4/100], Step [300/348], Loss: 0.7329, Accuracy: 87.19%\n",
      "train Loss: 0.7686 Acc: 85.68%\n",
      "Epoch [4/100], Step [100/348], Loss: 0.9102, Accuracy: 85.31%\n",
      "val Loss: 0.9826 Acc: 84.33%\n",
      "\n",
      "Epoch 5/100\n",
      "----------\n",
      "Epoch [5/100], Step [100/348], Loss: 0.8709, Accuracy: 85.47%\n",
      "Epoch [5/100], Step [200/348], Loss: 0.7640, Accuracy: 85.16%\n",
      "Epoch [5/100], Step [300/348], Loss: 0.6310, Accuracy: 87.50%\n",
      "train Loss: 0.7558 Acc: 85.82%\n",
      "Epoch [5/100], Step [100/348], Loss: 1.0078, Accuracy: 87.34%\n",
      "val Loss: 1.0707 Acc: 86.23%\n",
      "\n",
      "Epoch 6/100\n",
      "----------\n",
      "Epoch [6/100], Step [100/348], Loss: 0.5801, Accuracy: 87.34%\n",
      "Epoch [6/100], Step [200/348], Loss: 1.0113, Accuracy: 84.22%\n",
      "Epoch [6/100], Step [300/348], Loss: 0.5423, Accuracy: 86.88%\n",
      "train Loss: 0.7432 Acc: 86.19%\n",
      "Epoch [6/100], Step [100/348], Loss: 1.0368, Accuracy: 88.91%\n",
      "val Loss: 1.0696 Acc: 86.55%\n",
      "\n",
      "Epoch 7/100\n",
      "----------\n",
      "Epoch [7/100], Step [100/348], Loss: 0.5406, Accuracy: 86.25%\n",
      "Epoch [7/100], Step [200/348], Loss: 0.8338, Accuracy: 81.25%\n",
      "Epoch [7/100], Step [300/348], Loss: 1.0601, Accuracy: 82.50%\n",
      "train Loss: 0.7449 Acc: 85.88%\n",
      "Epoch [7/100], Step [100/348], Loss: 1.0257, Accuracy: 87.66%\n",
      "val Loss: 1.1193 Acc: 85.30%\n",
      "\n",
      "Epoch 8/100\n",
      "----------\n",
      "Epoch [8/100], Step [100/348], Loss: 0.5395, Accuracy: 88.75%\n",
      "Epoch [8/100], Step [200/348], Loss: 0.6634, Accuracy: 89.69%\n",
      "Epoch [8/100], Step [300/348], Loss: 0.7357, Accuracy: 85.78%\n",
      "train Loss: 0.7261 Acc: 86.32%\n",
      "Epoch [8/100], Step [100/348], Loss: 0.8351, Accuracy: 85.47%\n",
      "val Loss: 1.1131 Acc: 82.24%\n",
      "\n",
      "Epoch 9/100\n",
      "----------\n",
      "Epoch [9/100], Step [100/348], Loss: 0.8987, Accuracy: 87.81%\n",
      "Epoch [9/100], Step [200/348], Loss: 0.5285, Accuracy: 85.94%\n",
      "Epoch [9/100], Step [300/348], Loss: 0.6472, Accuracy: 84.38%\n",
      "train Loss: 0.7229 Acc: 86.21%\n",
      "Epoch [9/100], Step [100/348], Loss: 0.9680, Accuracy: 88.59%\n",
      "val Loss: 1.1515 Acc: 86.26%\n",
      "\n",
      "Epoch 10/100\n",
      "----------\n",
      "Epoch [10/100], Step [100/348], Loss: 0.9070, Accuracy: 86.72%\n",
      "Epoch [10/100], Step [200/348], Loss: 0.5410, Accuracy: 87.34%\n",
      "Epoch [10/100], Step [300/348], Loss: 0.5530, Accuracy: 86.41%\n",
      "train Loss: 0.7021 Acc: 86.56%\n",
      "Epoch [10/100], Step [100/348], Loss: 0.8296, Accuracy: 89.53%\n",
      "val Loss: 1.2573 Acc: 86.76%\n",
      "\n",
      "Epoch 11/100\n",
      "----------\n",
      "Epoch [11/100], Step [100/348], Loss: 0.5540, Accuracy: 87.66%\n",
      "Epoch [11/100], Step [200/348], Loss: 0.7816, Accuracy: 87.19%\n",
      "Epoch [11/100], Step [300/348], Loss: 0.5412, Accuracy: 84.53%\n",
      "train Loss: 0.7125 Acc: 86.56%\n",
      "Epoch [11/100], Step [100/348], Loss: 1.0766, Accuracy: 89.38%\n",
      "val Loss: 1.1844 Acc: 86.75%\n",
      "\n",
      "Epoch 12/100\n",
      "----------\n",
      "Epoch [12/100], Step [100/348], Loss: 0.7675, Accuracy: 83.59%\n",
      "Epoch [12/100], Step [200/348], Loss: 0.7039, Accuracy: 83.91%\n",
      "Epoch [12/100], Step [300/348], Loss: 0.8887, Accuracy: 87.66%\n",
      "train Loss: 0.6967 Acc: 86.61%\n",
      "Epoch [12/100], Step [100/348], Loss: 0.8116, Accuracy: 90.47%\n",
      "val Loss: 1.2733 Acc: 87.28%\n",
      "\n",
      "Epoch 13/100\n",
      "----------\n",
      "Epoch [13/100], Step [100/348], Loss: 0.7939, Accuracy: 83.44%\n",
      "Epoch [13/100], Step [200/348], Loss: 0.8150, Accuracy: 87.50%\n",
      "Epoch [13/100], Step [300/348], Loss: 0.8436, Accuracy: 85.94%\n",
      "train Loss: 0.6997 Acc: 86.56%\n",
      "Epoch [13/100], Step [100/348], Loss: 0.8973, Accuracy: 87.97%\n",
      "val Loss: 1.2487 Acc: 85.19%\n",
      "\n",
      "Epoch 14/100\n",
      "----------\n",
      "Epoch [14/100], Step [100/348], Loss: 0.5496, Accuracy: 87.34%\n",
      "Epoch [14/100], Step [200/348], Loss: 1.3773, Accuracy: 88.44%\n",
      "Epoch [14/100], Step [300/348], Loss: 0.7068, Accuracy: 84.22%\n",
      "train Loss: 0.7100 Acc: 86.52%\n",
      "Epoch [14/100], Step [100/348], Loss: 1.0110, Accuracy: 88.28%\n",
      "val Loss: 1.2427 Acc: 85.47%\n",
      "\n",
      "Epoch 15/100\n",
      "----------\n",
      "Epoch [15/100], Step [100/348], Loss: 0.5394, Accuracy: 87.81%\n",
      "Epoch [15/100], Step [200/348], Loss: 0.6795, Accuracy: 85.47%\n",
      "Epoch [15/100], Step [300/348], Loss: 0.6512, Accuracy: 85.00%\n",
      "train Loss: 0.6886 Acc: 86.67%\n",
      "Epoch [15/100], Step [100/348], Loss: 1.0896, Accuracy: 87.19%\n",
      "val Loss: 1.2632 Acc: 84.14%\n",
      "\n",
      "Epoch 16/100\n",
      "----------\n",
      "Epoch [16/100], Step [100/348], Loss: 0.8485, Accuracy: 87.03%\n",
      "Epoch [16/100], Step [200/348], Loss: 0.5492, Accuracy: 88.28%\n",
      "Epoch [16/100], Step [300/348], Loss: 0.4272, Accuracy: 87.66%\n",
      "train Loss: 0.6878 Acc: 86.61%\n",
      "Epoch [16/100], Step [100/348], Loss: 1.0318, Accuracy: 88.59%\n",
      "val Loss: 1.3215 Acc: 84.98%\n",
      "\n",
      "Epoch 17/100\n",
      "----------\n",
      "Epoch [17/100], Step [100/348], Loss: 0.4689, Accuracy: 88.91%\n",
      "Epoch [17/100], Step [200/348], Loss: 0.6727, Accuracy: 89.06%\n",
      "Epoch [17/100], Step [300/348], Loss: 0.6717, Accuracy: 85.47%\n",
      "train Loss: 0.6855 Acc: 86.70%\n",
      "Epoch [17/100], Step [100/348], Loss: 1.0022, Accuracy: 88.44%\n",
      "val Loss: 1.2713 Acc: 86.22%\n",
      "\n",
      "Epoch 18/100\n",
      "----------\n",
      "Epoch [18/100], Step [100/348], Loss: 0.5555, Accuracy: 86.56%\n",
      "Epoch [18/100], Step [200/348], Loss: 0.5153, Accuracy: 86.25%\n",
      "Epoch [18/100], Step [300/348], Loss: 0.5974, Accuracy: 84.84%\n",
      "train Loss: 0.7050 Acc: 86.71%\n",
      "Epoch [18/100], Step [100/348], Loss: 1.0137, Accuracy: 88.59%\n",
      "val Loss: 1.3847 Acc: 87.14%\n",
      "\n",
      "Epoch 19/100\n",
      "----------\n",
      "Epoch [19/100], Step [100/348], Loss: 0.4385, Accuracy: 88.91%\n",
      "Epoch [19/100], Step [200/348], Loss: 1.3075, Accuracy: 87.03%\n",
      "Epoch [19/100], Step [300/348], Loss: 0.5918, Accuracy: 84.38%\n",
      "train Loss: 0.7072 Acc: 86.81%\n",
      "Epoch [19/100], Step [100/348], Loss: 1.1324, Accuracy: 90.16%\n",
      "val Loss: 1.4273 Acc: 87.12%\n",
      "\n",
      "Epoch 20/100\n",
      "----------\n",
      "Epoch [20/100], Step [100/348], Loss: 0.4853, Accuracy: 87.81%\n",
      "Epoch [20/100], Step [200/348], Loss: 0.6358, Accuracy: 84.84%\n",
      "Epoch [20/100], Step [300/348], Loss: 0.6509, Accuracy: 85.62%\n",
      "train Loss: 0.6900 Acc: 86.67%\n",
      "Epoch [20/100], Step [100/348], Loss: 1.1967, Accuracy: 88.12%\n",
      "val Loss: 1.3646 Acc: 85.01%\n",
      "\n",
      "Epoch 21/100\n",
      "----------\n",
      "Epoch [21/100], Step [100/348], Loss: 1.0620, Accuracy: 87.50%\n",
      "Epoch [21/100], Step [200/348], Loss: 0.6870, Accuracy: 86.09%\n",
      "Epoch [21/100], Step [300/348], Loss: 0.6895, Accuracy: 85.00%\n",
      "train Loss: 0.6894 Acc: 86.81%\n",
      "Epoch [21/100], Step [100/348], Loss: 0.8263, Accuracy: 89.06%\n",
      "val Loss: 1.4012 Acc: 87.48%\n",
      "\n",
      "Epoch 22/100\n",
      "----------\n",
      "Epoch [22/100], Step [100/348], Loss: 0.5688, Accuracy: 87.50%\n",
      "Epoch [22/100], Step [200/348], Loss: 0.4602, Accuracy: 86.41%\n",
      "Epoch [22/100], Step [300/348], Loss: 0.5545, Accuracy: 86.41%\n",
      "train Loss: 0.6798 Acc: 87.03%\n",
      "Epoch [22/100], Step [100/348], Loss: 0.8126, Accuracy: 89.53%\n",
      "val Loss: 1.3951 Acc: 87.62%\n",
      "\n",
      "Epoch 23/100\n",
      "----------\n",
      "Epoch [23/100], Step [100/348], Loss: 0.8016, Accuracy: 85.47%\n",
      "Epoch [23/100], Step [200/348], Loss: 0.6979, Accuracy: 85.62%\n",
      "Epoch [23/100], Step [300/348], Loss: 0.9181, Accuracy: 81.25%\n",
      "train Loss: 0.6889 Acc: 86.79%\n",
      "Epoch [23/100], Step [100/348], Loss: 1.0642, Accuracy: 87.50%\n",
      "val Loss: 1.3479 Acc: 86.21%\n",
      "\n",
      "Epoch 24/100\n",
      "----------\n",
      "Epoch [24/100], Step [100/348], Loss: 0.6338, Accuracy: 90.16%\n",
      "Epoch [24/100], Step [200/348], Loss: 0.5920, Accuracy: 87.19%\n",
      "Epoch [24/100], Step [300/348], Loss: 0.5528, Accuracy: 86.25%\n",
      "train Loss: 0.6719 Acc: 87.12%\n",
      "Epoch [24/100], Step [100/348], Loss: 0.8848, Accuracy: 87.81%\n",
      "val Loss: 1.3820 Acc: 86.16%\n",
      "\n",
      "Epoch 25/100\n",
      "----------\n",
      "Epoch [25/100], Step [100/348], Loss: 0.5034, Accuracy: 87.66%\n",
      "Epoch [25/100], Step [200/348], Loss: 0.5341, Accuracy: 85.62%\n",
      "Epoch [25/100], Step [300/348], Loss: 0.3506, Accuracy: 89.84%\n",
      "train Loss: 0.6750 Acc: 87.27%\n",
      "Epoch [25/100], Step [100/348], Loss: 0.9058, Accuracy: 90.16%\n",
      "val Loss: 1.5523 Acc: 88.99%\n",
      "\n",
      "Epoch 26/100\n",
      "----------\n",
      "Epoch [26/100], Step [100/348], Loss: 0.5905, Accuracy: 85.16%\n",
      "Epoch [26/100], Step [200/348], Loss: 0.9162, Accuracy: 89.22%\n",
      "Epoch [26/100], Step [300/348], Loss: 0.7555, Accuracy: 83.12%\n",
      "train Loss: 0.6725 Acc: 87.03%\n",
      "Epoch [26/100], Step [100/348], Loss: 0.9067, Accuracy: 87.34%\n",
      "val Loss: 1.3784 Acc: 86.77%\n",
      "\n",
      "Epoch 27/100\n",
      "----------\n",
      "Epoch [27/100], Step [100/348], Loss: 0.6520, Accuracy: 87.81%\n",
      "Epoch [27/100], Step [200/348], Loss: 0.9177, Accuracy: 84.69%\n",
      "Epoch [27/100], Step [300/348], Loss: 0.8934, Accuracy: 86.56%\n",
      "train Loss: 0.6832 Acc: 87.06%\n",
      "Epoch [27/100], Step [100/348], Loss: 0.8794, Accuracy: 87.81%\n",
      "val Loss: 1.3830 Acc: 85.75%\n",
      "\n",
      "Epoch 28/100\n",
      "----------\n",
      "Epoch [28/100], Step [100/348], Loss: 0.6311, Accuracy: 88.75%\n",
      "Epoch [28/100], Step [200/348], Loss: 0.5982, Accuracy: 85.78%\n",
      "Epoch [28/100], Step [300/348], Loss: 0.4763, Accuracy: 86.25%\n",
      "train Loss: 0.6720 Acc: 87.10%\n",
      "Epoch [28/100], Step [100/348], Loss: 1.1831, Accuracy: 88.75%\n",
      "val Loss: 1.4806 Acc: 87.79%\n",
      "\n",
      "Epoch 29/100\n",
      "----------\n",
      "Epoch [29/100], Step [100/348], Loss: 0.6590, Accuracy: 85.78%\n",
      "Epoch [29/100], Step [200/348], Loss: 0.6099, Accuracy: 88.59%\n",
      "Epoch [29/100], Step [300/348], Loss: 1.1370, Accuracy: 87.97%\n",
      "train Loss: 0.6631 Acc: 87.25%\n",
      "Epoch [29/100], Step [100/348], Loss: 0.9586, Accuracy: 90.31%\n",
      "val Loss: 1.4758 Acc: 87.80%\n",
      "\n",
      "Epoch 30/100\n",
      "----------\n",
      "Epoch [30/100], Step [100/348], Loss: 0.7855, Accuracy: 89.69%\n",
      "Epoch [30/100], Step [200/348], Loss: 0.6057, Accuracy: 86.09%\n",
      "Epoch [30/100], Step [300/348], Loss: 0.6597, Accuracy: 87.19%\n",
      "train Loss: 0.6626 Acc: 87.17%\n",
      "Epoch [30/100], Step [100/348], Loss: 0.8007, Accuracy: 88.75%\n",
      "val Loss: 1.4031 Acc: 86.38%\n",
      "\n",
      "Epoch 31/100\n",
      "----------\n",
      "Epoch [31/100], Step [100/348], Loss: 0.8660, Accuracy: 84.69%\n",
      "Epoch [31/100], Step [200/348], Loss: 0.5109, Accuracy: 85.31%\n",
      "Epoch [31/100], Step [300/348], Loss: 0.5211, Accuracy: 87.97%\n",
      "train Loss: 0.6508 Acc: 87.35%\n",
      "Epoch [31/100], Step [100/348], Loss: 0.8360, Accuracy: 87.81%\n",
      "val Loss: 1.3938 Acc: 86.72%\n",
      "\n",
      "Epoch 32/100\n",
      "----------\n",
      "Epoch [32/100], Step [100/348], Loss: 0.8829, Accuracy: 86.56%\n",
      "Epoch [32/100], Step [200/348], Loss: 0.4854, Accuracy: 88.12%\n",
      "Epoch [32/100], Step [300/348], Loss: 0.5750, Accuracy: 89.22%\n",
      "train Loss: 0.6392 Acc: 87.50%\n",
      "Epoch [32/100], Step [100/348], Loss: 0.7331, Accuracy: 88.28%\n",
      "val Loss: 1.3683 Acc: 86.51%\n",
      "\n",
      "Epoch 33/100\n",
      "----------\n",
      "Epoch [33/100], Step [100/348], Loss: 0.7172, Accuracy: 86.72%\n",
      "Epoch [33/100], Step [200/348], Loss: 1.6901, Accuracy: 88.59%\n",
      "Epoch [33/100], Step [300/348], Loss: 0.5709, Accuracy: 88.28%\n",
      "train Loss: 0.6733 Acc: 87.34%\n",
      "Epoch [33/100], Step [100/348], Loss: 0.9726, Accuracy: 86.56%\n",
      "val Loss: 1.3891 Acc: 84.41%\n",
      "\n",
      "Epoch 34/100\n",
      "----------\n",
      "Epoch [34/100], Step [100/348], Loss: 0.5611, Accuracy: 85.78%\n",
      "Epoch [34/100], Step [200/348], Loss: 0.6757, Accuracy: 86.09%\n",
      "Epoch [34/100], Step [300/348], Loss: 0.9278, Accuracy: 84.38%\n",
      "train Loss: 0.6540 Acc: 87.42%\n",
      "Epoch [34/100], Step [100/348], Loss: 0.8526, Accuracy: 89.06%\n",
      "val Loss: 1.4639 Acc: 86.06%\n",
      "\n",
      "Epoch 35/100\n",
      "----------\n",
      "Epoch [35/100], Step [100/348], Loss: 0.7581, Accuracy: 88.12%\n",
      "Epoch [35/100], Step [200/348], Loss: 0.4342, Accuracy: 90.00%\n",
      "Epoch [35/100], Step [300/348], Loss: 0.6398, Accuracy: 89.22%\n",
      "train Loss: 0.6340 Acc: 87.59%\n",
      "Epoch [35/100], Step [100/348], Loss: 0.8076, Accuracy: 89.53%\n",
      "val Loss: 1.4190 Acc: 87.23%\n",
      "\n",
      "Epoch 36/100\n",
      "----------\n",
      "Epoch [36/100], Step [100/348], Loss: 0.3942, Accuracy: 89.06%\n",
      "Epoch [36/100], Step [200/348], Loss: 0.6364, Accuracy: 85.62%\n",
      "Epoch [36/100], Step [300/348], Loss: 0.6434, Accuracy: 87.50%\n",
      "train Loss: 0.6508 Acc: 87.44%\n",
      "Epoch [36/100], Step [100/348], Loss: 0.8160, Accuracy: 88.28%\n",
      "val Loss: 1.3557 Acc: 86.66%\n",
      "\n",
      "Epoch 37/100\n",
      "----------\n",
      "Epoch [37/100], Step [100/348], Loss: 0.8654, Accuracy: 88.28%\n",
      "Epoch [37/100], Step [200/348], Loss: 0.8832, Accuracy: 86.41%\n",
      "Epoch [37/100], Step [300/348], Loss: 0.3921, Accuracy: 87.81%\n",
      "train Loss: 0.6357 Acc: 87.62%\n",
      "Epoch [37/100], Step [100/348], Loss: 0.9638, Accuracy: 88.44%\n",
      "val Loss: 1.4794 Acc: 86.89%\n",
      "\n",
      "Epoch 38/100\n",
      "----------\n",
      "Epoch [38/100], Step [100/348], Loss: 0.4458, Accuracy: 90.78%\n",
      "Epoch [38/100], Step [200/348], Loss: 0.7732, Accuracy: 86.72%\n",
      "Epoch [38/100], Step [300/348], Loss: 0.6211, Accuracy: 85.94%\n",
      "train Loss: 0.6367 Acc: 87.75%\n",
      "Epoch [38/100], Step [100/348], Loss: 0.7599, Accuracy: 88.75%\n",
      "val Loss: 1.4188 Acc: 86.46%\n",
      "\n",
      "Epoch 39/100\n",
      "----------\n",
      "Epoch [39/100], Step [100/348], Loss: 0.6762, Accuracy: 88.28%\n",
      "Epoch [39/100], Step [200/348], Loss: 0.9578, Accuracy: 87.50%\n",
      "Epoch [39/100], Step [300/348], Loss: 0.6254, Accuracy: 87.03%\n",
      "train Loss: 0.6250 Acc: 87.66%\n",
      "Epoch [39/100], Step [100/348], Loss: 0.8471, Accuracy: 89.22%\n",
      "val Loss: 1.5471 Acc: 87.68%\n",
      "\n",
      "Epoch 40/100\n",
      "----------\n",
      "Epoch [40/100], Step [100/348], Loss: 0.8396, Accuracy: 90.62%\n",
      "Epoch [40/100], Step [200/348], Loss: 0.5346, Accuracy: 86.88%\n",
      "Epoch [40/100], Step [300/348], Loss: 0.9056, Accuracy: 88.28%\n",
      "train Loss: 0.6282 Acc: 87.70%\n",
      "Epoch [40/100], Step [100/348], Loss: 0.9668, Accuracy: 90.94%\n",
      "val Loss: 1.5027 Acc: 87.41%\n",
      "\n",
      "Epoch 41/100\n",
      "----------\n",
      "Epoch [41/100], Step [100/348], Loss: 0.4725, Accuracy: 87.66%\n",
      "Epoch [41/100], Step [200/348], Loss: 0.6568, Accuracy: 84.22%\n",
      "Epoch [41/100], Step [300/348], Loss: 0.5858, Accuracy: 86.56%\n",
      "train Loss: 0.6439 Acc: 87.61%\n",
      "Epoch [41/100], Step [100/348], Loss: 0.7481, Accuracy: 90.47%\n",
      "val Loss: 1.5562 Acc: 87.77%\n",
      "\n",
      "Epoch 42/100\n",
      "----------\n",
      "Epoch [42/100], Step [100/348], Loss: 0.4543, Accuracy: 88.59%\n",
      "Epoch [42/100], Step [200/348], Loss: 0.9564, Accuracy: 85.31%\n",
      "Epoch [42/100], Step [300/348], Loss: 1.1742, Accuracy: 88.75%\n",
      "train Loss: 0.6320 Acc: 87.72%\n",
      "Epoch [42/100], Step [100/348], Loss: 0.9953, Accuracy: 90.31%\n",
      "val Loss: 1.6181 Acc: 88.37%\n",
      "\n",
      "Epoch 43/100\n",
      "----------\n",
      "Epoch [43/100], Step [100/348], Loss: 0.6549, Accuracy: 86.88%\n",
      "Epoch [43/100], Step [200/348], Loss: 0.7006, Accuracy: 84.38%\n",
      "Epoch [43/100], Step [300/348], Loss: 0.5444, Accuracy: 86.41%\n",
      "train Loss: 0.6287 Acc: 87.86%\n",
      "Epoch [43/100], Step [100/348], Loss: 0.9083, Accuracy: 89.69%\n",
      "val Loss: 1.4645 Acc: 87.24%\n",
      "\n",
      "Epoch 44/100\n",
      "----------\n",
      "Epoch [44/100], Step [100/348], Loss: 0.4588, Accuracy: 90.31%\n",
      "Epoch [44/100], Step [200/348], Loss: 0.5617, Accuracy: 85.78%\n",
      "Epoch [44/100], Step [300/348], Loss: 0.5231, Accuracy: 85.94%\n",
      "train Loss: 0.6092 Acc: 88.06%\n",
      "Epoch [44/100], Step [100/348], Loss: 0.9889, Accuracy: 89.06%\n",
      "val Loss: 1.4510 Acc: 87.55%\n",
      "\n",
      "Epoch 45/100\n",
      "----------\n",
      "Epoch [45/100], Step [100/348], Loss: 0.7775, Accuracy: 87.66%\n",
      "Epoch [45/100], Step [200/348], Loss: 0.4936, Accuracy: 88.91%\n",
      "Epoch [45/100], Step [300/348], Loss: 0.7103, Accuracy: 86.41%\n",
      "train Loss: 0.6209 Acc: 87.80%\n",
      "Epoch [45/100], Step [100/348], Loss: 0.8801, Accuracy: 90.62%\n",
      "val Loss: 1.3954 Acc: 86.49%\n",
      "\n",
      "Epoch 46/100\n",
      "----------\n",
      "Epoch [46/100], Step [100/348], Loss: 0.4632, Accuracy: 88.12%\n",
      "Epoch [46/100], Step [200/348], Loss: 0.8803, Accuracy: 89.22%\n",
      "Epoch [46/100], Step [300/348], Loss: 0.3630, Accuracy: 88.91%\n",
      "train Loss: 0.6027 Acc: 88.09%\n",
      "Epoch [46/100], Step [100/348], Loss: 0.8837, Accuracy: 88.59%\n",
      "val Loss: 1.4823 Acc: 86.80%\n",
      "\n",
      "Epoch 47/100\n",
      "----------\n",
      "Epoch [47/100], Step [100/348], Loss: 0.4449, Accuracy: 91.41%\n",
      "Epoch [47/100], Step [200/348], Loss: 0.7426, Accuracy: 85.31%\n",
      "Epoch [47/100], Step [300/348], Loss: 0.6897, Accuracy: 86.09%\n",
      "train Loss: 0.5920 Acc: 88.27%\n",
      "Epoch [47/100], Step [100/348], Loss: 0.8069, Accuracy: 90.62%\n",
      "val Loss: 1.4707 Acc: 87.51%\n",
      "\n",
      "Epoch 48/100\n",
      "----------\n",
      "Epoch [48/100], Step [100/348], Loss: 1.1865, Accuracy: 88.28%\n",
      "Epoch [48/100], Step [200/348], Loss: 0.4152, Accuracy: 87.50%\n",
      "Epoch [48/100], Step [300/348], Loss: 0.5046, Accuracy: 84.53%\n",
      "train Loss: 0.6034 Acc: 88.09%\n",
      "Epoch [48/100], Step [100/348], Loss: 0.8782, Accuracy: 88.59%\n",
      "val Loss: 1.4264 Acc: 87.51%\n",
      "\n",
      "Epoch 49/100\n",
      "----------\n",
      "Epoch [49/100], Step [100/348], Loss: 0.4742, Accuracy: 89.84%\n",
      "Epoch [49/100], Step [200/348], Loss: 0.4169, Accuracy: 87.03%\n",
      "Epoch [49/100], Step [300/348], Loss: 0.8752, Accuracy: 86.72%\n",
      "train Loss: 0.6013 Acc: 88.35%\n",
      "Epoch [49/100], Step [100/348], Loss: 0.7306, Accuracy: 89.84%\n",
      "val Loss: 1.4531 Acc: 87.42%\n",
      "\n",
      "Epoch 50/100\n",
      "----------\n",
      "Epoch [50/100], Step [100/348], Loss: 0.5348, Accuracy: 88.75%\n",
      "Epoch [50/100], Step [200/348], Loss: 0.8519, Accuracy: 87.03%\n",
      "Epoch [50/100], Step [300/348], Loss: 0.5314, Accuracy: 91.56%\n",
      "train Loss: 0.5743 Acc: 88.49%\n",
      "Epoch [50/100], Step [100/348], Loss: 0.9138, Accuracy: 90.47%\n",
      "val Loss: 1.5957 Acc: 88.62%\n",
      "\n",
      "Epoch 51/100\n",
      "----------\n",
      "Epoch [51/100], Step [100/348], Loss: 0.5899, Accuracy: 86.09%\n",
      "Epoch [51/100], Step [200/348], Loss: 0.6641, Accuracy: 87.97%\n",
      "Epoch [51/100], Step [300/348], Loss: 0.7979, Accuracy: 87.66%\n",
      "train Loss: 0.5989 Acc: 88.21%\n",
      "Epoch [51/100], Step [100/348], Loss: 0.8757, Accuracy: 92.19%\n",
      "val Loss: 1.4174 Acc: 89.19%\n",
      "\n",
      "Epoch 52/100\n",
      "----------\n",
      "Epoch [52/100], Step [100/348], Loss: 0.3589, Accuracy: 89.22%\n",
      "Epoch [52/100], Step [200/348], Loss: 0.4731, Accuracy: 87.50%\n",
      "Epoch [52/100], Step [300/348], Loss: 0.8903, Accuracy: 88.91%\n",
      "train Loss: 0.5756 Acc: 88.46%\n",
      "Epoch [52/100], Step [100/348], Loss: 0.8027, Accuracy: 89.69%\n",
      "val Loss: 1.4429 Acc: 87.91%\n",
      "\n",
      "Epoch 53/100\n",
      "----------\n",
      "Epoch [53/100], Step [100/348], Loss: 0.3983, Accuracy: 87.50%\n",
      "Epoch [53/100], Step [200/348], Loss: 0.4616, Accuracy: 88.28%\n",
      "Epoch [53/100], Step [300/348], Loss: 0.6732, Accuracy: 86.88%\n",
      "train Loss: 0.5694 Acc: 88.63%\n",
      "Epoch [53/100], Step [100/348], Loss: 0.7096, Accuracy: 89.06%\n",
      "val Loss: 1.3882 Acc: 86.53%\n",
      "\n",
      "Epoch 54/100\n",
      "----------\n",
      "Epoch [54/100], Step [100/348], Loss: 0.7885, Accuracy: 89.22%\n",
      "Epoch [54/100], Step [200/348], Loss: 0.4088, Accuracy: 89.22%\n",
      "Epoch [54/100], Step [300/348], Loss: 0.7480, Accuracy: 91.41%\n",
      "train Loss: 0.5745 Acc: 88.54%\n",
      "Epoch [54/100], Step [100/348], Loss: 0.8792, Accuracy: 89.53%\n",
      "val Loss: 1.4324 Acc: 86.97%\n",
      "\n",
      "Epoch 55/100\n",
      "----------\n",
      "Epoch [55/100], Step [100/348], Loss: 0.3696, Accuracy: 89.84%\n",
      "Epoch [55/100], Step [200/348], Loss: 0.5101, Accuracy: 87.34%\n",
      "Epoch [55/100], Step [300/348], Loss: 0.5708, Accuracy: 86.72%\n",
      "train Loss: 0.5877 Acc: 88.50%\n",
      "Epoch [55/100], Step [100/348], Loss: 0.9819, Accuracy: 91.56%\n",
      "val Loss: 1.3642 Acc: 88.80%\n",
      "\n",
      "Epoch 56/100\n",
      "----------\n",
      "Epoch [56/100], Step [100/348], Loss: 1.5529, Accuracy: 87.66%\n",
      "Epoch [56/100], Step [200/348], Loss: 0.4707, Accuracy: 92.03%\n",
      "Epoch [56/100], Step [300/348], Loss: 0.5089, Accuracy: 90.00%\n",
      "train Loss: 0.5781 Acc: 88.63%\n",
      "Epoch [56/100], Step [100/348], Loss: 0.7768, Accuracy: 89.22%\n",
      "val Loss: 1.3559 Acc: 87.59%\n",
      "\n",
      "Epoch 57/100\n",
      "----------\n",
      "Epoch [57/100], Step [100/348], Loss: 0.3798, Accuracy: 91.56%\n",
      "Epoch [57/100], Step [200/348], Loss: 0.6558, Accuracy: 90.00%\n",
      "Epoch [57/100], Step [300/348], Loss: 0.4674, Accuracy: 88.75%\n",
      "train Loss: 0.5761 Acc: 88.57%\n",
      "Epoch [57/100], Step [100/348], Loss: 0.6647, Accuracy: 88.59%\n",
      "val Loss: 1.3744 Acc: 87.14%\n",
      "\n",
      "Epoch 58/100\n",
      "----------\n",
      "Epoch [58/100], Step [100/348], Loss: 0.6041, Accuracy: 90.78%\n",
      "Epoch [58/100], Step [200/348], Loss: 0.5582, Accuracy: 88.91%\n",
      "Epoch [58/100], Step [300/348], Loss: 0.3658, Accuracy: 89.53%\n",
      "train Loss: 0.5594 Acc: 88.73%\n",
      "Epoch [58/100], Step [100/348], Loss: 0.6814, Accuracy: 89.38%\n",
      "val Loss: 1.4303 Acc: 86.82%\n",
      "\n",
      "Epoch 59/100\n",
      "----------\n",
      "Epoch [59/100], Step [100/348], Loss: 0.5134, Accuracy: 88.91%\n",
      "Epoch [59/100], Step [200/348], Loss: 0.5808, Accuracy: 89.84%\n",
      "Epoch [59/100], Step [300/348], Loss: 0.7136, Accuracy: 87.19%\n",
      "train Loss: 0.5758 Acc: 88.59%\n",
      "Epoch [59/100], Step [100/348], Loss: 0.8148, Accuracy: 89.69%\n",
      "val Loss: 1.3746 Acc: 87.80%\n",
      "\n",
      "Epoch 60/100\n",
      "----------\n",
      "Epoch [60/100], Step [100/348], Loss: 0.4685, Accuracy: 90.31%\n",
      "Epoch [60/100], Step [200/348], Loss: 0.4667, Accuracy: 88.44%\n",
      "Epoch [60/100], Step [300/348], Loss: 0.6370, Accuracy: 89.38%\n",
      "train Loss: 0.5649 Acc: 88.65%\n",
      "Epoch [60/100], Step [100/348], Loss: 0.7644, Accuracy: 90.78%\n",
      "val Loss: 1.4767 Acc: 88.79%\n",
      "\n",
      "Epoch 61/100\n",
      "----------\n",
      "Epoch [61/100], Step [100/348], Loss: 0.5023, Accuracy: 88.59%\n",
      "Epoch [61/100], Step [200/348], Loss: 0.6279, Accuracy: 88.44%\n",
      "Epoch [61/100], Step [300/348], Loss: 0.6303, Accuracy: 87.97%\n",
      "train Loss: 0.5644 Acc: 88.78%\n",
      "Epoch [61/100], Step [100/348], Loss: 0.8168, Accuracy: 88.28%\n",
      "val Loss: 1.3449 Acc: 87.46%\n",
      "\n",
      "Epoch 62/100\n",
      "----------\n",
      "Epoch [62/100], Step [100/348], Loss: 0.5994, Accuracy: 87.81%\n",
      "Epoch [62/100], Step [200/348], Loss: 0.4037, Accuracy: 88.12%\n",
      "Epoch [62/100], Step [300/348], Loss: 0.3972, Accuracy: 90.00%\n",
      "train Loss: 0.5552 Acc: 88.89%\n",
      "Epoch [62/100], Step [100/348], Loss: 0.8477, Accuracy: 91.25%\n",
      "val Loss: 1.3605 Acc: 88.65%\n",
      "\n",
      "Epoch 63/100\n",
      "----------\n",
      "Epoch [63/100], Step [100/348], Loss: 0.4602, Accuracy: 87.81%\n",
      "Epoch [63/100], Step [200/348], Loss: 0.5560, Accuracy: 88.91%\n",
      "Epoch [63/100], Step [300/348], Loss: 0.5129, Accuracy: 87.19%\n",
      "train Loss: 0.5554 Acc: 89.08%\n",
      "Epoch [63/100], Step [100/348], Loss: 0.8056, Accuracy: 89.84%\n",
      "val Loss: 1.3239 Acc: 87.78%\n",
      "\n",
      "Epoch 64/100\n",
      "----------\n",
      "Epoch [64/100], Step [100/348], Loss: 0.6153, Accuracy: 89.22%\n",
      "Epoch [64/100], Step [200/348], Loss: 0.4027, Accuracy: 89.84%\n",
      "Epoch [64/100], Step [300/348], Loss: 0.4563, Accuracy: 89.69%\n",
      "train Loss: 0.5417 Acc: 89.00%\n",
      "Epoch [64/100], Step [100/348], Loss: 0.7228, Accuracy: 88.91%\n",
      "val Loss: 1.2742 Acc: 87.14%\n",
      "\n",
      "Epoch 65/100\n",
      "----------\n",
      "Epoch [65/100], Step [100/348], Loss: 0.4161, Accuracy: 89.84%\n",
      "Epoch [65/100], Step [200/348], Loss: 0.6218, Accuracy: 87.97%\n",
      "Epoch [65/100], Step [300/348], Loss: 0.5885, Accuracy: 86.72%\n",
      "train Loss: 0.5391 Acc: 88.95%\n",
      "Epoch [65/100], Step [100/348], Loss: 0.7467, Accuracy: 90.94%\n",
      "val Loss: 1.3648 Acc: 88.72%\n",
      "\n",
      "Epoch 66/100\n",
      "----------\n",
      "Epoch [66/100], Step [100/348], Loss: 0.4418, Accuracy: 89.53%\n",
      "Epoch [66/100], Step [200/348], Loss: 0.6290, Accuracy: 89.84%\n",
      "Epoch [66/100], Step [300/348], Loss: 0.4839, Accuracy: 87.97%\n",
      "train Loss: 0.5318 Acc: 89.38%\n",
      "Epoch [66/100], Step [100/348], Loss: 0.7749, Accuracy: 89.84%\n",
      "val Loss: 1.2957 Acc: 88.19%\n",
      "\n",
      "Epoch 67/100\n",
      "----------\n",
      "Epoch [67/100], Step [100/348], Loss: 0.3498, Accuracy: 91.25%\n",
      "Epoch [67/100], Step [200/348], Loss: 0.5767, Accuracy: 86.56%\n",
      "Epoch [67/100], Step [300/348], Loss: 0.6017, Accuracy: 87.19%\n",
      "train Loss: 0.5461 Acc: 88.99%\n",
      "Epoch [67/100], Step [100/348], Loss: 0.8668, Accuracy: 89.22%\n",
      "val Loss: 1.3823 Acc: 87.75%\n",
      "\n",
      "Epoch 68/100\n",
      "----------\n",
      "Epoch [68/100], Step [100/348], Loss: 0.6506, Accuracy: 87.66%\n",
      "Epoch [68/100], Step [200/348], Loss: 0.6502, Accuracy: 90.16%\n",
      "Epoch [68/100], Step [300/348], Loss: 0.3732, Accuracy: 90.00%\n",
      "train Loss: 0.5338 Acc: 89.25%\n",
      "Epoch [68/100], Step [100/348], Loss: 0.8243, Accuracy: 89.22%\n",
      "val Loss: 1.3646 Acc: 87.15%\n",
      "\n",
      "Epoch 69/100\n",
      "----------\n",
      "Epoch [69/100], Step [100/348], Loss: 0.6180, Accuracy: 88.91%\n",
      "Epoch [69/100], Step [200/348], Loss: 0.4491, Accuracy: 88.75%\n",
      "Epoch [69/100], Step [300/348], Loss: 0.5110, Accuracy: 88.44%\n",
      "train Loss: 0.5302 Acc: 89.30%\n",
      "Epoch [69/100], Step [100/348], Loss: 0.6945, Accuracy: 89.53%\n",
      "val Loss: 1.3018 Acc: 87.23%\n",
      "\n",
      "Epoch 70/100\n",
      "----------\n",
      "Epoch [70/100], Step [100/348], Loss: 0.4305, Accuracy: 87.97%\n",
      "Epoch [70/100], Step [200/348], Loss: 0.4739, Accuracy: 91.25%\n",
      "Epoch [70/100], Step [300/348], Loss: 0.4845, Accuracy: 89.84%\n",
      "train Loss: 0.5359 Acc: 89.25%\n",
      "Epoch [70/100], Step [100/348], Loss: 0.7436, Accuracy: 91.25%\n",
      "val Loss: 1.3547 Acc: 88.82%\n",
      "\n",
      "Epoch 71/100\n",
      "----------\n",
      "Epoch [71/100], Step [100/348], Loss: 0.3215, Accuracy: 90.31%\n",
      "Epoch [71/100], Step [200/348], Loss: 0.6183, Accuracy: 89.38%\n",
      "Epoch [71/100], Step [300/348], Loss: 0.3592, Accuracy: 91.41%\n",
      "train Loss: 0.5087 Acc: 89.50%\n",
      "Epoch [71/100], Step [100/348], Loss: 0.7712, Accuracy: 91.41%\n",
      "val Loss: 1.3839 Acc: 88.73%\n",
      "\n",
      "Epoch 72/100\n",
      "----------\n",
      "Epoch [72/100], Step [100/348], Loss: 0.5262, Accuracy: 88.28%\n",
      "Epoch [72/100], Step [200/348], Loss: 0.4398, Accuracy: 88.91%\n",
      "Epoch [72/100], Step [300/348], Loss: 0.6258, Accuracy: 90.00%\n",
      "train Loss: 0.5178 Acc: 89.59%\n",
      "Epoch [72/100], Step [100/348], Loss: 0.7278, Accuracy: 90.78%\n",
      "val Loss: 1.3173 Acc: 88.74%\n",
      "\n",
      "Epoch 73/100\n",
      "----------\n",
      "Epoch [73/100], Step [100/348], Loss: 0.4547, Accuracy: 90.78%\n",
      "Epoch [73/100], Step [200/348], Loss: 0.4330, Accuracy: 87.19%\n",
      "Epoch [73/100], Step [300/348], Loss: 0.5128, Accuracy: 88.91%\n",
      "train Loss: 0.5265 Acc: 89.39%\n",
      "Epoch [73/100], Step [100/348], Loss: 0.7239, Accuracy: 90.78%\n",
      "val Loss: 1.3507 Acc: 89.19%\n",
      "\n",
      "Epoch 74/100\n",
      "----------\n",
      "Epoch [74/100], Step [100/348], Loss: 0.4945, Accuracy: 89.38%\n",
      "Epoch [74/100], Step [200/348], Loss: 0.4389, Accuracy: 87.50%\n",
      "Epoch [74/100], Step [300/348], Loss: 0.5005, Accuracy: 88.44%\n",
      "train Loss: 0.5227 Acc: 89.47%\n",
      "Epoch [74/100], Step [100/348], Loss: 0.7804, Accuracy: 91.25%\n",
      "val Loss: 1.3146 Acc: 88.61%\n",
      "\n",
      "Epoch 75/100\n",
      "----------\n",
      "Epoch [75/100], Step [100/348], Loss: 0.4266, Accuracy: 91.41%\n",
      "Epoch [75/100], Step [200/348], Loss: 0.6535, Accuracy: 87.81%\n",
      "Epoch [75/100], Step [300/348], Loss: 0.5864, Accuracy: 87.81%\n",
      "train Loss: 0.5207 Acc: 89.51%\n",
      "Epoch [75/100], Step [100/348], Loss: 0.7669, Accuracy: 91.25%\n",
      "val Loss: 1.3213 Acc: 88.70%\n",
      "\n",
      "Epoch 76/100\n",
      "----------\n",
      "Epoch [76/100], Step [100/348], Loss: 0.3416, Accuracy: 91.56%\n",
      "Epoch [76/100], Step [200/348], Loss: 0.3916, Accuracy: 90.94%\n",
      "Epoch [76/100], Step [300/348], Loss: 0.4598, Accuracy: 90.00%\n",
      "train Loss: 0.5074 Acc: 89.68%\n",
      "Epoch [76/100], Step [100/348], Loss: 0.7809, Accuracy: 91.72%\n",
      "val Loss: 1.4310 Acc: 89.81%\n",
      "\n",
      "Epoch 77/100\n",
      "----------\n",
      "Epoch [77/100], Step [100/348], Loss: 0.4050, Accuracy: 91.88%\n",
      "Epoch [77/100], Step [200/348], Loss: 0.8829, Accuracy: 88.59%\n",
      "Epoch [77/100], Step [300/348], Loss: 0.5213, Accuracy: 88.91%\n",
      "train Loss: 0.5056 Acc: 89.79%\n",
      "Epoch [77/100], Step [100/348], Loss: 0.8283, Accuracy: 90.94%\n",
      "val Loss: 1.3015 Acc: 88.53%\n",
      "\n",
      "Epoch 78/100\n",
      "----------\n",
      "Epoch [78/100], Step [100/348], Loss: 1.3682, Accuracy: 90.16%\n",
      "Epoch [78/100], Step [200/348], Loss: 0.4913, Accuracy: 90.47%\n",
      "Epoch [78/100], Step [300/348], Loss: 0.4426, Accuracy: 89.53%\n",
      "train Loss: 0.5114 Acc: 89.55%\n",
      "Epoch [78/100], Step [100/348], Loss: 0.7702, Accuracy: 91.25%\n",
      "val Loss: 1.3025 Acc: 88.32%\n",
      "\n",
      "Epoch 79/100\n",
      "----------\n",
      "Epoch [79/100], Step [100/348], Loss: 0.4679, Accuracy: 89.22%\n",
      "Epoch [79/100], Step [200/348], Loss: 0.5249, Accuracy: 90.31%\n",
      "Epoch [79/100], Step [300/348], Loss: 0.5323, Accuracy: 89.06%\n",
      "train Loss: 0.5003 Acc: 89.82%\n",
      "Epoch [79/100], Step [100/348], Loss: 0.8351, Accuracy: 90.78%\n",
      "val Loss: 1.3505 Acc: 88.34%\n",
      "\n",
      "Epoch 80/100\n",
      "----------\n",
      "Epoch [80/100], Step [100/348], Loss: 0.6390, Accuracy: 89.06%\n",
      "Epoch [80/100], Step [200/348], Loss: 0.6647, Accuracy: 90.62%\n",
      "Epoch [80/100], Step [300/348], Loss: 0.4394, Accuracy: 90.78%\n",
      "train Loss: 0.5035 Acc: 89.73%\n",
      "Epoch [80/100], Step [100/348], Loss: 0.7564, Accuracy: 90.94%\n",
      "val Loss: 1.2956 Acc: 88.62%\n",
      "\n",
      "Epoch 81/100\n",
      "----------\n",
      "Epoch [81/100], Step [100/348], Loss: 0.6682, Accuracy: 90.16%\n",
      "Epoch [81/100], Step [200/348], Loss: 0.6627, Accuracy: 90.00%\n",
      "Epoch [81/100], Step [300/348], Loss: 0.3511, Accuracy: 89.53%\n",
      "train Loss: 0.4967 Acc: 89.74%\n",
      "Epoch [81/100], Step [100/348], Loss: 0.7624, Accuracy: 90.78%\n",
      "val Loss: 1.3738 Acc: 89.13%\n",
      "\n",
      "Epoch 82/100\n",
      "----------\n",
      "Epoch [82/100], Step [100/348], Loss: 0.4282, Accuracy: 89.53%\n",
      "Epoch [82/100], Step [200/348], Loss: 0.4722, Accuracy: 89.53%\n",
      "Epoch [82/100], Step [300/348], Loss: 0.4768, Accuracy: 90.16%\n",
      "train Loss: 0.4927 Acc: 89.85%\n",
      "Epoch [82/100], Step [100/348], Loss: 0.7855, Accuracy: 91.41%\n",
      "val Loss: 1.3795 Acc: 89.21%\n",
      "\n",
      "Epoch 83/100\n",
      "----------\n",
      "Epoch [83/100], Step [100/348], Loss: 0.4330, Accuracy: 91.41%\n",
      "Epoch [83/100], Step [200/348], Loss: 0.4146, Accuracy: 89.38%\n",
      "Epoch [83/100], Step [300/348], Loss: 0.4379, Accuracy: 90.16%\n",
      "train Loss: 0.4966 Acc: 89.92%\n",
      "Epoch [83/100], Step [100/348], Loss: 0.7506, Accuracy: 90.31%\n",
      "val Loss: 1.3256 Acc: 88.26%\n",
      "\n",
      "Epoch 84/100\n",
      "----------\n",
      "Epoch [84/100], Step [100/348], Loss: 0.9657, Accuracy: 90.47%\n",
      "Epoch [84/100], Step [200/348], Loss: 0.6231, Accuracy: 90.62%\n",
      "Epoch [84/100], Step [300/348], Loss: 0.5135, Accuracy: 89.84%\n",
      "train Loss: 0.4971 Acc: 89.85%\n",
      "Epoch [84/100], Step [100/348], Loss: 0.8480, Accuracy: 91.41%\n",
      "val Loss: 1.3086 Acc: 89.50%\n",
      "\n",
      "Epoch 85/100\n",
      "----------\n",
      "Epoch [85/100], Step [100/348], Loss: 0.5395, Accuracy: 89.84%\n",
      "Epoch [85/100], Step [200/348], Loss: 0.5851, Accuracy: 91.41%\n",
      "Epoch [85/100], Step [300/348], Loss: 0.4388, Accuracy: 89.53%\n",
      "train Loss: 0.4957 Acc: 89.98%\n",
      "Epoch [85/100], Step [100/348], Loss: 0.8358, Accuracy: 90.78%\n",
      "val Loss: 1.3629 Acc: 88.70%\n",
      "\n",
      "Epoch 86/100\n",
      "----------\n",
      "Epoch [86/100], Step [100/348], Loss: 1.5326, Accuracy: 91.72%\n",
      "Epoch [86/100], Step [200/348], Loss: 0.5179, Accuracy: 91.56%\n",
      "Epoch [86/100], Step [300/348], Loss: 0.7498, Accuracy: 89.06%\n",
      "train Loss: 0.4941 Acc: 90.02%\n",
      "Epoch [86/100], Step [100/348], Loss: 0.7590, Accuracy: 90.94%\n",
      "val Loss: 1.3263 Acc: 88.88%\n",
      "\n",
      "Epoch 87/100\n",
      "----------\n",
      "Epoch [87/100], Step [100/348], Loss: 0.4631, Accuracy: 90.94%\n",
      "Epoch [87/100], Step [200/348], Loss: 0.5632, Accuracy: 90.16%\n",
      "Epoch [87/100], Step [300/348], Loss: 0.4768, Accuracy: 88.91%\n",
      "train Loss: 0.4907 Acc: 90.04%\n",
      "Epoch [87/100], Step [100/348], Loss: 0.7729, Accuracy: 90.62%\n",
      "val Loss: 1.3094 Acc: 88.58%\n",
      "\n",
      "Epoch 88/100\n",
      "----------\n",
      "Epoch [88/100], Step [100/348], Loss: 0.4382, Accuracy: 90.62%\n",
      "Epoch [88/100], Step [200/348], Loss: 0.5118, Accuracy: 89.84%\n",
      "Epoch [88/100], Step [300/348], Loss: 0.5460, Accuracy: 90.62%\n",
      "train Loss: 0.4907 Acc: 89.98%\n",
      "Epoch [88/100], Step [100/348], Loss: 0.7594, Accuracy: 90.62%\n",
      "val Loss: 1.2657 Acc: 88.75%\n",
      "\n",
      "Epoch 89/100\n",
      "----------\n",
      "Epoch [89/100], Step [100/348], Loss: 0.3844, Accuracy: 90.16%\n",
      "Epoch [89/100], Step [200/348], Loss: 0.4775, Accuracy: 87.81%\n",
      "Epoch [89/100], Step [300/348], Loss: 0.6836, Accuracy: 90.16%\n",
      "train Loss: 0.5021 Acc: 89.87%\n",
      "Epoch [89/100], Step [100/348], Loss: 0.8098, Accuracy: 90.94%\n",
      "val Loss: 1.2882 Acc: 89.25%\n",
      "\n",
      "Epoch 90/100\n",
      "----------\n",
      "Epoch [90/100], Step [100/348], Loss: 0.3227, Accuracy: 90.47%\n",
      "Epoch [90/100], Step [200/348], Loss: 0.4975, Accuracy: 92.34%\n",
      "Epoch [90/100], Step [300/348], Loss: 0.5630, Accuracy: 89.38%\n",
      "train Loss: 0.4913 Acc: 90.09%\n",
      "Epoch [90/100], Step [100/348], Loss: 0.8427, Accuracy: 90.00%\n",
      "val Loss: 1.2959 Acc: 89.03%\n",
      "\n",
      "Epoch 91/100\n",
      "----------\n",
      "Epoch [91/100], Step [100/348], Loss: 0.5112, Accuracy: 88.44%\n",
      "Epoch [91/100], Step [200/348], Loss: 0.5360, Accuracy: 89.69%\n",
      "Epoch [91/100], Step [300/348], Loss: 0.3420, Accuracy: 90.62%\n",
      "train Loss: 0.4852 Acc: 90.08%\n",
      "Epoch [91/100], Step [100/348], Loss: 0.8428, Accuracy: 90.94%\n",
      "val Loss: 1.3706 Acc: 89.13%\n",
      "\n",
      "Epoch 92/100\n",
      "----------\n",
      "Epoch [92/100], Step [100/348], Loss: 1.0262, Accuracy: 88.75%\n",
      "Epoch [92/100], Step [200/348], Loss: 0.3480, Accuracy: 90.47%\n",
      "Epoch [92/100], Step [300/348], Loss: 0.4990, Accuracy: 89.38%\n",
      "train Loss: 0.4773 Acc: 90.22%\n",
      "Epoch [92/100], Step [100/348], Loss: 0.8105, Accuracy: 90.31%\n",
      "val Loss: 1.3003 Acc: 89.31%\n",
      "\n",
      "Epoch 93/100\n",
      "----------\n",
      "Epoch [93/100], Step [100/348], Loss: 0.5739, Accuracy: 90.62%\n",
      "Epoch [93/100], Step [200/348], Loss: 0.6910, Accuracy: 88.91%\n",
      "Epoch [93/100], Step [300/348], Loss: 1.1323, Accuracy: 89.22%\n",
      "train Loss: 0.4944 Acc: 90.08%\n",
      "Epoch [93/100], Step [100/348], Loss: 0.9076, Accuracy: 92.03%\n",
      "val Loss: 1.3160 Acc: 89.08%\n",
      "\n",
      "Epoch 94/100\n",
      "----------\n",
      "Epoch [94/100], Step [100/348], Loss: 0.5469, Accuracy: 91.56%\n",
      "Epoch [94/100], Step [200/348], Loss: 0.4902, Accuracy: 90.16%\n",
      "Epoch [94/100], Step [300/348], Loss: 0.4126, Accuracy: 90.94%\n",
      "train Loss: 0.4926 Acc: 89.99%\n",
      "Epoch [94/100], Step [100/348], Loss: 0.7849, Accuracy: 90.31%\n",
      "val Loss: 1.3632 Acc: 88.88%\n",
      "\n",
      "Epoch 95/100\n",
      "----------\n",
      "Epoch [95/100], Step [100/348], Loss: 0.3398, Accuracy: 89.69%\n",
      "Epoch [95/100], Step [200/348], Loss: 0.5635, Accuracy: 90.47%\n",
      "Epoch [95/100], Step [300/348], Loss: 0.5627, Accuracy: 90.47%\n",
      "train Loss: 0.4796 Acc: 90.32%\n",
      "Epoch [95/100], Step [100/348], Loss: 0.7855, Accuracy: 91.25%\n",
      "val Loss: 1.3054 Acc: 89.10%\n",
      "\n",
      "Epoch 96/100\n",
      "----------\n",
      "Epoch [96/100], Step [100/348], Loss: 0.3722, Accuracy: 91.25%\n",
      "Epoch [96/100], Step [200/348], Loss: 0.6441, Accuracy: 90.31%\n",
      "Epoch [96/100], Step [300/348], Loss: 0.4677, Accuracy: 89.38%\n",
      "train Loss: 0.4857 Acc: 90.14%\n",
      "Epoch [96/100], Step [100/348], Loss: 0.8170, Accuracy: 90.47%\n",
      "val Loss: 1.3134 Acc: 88.90%\n",
      "\n",
      "Epoch 97/100\n",
      "----------\n",
      "Epoch [97/100], Step [100/348], Loss: 0.4835, Accuracy: 93.12%\n",
      "Epoch [97/100], Step [200/348], Loss: 0.4260, Accuracy: 91.56%\n",
      "Epoch [97/100], Step [300/348], Loss: 0.5417, Accuracy: 88.28%\n",
      "train Loss: 0.4848 Acc: 90.16%\n",
      "Epoch [97/100], Step [100/348], Loss: 0.7679, Accuracy: 90.31%\n",
      "val Loss: 1.3559 Acc: 89.03%\n",
      "\n",
      "Epoch 98/100\n",
      "----------\n",
      "Epoch [98/100], Step [100/348], Loss: 0.3897, Accuracy: 92.34%\n",
      "Epoch [98/100], Step [200/348], Loss: 0.4632, Accuracy: 89.53%\n",
      "Epoch [98/100], Step [300/348], Loss: 0.5074, Accuracy: 89.06%\n",
      "train Loss: 0.4780 Acc: 90.32%\n",
      "Epoch [98/100], Step [100/348], Loss: 0.8246, Accuracy: 90.00%\n",
      "val Loss: 1.3094 Acc: 88.79%\n",
      "\n",
      "Epoch 99/100\n",
      "----------\n",
      "Epoch [99/100], Step [100/348], Loss: 0.4295, Accuracy: 90.62%\n",
      "Epoch [99/100], Step [200/348], Loss: 0.7693, Accuracy: 89.06%\n",
      "Epoch [99/100], Step [300/348], Loss: 0.5752, Accuracy: 90.31%\n",
      "train Loss: 0.4812 Acc: 90.06%\n",
      "Epoch [99/100], Step [100/348], Loss: 0.8042, Accuracy: 90.78%\n",
      "val Loss: 1.3243 Acc: 88.80%\n",
      "\n",
      "Epoch 100/100\n",
      "----------\n",
      "Epoch [100/100], Step [100/348], Loss: 0.5798, Accuracy: 90.62%\n",
      "Epoch [100/100], Step [200/348], Loss: 0.6472, Accuracy: 90.47%\n",
      "Epoch [100/100], Step [300/348], Loss: 0.3970, Accuracy: 92.34%\n",
      "train Loss: 0.4737 Acc: 90.24%\n",
      "Epoch [100/100], Step [100/348], Loss: 0.7699, Accuracy: 90.62%\n",
      "val Loss: 1.3226 Acc: 89.56%\n",
      "\n",
      "Training complete in 148m 34s\n",
      "Best val Acc: 0.861045\n",
      "Best loss: 0.871360\n"
     ]
    }
   ],
   "source": [
    "# Observe that all parameters are being optimized\n",
    "optimizer = optim.Adam(params_to_update, lr=lr_start)\n",
    "\n",
    "# Learning rate scheduler.\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs, eta_min=lr_end,\n",
    "                                                 last_epoch=-1)\n",
    "\n",
    "\n",
    "# Setup the loss fxn\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "\n",
    "# Train and evaluate\n",
    "model_pyt, prof, val_history, train_history = train_model(device, model_pyt, data_loaders, \n",
    "                                                            optimizer, scheduler,\n",
    "                                                            criterion, \n",
    "                                                            num_epochs=num_epochs,\n",
    "                                                            num_classes=num_classes,\n",
    "                                                            is_inception=(model_name==\"inceptionv3\"),\n",
    "                                                            profiler=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'ads'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "zM-dorQBJAZb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_model(model_pyt.state_dict(), '../models/', \n",
    "           f'augmented_{model_name}_{dataset_name}_{num_epochs}_{batch_size}_{lr_start}_{lr_end}_model_weights.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_metrics = eval_model(device=device, model=model_pyt, test_loader=data_loaders['test'], is_inception=(model_name==\"inceptionv3\"), num_classes=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 2.4598599137931036\n",
      "f1: 0.17894126778972172\n",
      "cm: [[[3009  190]\n",
      "  [ 345  168]]\n",
      "\n",
      " [[2966  517]\n",
      "  [ 159   70]]\n",
      "\n",
      " [[3512  175]\n",
      "  [  21    4]]\n",
      "\n",
      " [[2666  986]\n",
      "  [  23   37]]\n",
      "\n",
      " [[3602   66]\n",
      "  [  38    6]]\n",
      "\n",
      " [[3465  162]\n",
      "  [  75   10]]\n",
      "\n",
      " [[3178  415]\n",
      "  [  93   26]]\n",
      "\n",
      " [[3015  626]\n",
      "  [  52   19]]\n",
      "\n",
      " [[2892   35]\n",
      "  [ 731   54]]\n",
      "\n",
      " [[2698   63]\n",
      "  [ 614  337]]\n",
      "\n",
      " [[3335  220]\n",
      "  [ 113   44]]\n",
      "\n",
      " [[3243  448]\n",
      "  [  12    9]]\n",
      "\n",
      " [[2867   24]\n",
      "  [ 670  151]]\n",
      "\n",
      " [[3134   76]\n",
      "  [ 327  175]]\n",
      "\n",
      " [[2848  647]\n",
      "  [ 108  109]]\n",
      "\n",
      " [[3412  279]\n",
      "  [  14    7]]\n",
      "\n",
      " [[3365  218]\n",
      "  [  82   47]]\n",
      "\n",
      " [[3413  211]\n",
      "  [  67   21]]\n",
      "\n",
      " [[3393  260]\n",
      "  [  17   42]]\n",
      "\n",
      " [[2520 1136]\n",
      "  [   8   48]]]\n",
      "outputs: [[0. 0. 0. ... 0. 0. 0.]\n",
      " [1. 1. 0. ... 1. 0. 1.]\n",
      " [0. 1. 0. ... 1. 0. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "targets: [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "for i, v in eval_metrics.items():\n",
    "    print(f\"{i}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'../models/val_history_augmented_{model_name}_{dataset_name}_{num_epochs}_{batch_size}_{lr_start}_{lr_end}_.pickle', 'wb') as handle:\n",
    "    pickle.dump(val_history, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open(f'../models/train_history_augmented_{model_name}_{dataset_name}_{num_epochs}_{batch_size}_{lr_start}_{lr_end}_.pickle', 'wb') as handle:\n",
    "    pickle.dump(train_history, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open(f'../models/eval_metrics_augmented_{model_name}_{dataset_name}_{num_epochs}_{batch_size}_{lr_start}_{lr_end}_.pickle', 'wb') as handle:\n",
    "    pickle.dump(eval_metrics, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "#with open('filename.pickle', 'rb') as handle:\n",
    "#    b = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WvFygat_aiDN"
   },
   "outputs": [],
   "source": [
    "#print(prof.key_averages(group_by_stack_n=5).table(sort_by='self_cpu_time_total', row_limit=50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "EQ6hb3iO2mXv"
   },
   "outputs": [],
   "source": [
    "# Plot the training curves of validation accuracy vs. number\n",
    "#  of training epochs for the transfer learning method and\n",
    "#  the model trained from scratch\n",
    "# vhist = []\n",
    "# vhist = [h.cpu().numpy() for h in val_acc_history]\n",
    "# thist = []\n",
    "# thist = [h.cpu().numpy() for h in train_acc_history]\n",
    "\n",
    "# plt.title(\"Accuracy vs. Number of Training Epochs\")\n",
    "# plt.xlabel(\"Training Epochs\")\n",
    "# plt.ylabel(\"Accuracy\")\n",
    "# #plt.plot(range(1,num_epochs+1),ohist,label=\"Pretrained\")\n",
    "# plt.plot(range(1,num_epochs+1),vhist,label=\"Validation\")\n",
    "# plt.plot(range(1,num_epochs+1),thist,label=\"Training\")\n",
    "# plt.ylim((0,1.))\n",
    "# plt.xticks(np.arange(1, num_epochs+1, 1.0))\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "aXpHASjTUE_Q"
   },
   "outputs": [],
   "source": [
    "# Plot the training curves of validation accuracy vs. number\n",
    "#  of training epochs for the transfer learning method and\n",
    "#  the model trained from scratch\n",
    "# vhist = []\n",
    "# vhist = [h for h in val_loss_history]\n",
    "# thist = []\n",
    "# thist = [h for h in train_loss_history]\n",
    "\n",
    "# plt.title(\"Loss vs. Number of Training Epochs\")\n",
    "# plt.xlabel(\"Training Epochs\")\n",
    "# plt.ylabel(\"Loss\")\n",
    "# #plt.plot(range(1,num_epochs+1),ohist,label=\"Pretrained\")\n",
    "# plt.plot(range(1,num_epochs+1),vhist,label=\"Validation\")\n",
    "# plt.plot(range(1,num_epochs+1),thist,label=\"Training\")\n",
    "# plt.ylim((0,1.))\n",
    "# plt.xticks(np.arange(1, num_epochs+1, 1.0))\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3.9.13 ('dl')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "8663be1127523d7121742bbf948a8b1c8dd9a63c15e224e5108ff87b090569d5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
