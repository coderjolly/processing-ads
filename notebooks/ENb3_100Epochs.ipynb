{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train for 50 epochs. First use only fine tuning on last layer\n",
    "## Then compare with fine-tuning entire network\n",
    "## TODO: \n",
    "## 0. Pre-process images\n",
    "##      Resize images\n",
    "##      Other pre-processing\n",
    "## 0.1. Check image colors\n",
    "## 1. Get mean and std of dataset - done\n",
    "## 2. Train on Resnet-34\n",
    "## 3. Train on efficient net b3 - done\n",
    "## 4. Train on mobilenet v3 large\n",
    "## 5. Write a script to plot loss + accuracy graph\n",
    "## 6. Get FLOPs\n",
    "## 7. Get num layers\n",
    "## 8. Add class weights - done\n",
    "## 9. Implement gradcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from multilabel.train import train_model\n",
    "from model import initialize_model\n",
    "from utils import set_requires_grad, save_model\n",
    "from multilabel.data import load_data\n",
    "from plotting import plot_data_loader\n",
    "from multilabel.eval import eval_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "0w24yf-Tj47H"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import time\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "from numpy.random import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.io import read_image\n",
    "import torchvision.transforms as T\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, models, transforms\n",
    "import torch.autograd.profiler as tprofiler\n",
    "import torch.utils.data as td\n",
    "\n",
    "plt.rcParams[\"savefig.bbox\"] = 'tight'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "O7W8BTtF3BN1"
   },
   "outputs": [],
   "source": [
    "seed = 42\n",
    "\n",
    "random.seed(seed)\n",
    "\n",
    "# pytorch RNGs\n",
    "torch.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "if torch.cuda.is_available(): torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "# numpy RNG\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "21_bts2Wj47M",
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_dir = \"../data\"\n",
    "images_dir = \"../data/processed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "nr7fQfkuj47u"
   },
   "outputs": [],
   "source": [
    "# Get best num_workers\n",
    "# for i in range(97):\n",
    "#     start = time.time()\n",
    "#     data_loader = load_data(images_dir,\n",
    "#                                                                    batch_size = 96, \n",
    "#                                                                    input_size = 299, \n",
    "#                                                                    norm_arr = ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "#                                                                    num_workers = i)\n",
    "#     iter(data_loader['train']).next()[0].shape\n",
    "#     print(f\"{i}: {time.time()-start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "96wB0P9Gj47u"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k-vpcOXE1pmg",
    "outputId": "25752964-a425-490c-d154-0cc8baab3b61"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Check if GPU is available.\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "# Models options: resnet50, resnet34, inceptionv3, vgg16, mobile_net_v3_large, efficient_net_b1, efficient_net_b0, efficient_net_b3.\n",
    "model_name = \"efficient_net_b3\"\n",
    "\n",
    "# Number of classes.\n",
    "num_classes = 20\n",
    "\n",
    "# Batch Size.\n",
    "batch_size = 32\n",
    "\n",
    "# Epochs to train for.\n",
    "num_epochs = 100\n",
    "\n",
    "# Number of workers for data loader.\n",
    "num_workers = 12\n",
    "\n",
    "# Imagenet norm array passed as default value.\n",
    "# norm_arr=([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "# Chest x-ray8 training dataset metrics \n",
    "norm_arr=((0.5989, 0.5510, 0.5175), (0.3358, 0.3330, 0.3377))\n",
    "\n",
    "# Feature extract flag: False - Tune the whole model,\n",
    "#                       True - Update only the reshaped layer parameters.\n",
    "feature_extract = True\n",
    "\n",
    "# Use pretrained flag: None - Use random weights\n",
    "#                      String - Use pretrained weights given by String\n",
    "use_pretrained = models.EfficientNet_B3_Weights.IMAGENET1K_V1\n",
    "\n",
    "# Initialize the model for this run.\n",
    "model_pyt, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=use_pretrained)\n",
    "\n",
    "# lr start and end points for training.\n",
    "lr_start = 0.01\n",
    "lr_end = 0.001\n",
    "\n",
    "# Print the model we just instantiated\n",
    "#print(model_ft)\n",
    "\n",
    "# Positive class weights.\n",
    "pos_weight=torch.as_tensor([ 2.3509,  6.4782, 76.3264, 23.6350, 46.7897, 18.5694, 14.4224, 24.4805,\n",
    "         1.1795,  0.6394,  9.1227, 80.2774,  0.8743,  2.1217,  7.2973, 87.3730,\n",
    "        12.8151, 23.7444, 28.1492, 29.6749], dtype=torch.float)\n",
    "pos_weight = pos_weight.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "e9FOwaso3LAc"
   },
   "outputs": [],
   "source": [
    "data_loaders = load_data(images_dir,\n",
    "                         batch_size = batch_size, \n",
    "                         input_size = input_size, \n",
    "                         norm_arr = norm_arr,\n",
    "                         num_workers = num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Active',\n",
       " 'Alert',\n",
       " 'Amazed',\n",
       " 'Amused',\n",
       " 'Calm',\n",
       " 'Cheerful',\n",
       " 'Confident',\n",
       " 'Conscious',\n",
       " 'Creative',\n",
       " 'Eager',\n",
       " 'Educated',\n",
       " 'Emotional',\n",
       " 'Fashionable',\n",
       " 'Feminine',\n",
       " 'Inspired',\n",
       " 'Loving',\n",
       " 'Manly',\n",
       " 'Persuaded',\n",
       " 'Thrifty',\n",
       " 'Youthful']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_loaders['train'].dataset.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_data_loader(data_loaders['train'], (2,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 392
    },
    "id": "vacZgHSCj47u",
    "outputId": "35a65cef-1d6d-4657-ff01-be15854ca24b"
   },
   "source": [
    "plot_data_loader(data_loader['train'], (2,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zRIOYWbV1cnS"
   },
   "source": [
    "plot_data_loader(data_loader['test'], (2,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "znBg5tkd1dXF"
   },
   "source": [
    "plot_data_loader(data_loader['val'], (2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "0rj7Qeg41wLm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params to learn:\n",
      "\t classifier.1.weight\n",
      "\t classifier.1.bias\n"
     ]
    }
   ],
   "source": [
    "#model_pyt = torch.compile(model_pyt)\n",
    "# Send model to GPU\n",
    "model_pyt = model_pyt.to(device)\n",
    "\n",
    "# Find parameters to be updated in this run.\n",
    "# parameters with requires_grad = True.\n",
    "params_to_update = model_pyt.parameters()\n",
    "print(\"Params to learn:\")\n",
    "if feature_extract:\n",
    "    params_to_update = []\n",
    "    for name,param in model_pyt.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            params_to_update.append(param)\n",
    "            print(\"\\t\",name)\n",
    "else:\n",
    "    for name,param in model_pyt.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            print(\"\\t\",name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "A4B1-pfYm0Ea"
   },
   "outputs": [],
   "source": [
    "# 17 min 1 epoch - 128 batch size - inception\n",
    "# Efficientnet b0 - batch 96 - epoch 50 - num_workers 2 - flip, auto cont, sharp - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8wBR8vcG2jcd",
    "outputId": "7d01aa07-d235-4cb6-dfaf-53ce0c5a577d",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "----------\n",
      "Epoch [1/100], Step [100/348], Loss: 0.7574, Accuracy: 83.44%\n",
      "Epoch [1/100], Step [200/348], Loss: 0.7917, Accuracy: 86.72%\n",
      "Epoch [1/100], Step [300/348], Loss: 0.7396, Accuracy: 85.94%\n",
      "train Loss: 0.9514 Acc: 84.04%\n",
      "Epoch [1/100], Step [100/348], Loss: 0.6606, Accuracy: 82.19%\n",
      "val Loss: 0.8480 Acc: 80.47%\n",
      "\n",
      "Epoch 2/100\n",
      "----------\n",
      "Epoch [2/100], Step [100/348], Loss: 0.5372, Accuracy: 80.16%\n",
      "Epoch [2/100], Step [200/348], Loss: 0.9038, Accuracy: 83.44%\n",
      "Epoch [2/100], Step [300/348], Loss: 1.0174, Accuracy: 82.81%\n",
      "train Loss: 0.8046 Acc: 84.51%\n",
      "Epoch [2/100], Step [100/348], Loss: 0.7040, Accuracy: 85.16%\n",
      "val Loss: 0.8724 Acc: 83.62%\n",
      "\n",
      "Epoch 3/100\n",
      "----------\n",
      "Epoch [3/100], Step [100/348], Loss: 0.6032, Accuracy: 86.56%\n",
      "Epoch [3/100], Step [200/348], Loss: 1.0220, Accuracy: 83.44%\n",
      "Epoch [3/100], Step [300/348], Loss: 0.7954, Accuracy: 80.47%\n",
      "train Loss: 0.8119 Acc: 84.37%\n",
      "Epoch [3/100], Step [100/348], Loss: 0.5544, Accuracy: 85.78%\n",
      "val Loss: 0.9228 Acc: 83.09%\n",
      "\n",
      "Epoch 4/100\n",
      "----------\n",
      "Epoch [4/100], Step [100/348], Loss: 0.7124, Accuracy: 85.62%\n",
      "Epoch [4/100], Step [200/348], Loss: 0.6158, Accuracy: 86.09%\n",
      "Epoch [4/100], Step [300/348], Loss: 0.9106, Accuracy: 85.47%\n",
      "train Loss: 0.8025 Acc: 84.79%\n",
      "Epoch [4/100], Step [100/348], Loss: 0.5830, Accuracy: 84.38%\n",
      "val Loss: 0.9851 Acc: 83.17%\n",
      "\n",
      "Epoch 5/100\n",
      "----------\n",
      "Epoch [5/100], Step [100/348], Loss: 0.5436, Accuracy: 85.62%\n",
      "Epoch [5/100], Step [200/348], Loss: 0.7073, Accuracy: 84.84%\n",
      "Epoch [5/100], Step [300/348], Loss: 0.9043, Accuracy: 85.00%\n",
      "train Loss: 0.7769 Acc: 84.97%\n",
      "Epoch [5/100], Step [100/348], Loss: 0.5470, Accuracy: 85.62%\n",
      "val Loss: 1.0442 Acc: 84.61%\n",
      "\n",
      "Epoch 6/100\n",
      "----------\n",
      "Epoch [6/100], Step [100/348], Loss: 0.6361, Accuracy: 82.97%\n",
      "Epoch [6/100], Step [200/348], Loss: 0.6505, Accuracy: 86.72%\n",
      "Epoch [6/100], Step [300/348], Loss: 0.7209, Accuracy: 85.47%\n",
      "train Loss: 0.8030 Acc: 84.80%\n",
      "Epoch [6/100], Step [100/348], Loss: 0.6899, Accuracy: 87.03%\n",
      "val Loss: 1.0479 Acc: 84.94%\n",
      "\n",
      "Epoch 7/100\n",
      "----------\n",
      "Epoch [7/100], Step [100/348], Loss: 0.6104, Accuracy: 85.47%\n",
      "Epoch [7/100], Step [200/348], Loss: 0.8011, Accuracy: 85.31%\n",
      "Epoch [7/100], Step [300/348], Loss: 0.6980, Accuracy: 83.75%\n",
      "train Loss: 0.7832 Acc: 85.11%\n",
      "Epoch [7/100], Step [100/348], Loss: 0.5735, Accuracy: 86.56%\n",
      "val Loss: 1.0343 Acc: 84.31%\n",
      "\n",
      "Epoch 8/100\n",
      "----------\n",
      "Epoch [8/100], Step [100/348], Loss: 0.8330, Accuracy: 80.62%\n",
      "Epoch [8/100], Step [200/348], Loss: 0.7514, Accuracy: 85.47%\n",
      "Epoch [8/100], Step [300/348], Loss: 0.5892, Accuracy: 87.03%\n",
      "train Loss: 0.7981 Acc: 84.89%\n",
      "Epoch [8/100], Step [100/348], Loss: 0.6270, Accuracy: 87.50%\n",
      "val Loss: 1.1005 Acc: 85.13%\n",
      "\n",
      "Epoch 9/100\n",
      "----------\n",
      "Epoch [9/100], Step [100/348], Loss: 0.6466, Accuracy: 85.31%\n",
      "Epoch [9/100], Step [200/348], Loss: 0.9404, Accuracy: 83.28%\n",
      "Epoch [9/100], Step [300/348], Loss: 0.7032, Accuracy: 83.75%\n",
      "train Loss: 0.7935 Acc: 85.44%\n",
      "Epoch [9/100], Step [100/348], Loss: 0.5573, Accuracy: 87.81%\n",
      "val Loss: 1.1173 Acc: 85.55%\n",
      "\n",
      "Epoch 10/100\n",
      "----------\n",
      "Epoch [10/100], Step [100/348], Loss: 0.8796, Accuracy: 86.56%\n",
      "Epoch [10/100], Step [200/348], Loss: 0.8790, Accuracy: 82.81%\n",
      "Epoch [10/100], Step [300/348], Loss: 0.7881, Accuracy: 84.38%\n",
      "train Loss: 0.7843 Acc: 85.38%\n",
      "Epoch [10/100], Step [100/348], Loss: 0.5720, Accuracy: 88.12%\n",
      "val Loss: 1.2073 Acc: 85.87%\n",
      "\n",
      "Epoch 11/100\n",
      "----------\n",
      "Epoch [11/100], Step [100/348], Loss: 0.6261, Accuracy: 83.75%\n",
      "Epoch [11/100], Step [200/348], Loss: 0.4545, Accuracy: 85.94%\n",
      "Epoch [11/100], Step [300/348], Loss: 0.8450, Accuracy: 84.22%\n",
      "train Loss: 0.7911 Acc: 85.48%\n",
      "Epoch [11/100], Step [100/348], Loss: 0.5489, Accuracy: 87.97%\n",
      "val Loss: 1.1805 Acc: 84.60%\n",
      "\n",
      "Epoch 12/100\n",
      "----------\n",
      "Epoch [12/100], Step [100/348], Loss: 0.6737, Accuracy: 83.28%\n",
      "Epoch [12/100], Step [200/348], Loss: 0.6406, Accuracy: 86.09%\n",
      "Epoch [12/100], Step [300/348], Loss: 0.6889, Accuracy: 86.41%\n",
      "train Loss: 0.7761 Acc: 85.46%\n",
      "Epoch [12/100], Step [100/348], Loss: 0.5832, Accuracy: 88.59%\n",
      "val Loss: 1.1703 Acc: 85.88%\n",
      "\n",
      "Epoch 13/100\n",
      "----------\n",
      "Epoch [13/100], Step [100/348], Loss: 0.6274, Accuracy: 86.41%\n",
      "Epoch [13/100], Step [200/348], Loss: 0.6781, Accuracy: 84.69%\n",
      "Epoch [13/100], Step [300/348], Loss: 0.5020, Accuracy: 86.25%\n",
      "train Loss: 0.8005 Acc: 85.38%\n",
      "Epoch [13/100], Step [100/348], Loss: 0.5450, Accuracy: 88.28%\n",
      "val Loss: 1.2270 Acc: 86.25%\n",
      "\n",
      "Epoch 14/100\n",
      "----------\n",
      "Epoch [14/100], Step [100/348], Loss: 0.6060, Accuracy: 88.28%\n",
      "Epoch [14/100], Step [200/348], Loss: 1.7489, Accuracy: 83.44%\n",
      "Epoch [14/100], Step [300/348], Loss: 0.5754, Accuracy: 86.56%\n",
      "train Loss: 0.7815 Acc: 85.64%\n",
      "Epoch [14/100], Step [100/348], Loss: 0.6287, Accuracy: 87.66%\n",
      "val Loss: 1.2075 Acc: 84.29%\n",
      "\n",
      "Epoch 15/100\n",
      "----------\n",
      "Epoch [15/100], Step [100/348], Loss: 0.7200, Accuracy: 84.38%\n",
      "Epoch [15/100], Step [200/348], Loss: 0.7009, Accuracy: 86.09%\n",
      "Epoch [15/100], Step [300/348], Loss: 0.6914, Accuracy: 85.78%\n",
      "train Loss: 0.7824 Acc: 85.80%\n",
      "Epoch [15/100], Step [100/348], Loss: 0.6773, Accuracy: 88.44%\n",
      "val Loss: 1.2747 Acc: 86.75%\n",
      "\n",
      "Epoch 16/100\n",
      "----------\n",
      "Epoch [16/100], Step [100/348], Loss: 0.5566, Accuracy: 88.12%\n",
      "Epoch [16/100], Step [200/348], Loss: 0.8278, Accuracy: 86.25%\n",
      "Epoch [16/100], Step [300/348], Loss: 0.9391, Accuracy: 84.53%\n",
      "train Loss: 0.7869 Acc: 85.53%\n",
      "Epoch [16/100], Step [100/348], Loss: 0.6796, Accuracy: 90.62%\n",
      "val Loss: 1.3212 Acc: 88.22%\n",
      "\n",
      "Epoch 17/100\n",
      "----------\n",
      "Epoch [17/100], Step [100/348], Loss: 0.5505, Accuracy: 85.94%\n",
      "Epoch [17/100], Step [200/348], Loss: 0.5047, Accuracy: 86.41%\n",
      "Epoch [17/100], Step [300/348], Loss: 0.6095, Accuracy: 85.31%\n",
      "train Loss: 0.7784 Acc: 85.83%\n",
      "Epoch [17/100], Step [100/348], Loss: 0.5552, Accuracy: 88.12%\n",
      "val Loss: 1.2434 Acc: 86.68%\n",
      "\n",
      "Epoch 18/100\n",
      "----------\n",
      "Epoch [18/100], Step [100/348], Loss: 0.8587, Accuracy: 87.50%\n",
      "Epoch [18/100], Step [200/348], Loss: 0.7229, Accuracy: 87.50%\n",
      "Epoch [18/100], Step [300/348], Loss: 0.8352, Accuracy: 85.62%\n",
      "train Loss: 0.7753 Acc: 85.83%\n",
      "Epoch [18/100], Step [100/348], Loss: 0.6359, Accuracy: 88.59%\n",
      "val Loss: 1.2572 Acc: 86.48%\n",
      "\n",
      "Epoch 19/100\n",
      "----------\n",
      "Epoch [19/100], Step [100/348], Loss: 0.5591, Accuracy: 87.34%\n",
      "Epoch [19/100], Step [200/348], Loss: 1.0208, Accuracy: 81.09%\n",
      "Epoch [19/100], Step [300/348], Loss: 2.0942, Accuracy: 84.53%\n",
      "train Loss: 0.7904 Acc: 85.66%\n",
      "Epoch [19/100], Step [100/348], Loss: 0.6427, Accuracy: 87.81%\n",
      "val Loss: 1.2237 Acc: 86.28%\n",
      "\n",
      "Epoch 20/100\n",
      "----------\n",
      "Epoch [20/100], Step [100/348], Loss: 0.6966, Accuracy: 86.25%\n",
      "Epoch [20/100], Step [200/348], Loss: 0.6775, Accuracy: 86.56%\n",
      "Epoch [20/100], Step [300/348], Loss: 0.5618, Accuracy: 87.50%\n",
      "train Loss: 0.8197 Acc: 85.55%\n",
      "Epoch [20/100], Step [100/348], Loss: 0.4812, Accuracy: 88.59%\n",
      "val Loss: 1.2974 Acc: 87.14%\n",
      "\n",
      "Epoch 21/100\n",
      "----------\n",
      "Epoch [21/100], Step [100/348], Loss: 0.7681, Accuracy: 86.41%\n",
      "Epoch [21/100], Step [200/348], Loss: 1.4722, Accuracy: 84.38%\n",
      "Epoch [21/100], Step [300/348], Loss: 0.8013, Accuracy: 86.09%\n",
      "train Loss: 0.8169 Acc: 85.50%\n",
      "Epoch [21/100], Step [100/348], Loss: 0.5703, Accuracy: 85.78%\n",
      "val Loss: 1.2039 Acc: 84.99%\n",
      "\n",
      "Epoch 22/100\n",
      "----------\n",
      "Epoch [22/100], Step [100/348], Loss: 1.7872, Accuracy: 86.41%\n",
      "Epoch [22/100], Step [200/348], Loss: 0.8333, Accuracy: 86.56%\n",
      "Epoch [22/100], Step [300/348], Loss: 1.6350, Accuracy: 87.50%\n",
      "train Loss: 0.8106 Acc: 85.67%\n",
      "Epoch [22/100], Step [100/348], Loss: 0.5906, Accuracy: 87.97%\n",
      "val Loss: 1.2613 Acc: 87.31%\n",
      "\n",
      "Epoch 23/100\n",
      "----------\n",
      "Epoch [23/100], Step [100/348], Loss: 1.3573, Accuracy: 87.34%\n",
      "Epoch [23/100], Step [200/348], Loss: 0.6070, Accuracy: 85.47%\n",
      "Epoch [23/100], Step [300/348], Loss: 0.7861, Accuracy: 85.78%\n",
      "train Loss: 0.7722 Acc: 86.27%\n",
      "Epoch [23/100], Step [100/348], Loss: 0.4944, Accuracy: 89.53%\n",
      "val Loss: 1.3030 Acc: 86.92%\n",
      "\n",
      "Epoch 24/100\n",
      "----------\n",
      "Epoch [24/100], Step [100/348], Loss: 0.5853, Accuracy: 84.69%\n",
      "Epoch [24/100], Step [200/348], Loss: 0.7092, Accuracy: 87.97%\n",
      "Epoch [24/100], Step [300/348], Loss: 1.0075, Accuracy: 86.41%\n",
      "train Loss: 0.7726 Acc: 86.17%\n",
      "Epoch [24/100], Step [100/348], Loss: 0.5808, Accuracy: 87.97%\n",
      "val Loss: 1.3109 Acc: 87.03%\n",
      "\n",
      "Epoch 25/100\n",
      "----------\n",
      "Epoch [25/100], Step [100/348], Loss: 0.8665, Accuracy: 85.16%\n",
      "Epoch [25/100], Step [200/348], Loss: 0.5742, Accuracy: 86.09%\n",
      "Epoch [25/100], Step [300/348], Loss: 0.7011, Accuracy: 85.78%\n",
      "train Loss: 0.7799 Acc: 85.94%\n",
      "Epoch [25/100], Step [100/348], Loss: 0.5393, Accuracy: 88.59%\n",
      "val Loss: 1.3450 Acc: 87.15%\n",
      "\n",
      "Epoch 26/100\n",
      "----------\n",
      "Epoch [26/100], Step [100/348], Loss: 0.8226, Accuracy: 86.25%\n",
      "Epoch [26/100], Step [200/348], Loss: 1.3515, Accuracy: 84.38%\n",
      "Epoch [26/100], Step [300/348], Loss: 1.2117, Accuracy: 84.06%\n",
      "train Loss: 0.7699 Acc: 85.96%\n",
      "Epoch [26/100], Step [100/348], Loss: 0.5166, Accuracy: 89.22%\n",
      "val Loss: 1.3588 Acc: 87.82%\n",
      "\n",
      "Epoch 27/100\n",
      "----------\n",
      "Epoch [27/100], Step [100/348], Loss: 0.9154, Accuracy: 85.62%\n",
      "Epoch [27/100], Step [200/348], Loss: 0.9712, Accuracy: 87.50%\n",
      "Epoch [27/100], Step [300/348], Loss: 0.7158, Accuracy: 83.44%\n",
      "train Loss: 0.7499 Acc: 86.35%\n",
      "Epoch [27/100], Step [100/348], Loss: 0.5554, Accuracy: 88.91%\n",
      "val Loss: 1.3190 Acc: 87.30%\n",
      "\n",
      "Epoch 28/100\n",
      "----------\n",
      "Epoch [28/100], Step [100/348], Loss: 0.7059, Accuracy: 84.53%\n",
      "Epoch [28/100], Step [200/348], Loss: 0.6535, Accuracy: 84.22%\n",
      "Epoch [28/100], Step [300/348], Loss: 1.2560, Accuracy: 87.03%\n",
      "train Loss: 0.7612 Acc: 86.29%\n",
      "Epoch [28/100], Step [100/348], Loss: 0.5087, Accuracy: 89.22%\n",
      "val Loss: 1.3674 Acc: 87.84%\n",
      "\n",
      "Epoch 29/100\n",
      "----------\n",
      "Epoch [29/100], Step [100/348], Loss: 0.5549, Accuracy: 86.25%\n",
      "Epoch [29/100], Step [200/348], Loss: 0.9721, Accuracy: 89.38%\n",
      "Epoch [29/100], Step [300/348], Loss: 0.8547, Accuracy: 84.69%\n",
      "train Loss: 0.7520 Acc: 86.36%\n",
      "Epoch [29/100], Step [100/348], Loss: 0.5953, Accuracy: 89.84%\n",
      "val Loss: 1.3401 Acc: 87.61%\n",
      "\n",
      "Epoch 30/100\n",
      "----------\n",
      "Epoch [30/100], Step [100/348], Loss: 0.6068, Accuracy: 87.34%\n",
      "Epoch [30/100], Step [200/348], Loss: 1.1400, Accuracy: 85.78%\n",
      "Epoch [30/100], Step [300/348], Loss: 0.9237, Accuracy: 83.75%\n",
      "train Loss: 0.7532 Acc: 86.25%\n",
      "Epoch [30/100], Step [100/348], Loss: 0.5049, Accuracy: 88.28%\n",
      "val Loss: 1.3585 Acc: 86.01%\n",
      "\n",
      "Epoch 31/100\n",
      "----------\n",
      "Epoch [31/100], Step [100/348], Loss: 0.6484, Accuracy: 88.44%\n",
      "Epoch [31/100], Step [200/348], Loss: 0.4759, Accuracy: 86.09%\n",
      "Epoch [31/100], Step [300/348], Loss: 0.8764, Accuracy: 85.16%\n",
      "train Loss: 0.7382 Acc: 86.59%\n",
      "Epoch [31/100], Step [100/348], Loss: 0.4800, Accuracy: 89.84%\n",
      "val Loss: 1.3114 Acc: 87.16%\n",
      "\n",
      "Epoch 32/100\n",
      "----------\n",
      "Epoch [32/100], Step [100/348], Loss: 0.6417, Accuracy: 86.25%\n",
      "Epoch [32/100], Step [200/348], Loss: 0.4544, Accuracy: 88.59%\n",
      "Epoch [32/100], Step [300/348], Loss: 0.8249, Accuracy: 86.88%\n",
      "train Loss: 0.7436 Acc: 86.30%\n",
      "Epoch [32/100], Step [100/348], Loss: 0.5255, Accuracy: 89.06%\n",
      "val Loss: 1.3584 Acc: 87.16%\n",
      "\n",
      "Epoch 33/100\n",
      "----------\n",
      "Epoch [33/100], Step [100/348], Loss: 1.6573, Accuracy: 85.16%\n",
      "Epoch [33/100], Step [200/348], Loss: 0.5667, Accuracy: 88.91%\n",
      "Epoch [33/100], Step [300/348], Loss: 0.6979, Accuracy: 86.72%\n",
      "train Loss: 0.7462 Acc: 86.59%\n",
      "Epoch [33/100], Step [100/348], Loss: 0.5674, Accuracy: 89.53%\n",
      "val Loss: 1.3608 Acc: 87.93%\n",
      "\n",
      "Epoch 34/100\n",
      "----------\n",
      "Epoch [34/100], Step [100/348], Loss: 0.4209, Accuracy: 87.97%\n",
      "Epoch [34/100], Step [200/348], Loss: 0.6076, Accuracy: 87.34%\n",
      "Epoch [34/100], Step [300/348], Loss: 0.6762, Accuracy: 87.03%\n",
      "train Loss: 0.7314 Acc: 86.76%\n",
      "Epoch [34/100], Step [100/348], Loss: 0.5525, Accuracy: 89.38%\n",
      "val Loss: 1.3445 Acc: 88.19%\n",
      "\n",
      "Epoch 35/100\n",
      "----------\n",
      "Epoch [35/100], Step [100/348], Loss: 0.7767, Accuracy: 84.06%\n",
      "Epoch [35/100], Step [200/348], Loss: 1.4059, Accuracy: 87.97%\n",
      "Epoch [35/100], Step [300/348], Loss: 0.8383, Accuracy: 86.56%\n",
      "train Loss: 0.7137 Acc: 86.85%\n",
      "Epoch [35/100], Step [100/348], Loss: 0.4524, Accuracy: 92.03%\n",
      "val Loss: 1.4671 Acc: 88.31%\n",
      "\n",
      "Epoch 36/100\n",
      "----------\n",
      "Epoch [36/100], Step [100/348], Loss: 2.5447, Accuracy: 87.34%\n",
      "Epoch [36/100], Step [200/348], Loss: 1.0624, Accuracy: 86.72%\n",
      "Epoch [36/100], Step [300/348], Loss: 0.5181, Accuracy: 87.50%\n",
      "train Loss: 0.7262 Acc: 86.82%\n",
      "Epoch [36/100], Step [100/348], Loss: 0.4933, Accuracy: 90.47%\n",
      "val Loss: 1.3879 Acc: 88.35%\n",
      "\n",
      "Epoch 37/100\n",
      "----------\n",
      "Epoch [37/100], Step [100/348], Loss: 0.4523, Accuracy: 87.50%\n",
      "Epoch [37/100], Step [200/348], Loss: 1.5041, Accuracy: 87.81%\n",
      "Epoch [37/100], Step [300/348], Loss: 0.6887, Accuracy: 86.72%\n",
      "train Loss: 0.7321 Acc: 86.82%\n",
      "Epoch [37/100], Step [100/348], Loss: 0.5125, Accuracy: 89.69%\n",
      "val Loss: 1.3222 Acc: 86.86%\n",
      "\n",
      "Epoch 38/100\n",
      "----------\n",
      "Epoch [38/100], Step [100/348], Loss: 0.8635, Accuracy: 88.28%\n",
      "Epoch [38/100], Step [200/348], Loss: 0.9391, Accuracy: 86.09%\n",
      "Epoch [38/100], Step [300/348], Loss: 0.7072, Accuracy: 86.41%\n",
      "train Loss: 0.7174 Acc: 86.90%\n",
      "Epoch [38/100], Step [100/348], Loss: 0.5129, Accuracy: 91.09%\n",
      "val Loss: 1.2804 Acc: 87.43%\n",
      "\n",
      "Epoch 39/100\n",
      "----------\n",
      "Epoch [39/100], Step [100/348], Loss: 0.3738, Accuracy: 90.47%\n",
      "Epoch [39/100], Step [200/348], Loss: 0.7493, Accuracy: 84.22%\n",
      "Epoch [39/100], Step [300/348], Loss: 0.5444, Accuracy: 87.66%\n",
      "train Loss: 0.7162 Acc: 86.93%\n",
      "Epoch [39/100], Step [100/348], Loss: 0.6412, Accuracy: 89.53%\n",
      "val Loss: 1.3524 Acc: 87.78%\n",
      "\n",
      "Epoch 40/100\n",
      "----------\n",
      "Epoch [40/100], Step [100/348], Loss: 0.5879, Accuracy: 87.97%\n",
      "Epoch [40/100], Step [200/348], Loss: 0.7328, Accuracy: 85.16%\n",
      "Epoch [40/100], Step [300/348], Loss: 0.9216, Accuracy: 83.59%\n",
      "train Loss: 0.7073 Acc: 86.97%\n",
      "Epoch [40/100], Step [100/348], Loss: 0.6439, Accuracy: 88.91%\n",
      "val Loss: 1.3490 Acc: 87.88%\n",
      "\n",
      "Epoch 41/100\n",
      "----------\n",
      "Epoch [41/100], Step [100/348], Loss: 0.6447, Accuracy: 87.97%\n",
      "Epoch [41/100], Step [200/348], Loss: 0.6614, Accuracy: 85.47%\n",
      "Epoch [41/100], Step [300/348], Loss: 0.6361, Accuracy: 84.69%\n",
      "train Loss: 0.6950 Acc: 87.06%\n",
      "Epoch [41/100], Step [100/348], Loss: 0.5752, Accuracy: 90.47%\n",
      "val Loss: 1.4442 Acc: 88.41%\n",
      "\n",
      "Epoch 42/100\n",
      "----------\n",
      "Epoch [42/100], Step [100/348], Loss: 0.4963, Accuracy: 86.72%\n",
      "Epoch [42/100], Step [200/348], Loss: 0.5607, Accuracy: 85.31%\n",
      "Epoch [42/100], Step [300/348], Loss: 1.0642, Accuracy: 88.12%\n",
      "train Loss: 0.7087 Acc: 87.02%\n",
      "Epoch [42/100], Step [100/348], Loss: 0.4890, Accuracy: 90.78%\n",
      "val Loss: 1.3939 Acc: 88.72%\n",
      "\n",
      "Epoch 43/100\n",
      "----------\n",
      "Epoch [43/100], Step [100/348], Loss: 0.4486, Accuracy: 87.97%\n",
      "Epoch [43/100], Step [200/348], Loss: 0.7034, Accuracy: 84.69%\n",
      "Epoch [43/100], Step [300/348], Loss: 0.5171, Accuracy: 87.66%\n",
      "train Loss: 0.7192 Acc: 86.83%\n",
      "Epoch [43/100], Step [100/348], Loss: 0.5889, Accuracy: 89.22%\n",
      "val Loss: 1.3181 Acc: 88.53%\n",
      "\n",
      "Epoch 44/100\n",
      "----------\n",
      "Epoch [44/100], Step [100/348], Loss: 0.5331, Accuracy: 85.94%\n",
      "Epoch [44/100], Step [200/348], Loss: 0.7585, Accuracy: 87.66%\n",
      "Epoch [44/100], Step [300/348], Loss: 0.4837, Accuracy: 88.12%\n",
      "train Loss: 0.6809 Acc: 87.15%\n",
      "Epoch [44/100], Step [100/348], Loss: 0.5621, Accuracy: 90.16%\n",
      "val Loss: 1.3216 Acc: 87.94%\n",
      "\n",
      "Epoch 45/100\n",
      "----------\n",
      "Epoch [45/100], Step [100/348], Loss: 0.9240, Accuracy: 86.88%\n",
      "Epoch [45/100], Step [200/348], Loss: 0.5878, Accuracy: 87.97%\n",
      "Epoch [45/100], Step [300/348], Loss: 0.6901, Accuracy: 88.75%\n",
      "train Loss: 0.6817 Acc: 87.27%\n",
      "Epoch [45/100], Step [100/348], Loss: 0.5091, Accuracy: 90.00%\n",
      "val Loss: 1.3130 Acc: 88.24%\n",
      "\n",
      "Epoch 46/100\n",
      "----------\n",
      "Epoch [46/100], Step [100/348], Loss: 0.7822, Accuracy: 87.81%\n",
      "Epoch [46/100], Step [200/348], Loss: 0.9682, Accuracy: 85.31%\n",
      "Epoch [46/100], Step [300/348], Loss: 0.5451, Accuracy: 90.00%\n",
      "train Loss: 0.6799 Acc: 87.20%\n",
      "Epoch [46/100], Step [100/348], Loss: 0.4990, Accuracy: 91.72%\n",
      "val Loss: 1.3530 Acc: 88.38%\n",
      "\n",
      "Epoch 47/100\n",
      "----------\n",
      "Epoch [47/100], Step [100/348], Loss: 0.4897, Accuracy: 87.81%\n",
      "Epoch [47/100], Step [200/348], Loss: 0.6089, Accuracy: 85.78%\n",
      "Epoch [47/100], Step [300/348], Loss: 0.5944, Accuracy: 88.28%\n",
      "train Loss: 0.6611 Acc: 87.34%\n",
      "Epoch [47/100], Step [100/348], Loss: 0.5710, Accuracy: 91.88%\n",
      "val Loss: 1.4608 Acc: 89.30%\n",
      "\n",
      "Epoch 48/100\n",
      "----------\n",
      "Epoch [48/100], Step [100/348], Loss: 0.5984, Accuracy: 85.00%\n",
      "Epoch [48/100], Step [200/348], Loss: 0.4523, Accuracy: 89.06%\n",
      "Epoch [48/100], Step [300/348], Loss: 0.4771, Accuracy: 87.34%\n",
      "train Loss: 0.6773 Acc: 87.39%\n",
      "Epoch [48/100], Step [100/348], Loss: 0.5712, Accuracy: 89.69%\n",
      "val Loss: 1.3698 Acc: 87.99%\n",
      "\n",
      "Epoch 49/100\n",
      "----------\n",
      "Epoch [49/100], Step [100/348], Loss: 0.6704, Accuracy: 86.25%\n",
      "Epoch [49/100], Step [200/348], Loss: 0.6143, Accuracy: 88.44%\n",
      "Epoch [49/100], Step [300/348], Loss: 0.7137, Accuracy: 85.94%\n",
      "train Loss: 0.6709 Acc: 87.49%\n",
      "Epoch [49/100], Step [100/348], Loss: 0.5126, Accuracy: 90.16%\n",
      "val Loss: 1.3455 Acc: 88.37%\n",
      "\n",
      "Epoch 50/100\n",
      "----------\n",
      "Epoch [50/100], Step [100/348], Loss: 0.8987, Accuracy: 88.75%\n",
      "Epoch [50/100], Step [200/348], Loss: 0.6169, Accuracy: 87.03%\n",
      "Epoch [50/100], Step [300/348], Loss: 0.6504, Accuracy: 89.84%\n",
      "train Loss: 0.6549 Acc: 87.60%\n",
      "Epoch [50/100], Step [100/348], Loss: 0.5986, Accuracy: 91.41%\n",
      "val Loss: 1.4818 Acc: 89.91%\n",
      "\n",
      "Epoch 51/100\n",
      "----------\n",
      "Epoch [51/100], Step [100/348], Loss: 0.5249, Accuracy: 87.81%\n",
      "Epoch [51/100], Step [200/348], Loss: 0.7673, Accuracy: 86.41%\n",
      "Epoch [51/100], Step [300/348], Loss: 0.6067, Accuracy: 86.41%\n",
      "train Loss: 0.6516 Acc: 87.66%\n",
      "Epoch [51/100], Step [100/348], Loss: 0.4643, Accuracy: 89.22%\n",
      "val Loss: 1.3985 Acc: 87.84%\n",
      "\n",
      "Epoch 52/100\n",
      "----------\n",
      "Epoch [52/100], Step [100/348], Loss: 0.5214, Accuracy: 86.41%\n",
      "Epoch [52/100], Step [200/348], Loss: 0.5245, Accuracy: 90.47%\n",
      "Epoch [52/100], Step [300/348], Loss: 0.4728, Accuracy: 89.22%\n",
      "train Loss: 0.6511 Acc: 87.70%\n",
      "Epoch [52/100], Step [100/348], Loss: 0.4967, Accuracy: 90.62%\n",
      "val Loss: 1.4428 Acc: 88.89%\n",
      "\n",
      "Epoch 53/100\n",
      "----------\n",
      "Epoch [53/100], Step [100/348], Loss: 0.5497, Accuracy: 87.50%\n",
      "Epoch [53/100], Step [200/348], Loss: 0.7524, Accuracy: 90.00%\n",
      "Epoch [53/100], Step [300/348], Loss: 0.4002, Accuracy: 88.28%\n",
      "train Loss: 0.6652 Acc: 87.51%\n",
      "Epoch [53/100], Step [100/348], Loss: 0.5600, Accuracy: 90.62%\n",
      "val Loss: 1.4112 Acc: 89.45%\n",
      "\n",
      "Epoch 54/100\n",
      "----------\n",
      "Epoch [54/100], Step [100/348], Loss: 0.5435, Accuracy: 86.56%\n",
      "Epoch [54/100], Step [200/348], Loss: 0.6937, Accuracy: 87.19%\n",
      "Epoch [54/100], Step [300/348], Loss: 0.5090, Accuracy: 85.31%\n",
      "train Loss: 0.6441 Acc: 87.80%\n",
      "Epoch [54/100], Step [100/348], Loss: 0.5678, Accuracy: 90.16%\n",
      "val Loss: 1.3052 Acc: 88.38%\n",
      "\n",
      "Epoch 55/100\n",
      "----------\n",
      "Epoch [55/100], Step [100/348], Loss: 1.0569, Accuracy: 87.66%\n",
      "Epoch [55/100], Step [200/348], Loss: 0.7699, Accuracy: 86.09%\n",
      "Epoch [55/100], Step [300/348], Loss: 0.5159, Accuracy: 88.28%\n",
      "train Loss: 0.6325 Acc: 87.77%\n",
      "Epoch [55/100], Step [100/348], Loss: 0.5061, Accuracy: 90.47%\n",
      "val Loss: 1.4372 Acc: 89.38%\n",
      "\n",
      "Epoch 56/100\n",
      "----------\n",
      "Epoch [56/100], Step [100/348], Loss: 0.4772, Accuracy: 87.03%\n",
      "Epoch [56/100], Step [200/348], Loss: 0.5544, Accuracy: 88.28%\n",
      "Epoch [56/100], Step [300/348], Loss: 0.7221, Accuracy: 86.25%\n",
      "train Loss: 0.6286 Acc: 88.18%\n",
      "Epoch [56/100], Step [100/348], Loss: 0.6168, Accuracy: 91.25%\n",
      "val Loss: 1.3897 Acc: 89.55%\n",
      "\n",
      "Epoch 57/100\n",
      "----------\n",
      "Epoch [57/100], Step [100/348], Loss: 0.7057, Accuracy: 86.88%\n",
      "Epoch [57/100], Step [200/348], Loss: 0.4538, Accuracy: 89.69%\n",
      "Epoch [57/100], Step [300/348], Loss: 0.5034, Accuracy: 87.97%\n",
      "train Loss: 0.6394 Acc: 87.94%\n",
      "Epoch [57/100], Step [100/348], Loss: 0.6031, Accuracy: 90.62%\n",
      "val Loss: 1.4084 Acc: 89.99%\n",
      "\n",
      "Epoch 58/100\n",
      "----------\n",
      "Epoch [58/100], Step [100/348], Loss: 0.4445, Accuracy: 90.78%\n",
      "Epoch [58/100], Step [200/348], Loss: 0.4337, Accuracy: 89.53%\n",
      "Epoch [58/100], Step [300/348], Loss: 1.4824, Accuracy: 89.06%\n",
      "train Loss: 0.6187 Acc: 88.07%\n",
      "Epoch [58/100], Step [100/348], Loss: 0.5737, Accuracy: 90.16%\n",
      "val Loss: 1.3902 Acc: 88.95%\n",
      "\n",
      "Epoch 59/100\n",
      "----------\n",
      "Epoch [59/100], Step [100/348], Loss: 0.7397, Accuracy: 88.12%\n",
      "Epoch [59/100], Step [200/348], Loss: 0.4636, Accuracy: 85.47%\n",
      "Epoch [59/100], Step [300/348], Loss: 0.5523, Accuracy: 87.97%\n",
      "train Loss: 0.6095 Acc: 88.22%\n",
      "Epoch [59/100], Step [100/348], Loss: 0.5195, Accuracy: 90.31%\n",
      "val Loss: 1.4516 Acc: 88.48%\n",
      "\n",
      "Epoch 60/100\n",
      "----------\n",
      "Epoch [60/100], Step [100/348], Loss: 0.5248, Accuracy: 90.62%\n",
      "Epoch [60/100], Step [200/348], Loss: 0.6190, Accuracy: 85.62%\n",
      "Epoch [60/100], Step [300/348], Loss: 0.4095, Accuracy: 89.22%\n",
      "train Loss: 0.6193 Acc: 88.33%\n",
      "Epoch [60/100], Step [100/348], Loss: 0.5977, Accuracy: 90.00%\n",
      "val Loss: 1.3195 Acc: 88.37%\n",
      "\n",
      "Epoch 61/100\n",
      "----------\n",
      "Epoch [61/100], Step [100/348], Loss: 0.8395, Accuracy: 87.34%\n",
      "Epoch [61/100], Step [200/348], Loss: 0.4822, Accuracy: 89.06%\n",
      "Epoch [61/100], Step [300/348], Loss: 0.3496, Accuracy: 89.22%\n",
      "train Loss: 0.6067 Acc: 88.26%\n",
      "Epoch [61/100], Step [100/348], Loss: 0.5628, Accuracy: 91.88%\n",
      "val Loss: 1.4087 Acc: 89.94%\n",
      "\n",
      "Epoch 62/100\n",
      "----------\n",
      "Epoch [62/100], Step [100/348], Loss: 0.7080, Accuracy: 87.03%\n",
      "Epoch [62/100], Step [200/348], Loss: 0.5269, Accuracy: 86.41%\n",
      "Epoch [62/100], Step [300/348], Loss: 0.5612, Accuracy: 87.81%\n",
      "train Loss: 0.6178 Acc: 88.38%\n",
      "Epoch [62/100], Step [100/348], Loss: 0.5939, Accuracy: 89.53%\n",
      "val Loss: 1.2983 Acc: 88.54%\n",
      "\n",
      "Epoch 63/100\n",
      "----------\n",
      "Epoch [63/100], Step [100/348], Loss: 0.5634, Accuracy: 87.19%\n",
      "Epoch [63/100], Step [200/348], Loss: 0.4953, Accuracy: 89.84%\n",
      "Epoch [63/100], Step [300/348], Loss: 1.0375, Accuracy: 87.97%\n",
      "train Loss: 0.6074 Acc: 88.30%\n",
      "Epoch [63/100], Step [100/348], Loss: 0.5428, Accuracy: 90.62%\n",
      "val Loss: 1.3544 Acc: 89.62%\n",
      "\n",
      "Epoch 64/100\n",
      "----------\n",
      "Epoch [64/100], Step [100/348], Loss: 0.6555, Accuracy: 90.78%\n",
      "Epoch [64/100], Step [200/348], Loss: 0.7269, Accuracy: 86.41%\n",
      "Epoch [64/100], Step [300/348], Loss: 0.5534, Accuracy: 86.88%\n",
      "train Loss: 0.6037 Acc: 88.46%\n",
      "Epoch [64/100], Step [100/348], Loss: 0.5888, Accuracy: 90.62%\n",
      "val Loss: 1.3416 Acc: 89.53%\n",
      "\n",
      "Epoch 65/100\n",
      "----------\n",
      "Epoch [65/100], Step [100/348], Loss: 0.6187, Accuracy: 89.06%\n",
      "Epoch [65/100], Step [200/348], Loss: 0.6545, Accuracy: 88.12%\n",
      "Epoch [65/100], Step [300/348], Loss: 0.6153, Accuracy: 87.81%\n",
      "train Loss: 0.5870 Acc: 88.54%\n",
      "Epoch [65/100], Step [100/348], Loss: 0.5791, Accuracy: 90.94%\n",
      "val Loss: 1.3112 Acc: 89.49%\n",
      "\n",
      "Epoch 66/100\n",
      "----------\n",
      "Epoch [66/100], Step [100/348], Loss: 0.4329, Accuracy: 88.44%\n",
      "Epoch [66/100], Step [200/348], Loss: 0.6092, Accuracy: 89.84%\n",
      "Epoch [66/100], Step [300/348], Loss: 0.5726, Accuracy: 90.78%\n",
      "train Loss: 0.5766 Acc: 88.58%\n",
      "Epoch [66/100], Step [100/348], Loss: 0.5911, Accuracy: 90.94%\n",
      "val Loss: 1.3717 Acc: 89.62%\n",
      "\n",
      "Epoch 67/100\n",
      "----------\n",
      "Epoch [67/100], Step [100/348], Loss: 0.5115, Accuracy: 88.91%\n",
      "Epoch [67/100], Step [200/348], Loss: 0.4873, Accuracy: 89.22%\n",
      "Epoch [67/100], Step [300/348], Loss: 0.5670, Accuracy: 90.47%\n",
      "train Loss: 0.5798 Acc: 88.71%\n",
      "Epoch [67/100], Step [100/348], Loss: 0.5275, Accuracy: 91.56%\n",
      "val Loss: 1.3682 Acc: 90.05%\n",
      "\n",
      "Epoch 68/100\n",
      "----------\n",
      "Epoch [68/100], Step [100/348], Loss: 0.8385, Accuracy: 88.91%\n",
      "Epoch [68/100], Step [200/348], Loss: 0.3755, Accuracy: 89.69%\n",
      "Epoch [68/100], Step [300/348], Loss: 0.6083, Accuracy: 89.22%\n",
      "train Loss: 0.5742 Acc: 88.89%\n",
      "Epoch [68/100], Step [100/348], Loss: 0.5291, Accuracy: 91.25%\n",
      "val Loss: 1.3287 Acc: 89.99%\n",
      "\n",
      "Epoch 69/100\n",
      "----------\n",
      "Epoch [69/100], Step [100/348], Loss: 0.5270, Accuracy: 89.22%\n",
      "Epoch [69/100], Step [200/348], Loss: 0.8354, Accuracy: 89.53%\n",
      "Epoch [69/100], Step [300/348], Loss: 0.3591, Accuracy: 89.06%\n",
      "train Loss: 0.5700 Acc: 88.86%\n",
      "Epoch [69/100], Step [100/348], Loss: 0.4677, Accuracy: 92.19%\n",
      "val Loss: 1.4042 Acc: 89.82%\n",
      "\n",
      "Epoch 70/100\n",
      "----------\n",
      "Epoch [70/100], Step [100/348], Loss: 0.3834, Accuracy: 90.47%\n",
      "Epoch [70/100], Step [200/348], Loss: 0.3439, Accuracy: 90.47%\n",
      "Epoch [70/100], Step [300/348], Loss: 0.5481, Accuracy: 90.31%\n",
      "train Loss: 0.5937 Acc: 88.73%\n",
      "Epoch [70/100], Step [100/348], Loss: 0.4897, Accuracy: 92.34%\n",
      "val Loss: 1.3133 Acc: 89.58%\n",
      "\n",
      "Epoch 71/100\n",
      "----------\n",
      "Epoch [71/100], Step [100/348], Loss: 0.5333, Accuracy: 87.34%\n",
      "Epoch [71/100], Step [200/348], Loss: 0.3772, Accuracy: 90.31%\n",
      "Epoch [71/100], Step [300/348], Loss: 0.4056, Accuracy: 88.12%\n",
      "train Loss: 0.5652 Acc: 88.78%\n",
      "Epoch [71/100], Step [100/348], Loss: 0.5192, Accuracy: 91.41%\n",
      "val Loss: 1.3112 Acc: 89.93%\n",
      "\n",
      "Epoch 72/100\n",
      "----------\n",
      "Epoch [72/100], Step [100/348], Loss: 0.6902, Accuracy: 90.00%\n",
      "Epoch [72/100], Step [200/348], Loss: 0.4911, Accuracy: 87.34%\n",
      "Epoch [72/100], Step [300/348], Loss: 0.5040, Accuracy: 89.38%\n",
      "train Loss: 0.5690 Acc: 89.08%\n",
      "Epoch [72/100], Step [100/348], Loss: 0.5504, Accuracy: 90.62%\n",
      "val Loss: 1.3258 Acc: 89.88%\n",
      "\n",
      "Epoch 73/100\n",
      "----------\n",
      "Epoch [73/100], Step [100/348], Loss: 0.7492, Accuracy: 90.16%\n",
      "Epoch [73/100], Step [200/348], Loss: 0.4264, Accuracy: 88.44%\n",
      "Epoch [73/100], Step [300/348], Loss: 0.5959, Accuracy: 87.66%\n",
      "train Loss: 0.5692 Acc: 88.97%\n",
      "Epoch [73/100], Step [100/348], Loss: 0.5593, Accuracy: 90.31%\n",
      "val Loss: 1.2734 Acc: 89.90%\n",
      "\n",
      "Epoch 74/100\n",
      "----------\n",
      "Epoch [74/100], Step [100/348], Loss: 0.5241, Accuracy: 87.97%\n",
      "Epoch [74/100], Step [200/348], Loss: 0.3877, Accuracy: 89.84%\n",
      "Epoch [74/100], Step [300/348], Loss: 0.4354, Accuracy: 87.50%\n",
      "train Loss: 0.5723 Acc: 88.78%\n",
      "Epoch [74/100], Step [100/348], Loss: 0.5619, Accuracy: 91.88%\n",
      "val Loss: 1.2954 Acc: 90.45%\n",
      "\n",
      "Epoch 75/100\n",
      "----------\n",
      "Epoch [75/100], Step [100/348], Loss: 0.5743, Accuracy: 88.75%\n",
      "Epoch [75/100], Step [200/348], Loss: 0.4533, Accuracy: 89.69%\n",
      "Epoch [75/100], Step [300/348], Loss: 0.5549, Accuracy: 90.00%\n",
      "train Loss: 0.5608 Acc: 89.14%\n",
      "Epoch [75/100], Step [100/348], Loss: 0.5686, Accuracy: 91.09%\n",
      "val Loss: 1.3232 Acc: 89.99%\n",
      "\n",
      "Epoch 76/100\n",
      "----------\n",
      "Epoch [76/100], Step [100/348], Loss: 0.5297, Accuracy: 88.44%\n",
      "Epoch [76/100], Step [200/348], Loss: 0.6261, Accuracy: 88.28%\n",
      "Epoch [76/100], Step [300/348], Loss: 0.4262, Accuracy: 89.38%\n",
      "train Loss: 0.5514 Acc: 89.27%\n",
      "Epoch [76/100], Step [100/348], Loss: 0.6025, Accuracy: 91.56%\n",
      "val Loss: 1.2976 Acc: 90.04%\n",
      "\n",
      "Epoch 77/100\n",
      "----------\n",
      "Epoch [77/100], Step [100/348], Loss: 0.4315, Accuracy: 88.59%\n",
      "Epoch [77/100], Step [200/348], Loss: 0.5535, Accuracy: 89.38%\n",
      "Epoch [77/100], Step [300/348], Loss: 0.5377, Accuracy: 89.22%\n",
      "train Loss: 0.5532 Acc: 89.28%\n",
      "Epoch [77/100], Step [100/348], Loss: 0.5362, Accuracy: 92.66%\n",
      "val Loss: 1.3441 Acc: 90.48%\n",
      "\n",
      "Epoch 78/100\n",
      "----------\n",
      "Epoch [78/100], Step [100/348], Loss: 0.6537, Accuracy: 88.75%\n",
      "Epoch [78/100], Step [200/348], Loss: 0.4130, Accuracy: 88.12%\n",
      "Epoch [78/100], Step [300/348], Loss: 0.5997, Accuracy: 89.69%\n",
      "train Loss: 0.5592 Acc: 89.19%\n",
      "Epoch [78/100], Step [100/348], Loss: 0.5506, Accuracy: 91.25%\n",
      "val Loss: 1.2899 Acc: 89.94%\n",
      "\n",
      "Epoch 79/100\n",
      "----------\n",
      "Epoch [79/100], Step [100/348], Loss: 0.6919, Accuracy: 88.91%\n",
      "Epoch [79/100], Step [200/348], Loss: 0.4771, Accuracy: 89.06%\n",
      "Epoch [79/100], Step [300/348], Loss: 0.8046, Accuracy: 89.84%\n",
      "train Loss: 0.5437 Acc: 89.37%\n",
      "Epoch [79/100], Step [100/348], Loss: 0.5905, Accuracy: 92.19%\n",
      "val Loss: 1.3206 Acc: 90.59%\n",
      "\n",
      "Epoch 80/100\n",
      "----------\n",
      "Epoch [80/100], Step [100/348], Loss: 0.4873, Accuracy: 90.47%\n",
      "Epoch [80/100], Step [200/348], Loss: 0.4642, Accuracy: 88.28%\n",
      "Epoch [80/100], Step [300/348], Loss: 0.3768, Accuracy: 89.53%\n",
      "train Loss: 0.5619 Acc: 89.19%\n",
      "Epoch [80/100], Step [100/348], Loss: 0.5662, Accuracy: 92.50%\n",
      "val Loss: 1.2961 Acc: 90.76%\n",
      "\n",
      "Epoch 81/100\n",
      "----------\n",
      "Epoch [81/100], Step [100/348], Loss: 0.6673, Accuracy: 90.31%\n",
      "Epoch [81/100], Step [200/348], Loss: 0.5005, Accuracy: 90.78%\n",
      "Epoch [81/100], Step [300/348], Loss: 0.5346, Accuracy: 89.06%\n",
      "train Loss: 0.5419 Acc: 89.51%\n",
      "Epoch [81/100], Step [100/348], Loss: 0.5867, Accuracy: 91.88%\n",
      "val Loss: 1.2836 Acc: 90.16%\n",
      "\n",
      "Epoch 82/100\n",
      "----------\n",
      "Epoch [82/100], Step [100/348], Loss: 0.5316, Accuracy: 89.38%\n",
      "Epoch [82/100], Step [200/348], Loss: 0.4998, Accuracy: 88.44%\n",
      "Epoch [82/100], Step [300/348], Loss: 0.3439, Accuracy: 89.06%\n",
      "train Loss: 0.5636 Acc: 89.22%\n",
      "Epoch [82/100], Step [100/348], Loss: 0.5683, Accuracy: 91.56%\n",
      "val Loss: 1.2857 Acc: 90.41%\n",
      "\n",
      "Epoch 83/100\n",
      "----------\n",
      "Epoch [83/100], Step [100/348], Loss: 0.6430, Accuracy: 87.03%\n",
      "Epoch [83/100], Step [200/348], Loss: 0.4888, Accuracy: 90.94%\n",
      "Epoch [83/100], Step [300/348], Loss: 0.6740, Accuracy: 90.94%\n",
      "train Loss: 0.5389 Acc: 89.56%\n",
      "Epoch [83/100], Step [100/348], Loss: 0.6026, Accuracy: 92.19%\n",
      "val Loss: 1.2526 Acc: 90.41%\n",
      "\n",
      "Epoch 84/100\n",
      "----------\n",
      "Epoch [84/100], Step [100/348], Loss: 1.1179, Accuracy: 88.75%\n",
      "Epoch [84/100], Step [200/348], Loss: 0.3784, Accuracy: 89.69%\n",
      "Epoch [84/100], Step [300/348], Loss: 0.4444, Accuracy: 91.25%\n",
      "train Loss: 0.5454 Acc: 89.48%\n",
      "Epoch [84/100], Step [100/348], Loss: 0.5705, Accuracy: 91.25%\n",
      "val Loss: 1.2643 Acc: 90.19%\n",
      "\n",
      "Epoch 85/100\n",
      "----------\n",
      "Epoch [85/100], Step [100/348], Loss: 0.7998, Accuracy: 88.75%\n",
      "Epoch [85/100], Step [200/348], Loss: 0.5162, Accuracy: 90.16%\n",
      "Epoch [85/100], Step [300/348], Loss: 0.4195, Accuracy: 89.53%\n",
      "train Loss: 0.5238 Acc: 89.55%\n",
      "Epoch [85/100], Step [100/348], Loss: 0.5420, Accuracy: 91.25%\n",
      "val Loss: 1.2939 Acc: 90.32%\n",
      "\n",
      "Epoch 86/100\n",
      "----------\n",
      "Epoch [86/100], Step [100/348], Loss: 0.3990, Accuracy: 91.09%\n",
      "Epoch [86/100], Step [200/348], Loss: 0.4971, Accuracy: 89.53%\n",
      "Epoch [86/100], Step [300/348], Loss: 0.4711, Accuracy: 87.34%\n",
      "train Loss: 0.5308 Acc: 89.66%\n",
      "Epoch [86/100], Step [100/348], Loss: 0.5828, Accuracy: 92.19%\n",
      "val Loss: 1.2952 Acc: 90.95%\n",
      "\n",
      "Epoch 87/100\n",
      "----------\n",
      "Epoch [87/100], Step [100/348], Loss: 0.3857, Accuracy: 88.28%\n",
      "Epoch [87/100], Step [200/348], Loss: 0.5939, Accuracy: 89.22%\n",
      "Epoch [87/100], Step [300/348], Loss: 0.5988, Accuracy: 89.38%\n",
      "train Loss: 0.5394 Acc: 89.73%\n",
      "Epoch [87/100], Step [100/348], Loss: 0.6111, Accuracy: 91.41%\n",
      "val Loss: 1.2223 Acc: 90.17%\n",
      "\n",
      "Epoch 88/100\n",
      "----------\n",
      "Epoch [88/100], Step [100/348], Loss: 1.6338, Accuracy: 89.06%\n",
      "Epoch [88/100], Step [200/348], Loss: 0.3696, Accuracy: 90.78%\n",
      "Epoch [88/100], Step [300/348], Loss: 0.3858, Accuracy: 90.16%\n",
      "train Loss: 0.5302 Acc: 89.66%\n",
      "Epoch [88/100], Step [100/348], Loss: 0.5329, Accuracy: 91.88%\n",
      "val Loss: 1.2888 Acc: 90.76%\n",
      "\n",
      "Epoch 89/100\n",
      "----------\n",
      "Epoch [89/100], Step [100/348], Loss: 0.6866, Accuracy: 88.28%\n",
      "Epoch [89/100], Step [200/348], Loss: 0.5368, Accuracy: 91.88%\n",
      "Epoch [89/100], Step [300/348], Loss: 1.0203, Accuracy: 87.97%\n",
      "train Loss: 0.5321 Acc: 89.86%\n",
      "Epoch [89/100], Step [100/348], Loss: 0.5394, Accuracy: 92.34%\n",
      "val Loss: 1.2381 Acc: 90.56%\n",
      "\n",
      "Epoch 90/100\n",
      "----------\n",
      "Epoch [90/100], Step [100/348], Loss: 0.5485, Accuracy: 89.06%\n",
      "Epoch [90/100], Step [200/348], Loss: 0.4017, Accuracy: 90.94%\n",
      "Epoch [90/100], Step [300/348], Loss: 0.5237, Accuracy: 88.91%\n",
      "train Loss: 0.5113 Acc: 89.89%\n",
      "Epoch [90/100], Step [100/348], Loss: 0.5237, Accuracy: 92.66%\n",
      "val Loss: 1.2777 Acc: 90.65%\n",
      "\n",
      "Epoch 91/100\n",
      "----------\n",
      "Epoch [91/100], Step [100/348], Loss: 0.4340, Accuracy: 89.38%\n",
      "Epoch [91/100], Step [200/348], Loss: 0.4254, Accuracy: 90.47%\n",
      "Epoch [91/100], Step [300/348], Loss: 0.3540, Accuracy: 90.94%\n",
      "train Loss: 0.5065 Acc: 89.98%\n",
      "Epoch [91/100], Step [100/348], Loss: 0.5511, Accuracy: 92.66%\n",
      "val Loss: 1.2382 Acc: 90.62%\n",
      "\n",
      "Epoch 92/100\n",
      "----------\n",
      "Epoch [92/100], Step [100/348], Loss: 0.3855, Accuracy: 91.41%\n",
      "Epoch [92/100], Step [200/348], Loss: 0.5649, Accuracy: 90.00%\n",
      "Epoch [92/100], Step [300/348], Loss: 0.4874, Accuracy: 92.66%\n",
      "train Loss: 0.5177 Acc: 89.75%\n",
      "Epoch [92/100], Step [100/348], Loss: 0.5477, Accuracy: 91.72%\n",
      "val Loss: 1.2504 Acc: 90.58%\n",
      "\n",
      "Epoch 93/100\n",
      "----------\n",
      "Epoch [93/100], Step [100/348], Loss: 0.5449, Accuracy: 89.22%\n",
      "Epoch [93/100], Step [200/348], Loss: 0.3492, Accuracy: 90.94%\n",
      "Epoch [93/100], Step [300/348], Loss: 0.4158, Accuracy: 89.06%\n",
      "train Loss: 0.4965 Acc: 90.03%\n",
      "Epoch [93/100], Step [100/348], Loss: 0.5406, Accuracy: 92.66%\n",
      "val Loss: 1.2990 Acc: 90.73%\n",
      "\n",
      "Epoch 94/100\n",
      "----------\n",
      "Epoch [94/100], Step [100/348], Loss: 0.4830, Accuracy: 91.09%\n",
      "Epoch [94/100], Step [200/348], Loss: 0.3506, Accuracy: 89.22%\n",
      "Epoch [94/100], Step [300/348], Loss: 0.5143, Accuracy: 89.69%\n",
      "train Loss: 0.4990 Acc: 90.08%\n",
      "Epoch [94/100], Step [100/348], Loss: 0.5876, Accuracy: 92.03%\n",
      "val Loss: 1.2718 Acc: 90.65%\n",
      "\n",
      "Epoch 95/100\n",
      "----------\n",
      "Epoch [95/100], Step [100/348], Loss: 0.7038, Accuracy: 91.25%\n",
      "Epoch [95/100], Step [200/348], Loss: 0.4877, Accuracy: 91.09%\n",
      "Epoch [95/100], Step [300/348], Loss: 0.4516, Accuracy: 90.47%\n",
      "train Loss: 0.5078 Acc: 90.00%\n",
      "Epoch [95/100], Step [100/348], Loss: 0.5677, Accuracy: 91.88%\n",
      "val Loss: 1.2286 Acc: 90.81%\n",
      "\n",
      "Epoch 96/100\n",
      "----------\n",
      "Epoch [96/100], Step [100/348], Loss: 0.5049, Accuracy: 88.44%\n",
      "Epoch [96/100], Step [200/348], Loss: 0.7165, Accuracy: 91.25%\n",
      "Epoch [96/100], Step [300/348], Loss: 0.3287, Accuracy: 90.62%\n",
      "train Loss: 0.5109 Acc: 90.02%\n",
      "Epoch [96/100], Step [100/348], Loss: 0.5461, Accuracy: 91.72%\n",
      "val Loss: 1.2599 Acc: 90.64%\n",
      "\n",
      "Epoch 97/100\n",
      "----------\n",
      "Epoch [97/100], Step [100/348], Loss: 0.4735, Accuracy: 89.84%\n",
      "Epoch [97/100], Step [200/348], Loss: 0.4265, Accuracy: 89.06%\n",
      "Epoch [97/100], Step [300/348], Loss: 1.2553, Accuracy: 90.16%\n",
      "train Loss: 0.5080 Acc: 89.94%\n",
      "Epoch [97/100], Step [100/348], Loss: 0.5682, Accuracy: 92.19%\n",
      "val Loss: 1.2420 Acc: 90.55%\n",
      "\n",
      "Epoch 98/100\n",
      "----------\n",
      "Epoch [98/100], Step [100/348], Loss: 0.4640, Accuracy: 91.56%\n",
      "Epoch [98/100], Step [200/348], Loss: 0.3981, Accuracy: 90.62%\n",
      "Epoch [98/100], Step [300/348], Loss: 0.4081, Accuracy: 90.16%\n",
      "train Loss: 0.5089 Acc: 89.95%\n",
      "Epoch [98/100], Step [100/348], Loss: 0.5603, Accuracy: 91.88%\n",
      "val Loss: 1.2888 Acc: 90.95%\n",
      "\n",
      "Epoch 99/100\n",
      "----------\n",
      "Epoch [99/100], Step [100/348], Loss: 0.3108, Accuracy: 92.66%\n",
      "Epoch [99/100], Step [200/348], Loss: 0.3859, Accuracy: 90.47%\n",
      "Epoch [99/100], Step [300/348], Loss: 0.4490, Accuracy: 90.00%\n",
      "train Loss: 0.5032 Acc: 90.16%\n",
      "Epoch [99/100], Step [100/348], Loss: 0.5209, Accuracy: 91.41%\n",
      "val Loss: 1.2805 Acc: 90.73%\n",
      "\n",
      "Epoch 100/100\n",
      "----------\n",
      "Epoch [100/100], Step [100/348], Loss: 0.4408, Accuracy: 90.47%\n",
      "Epoch [100/100], Step [200/348], Loss: 0.4052, Accuracy: 90.00%\n",
      "Epoch [100/100], Step [300/348], Loss: 0.3813, Accuracy: 88.75%\n",
      "train Loss: 0.5052 Acc: 90.10%\n",
      "Epoch [100/100], Step [100/348], Loss: 0.4948, Accuracy: 92.34%\n",
      "val Loss: 1.2427 Acc: 90.96%\n",
      "\n",
      "Training complete in 136m 56s\n",
      "Best val Acc: 0.804688\n",
      "Best loss: 0.848011\n"
     ]
    }
   ],
   "source": [
    "# Observe that all parameters are being optimized\n",
    "optimizer = optim.Adam(params_to_update, lr=lr_start)\n",
    "\n",
    "# Learning rate scheduler.\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs, eta_min=lr_end,\n",
    "                                                 last_epoch=-1)\n",
    "\n",
    "\n",
    "# Setup the loss fxn\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "\n",
    "# Train and evaluate\n",
    "model_pyt, prof, val_history, train_history = train_model(device, model_pyt, data_loaders, \n",
    "                                                            optimizer, scheduler,\n",
    "                                                            criterion, \n",
    "                                                            num_epochs=num_epochs,\n",
    "                                                            num_classes=num_classes,\n",
    "                                                            is_inception=(model_name==\"inceptionv3\"),\n",
    "                                                            profiler=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'ads'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "zM-dorQBJAZb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_model(model_pyt.state_dict(), '../models/', \n",
    "           f'{model_name}_{dataset_name}_{num_epochs}_{batch_size}_{lr_start}_{lr_end}_model_weights.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_metrics = eval_model(device=device, model=model_pyt, test_loader=data_loaders['test'], is_inception=(model_name==\"inceptionv3\"), num_classes=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 2.294411945812808\n",
      "f1: 0.19441178208659088\n",
      "cm: [[[2841  358]\n",
      "  [ 309  204]]\n",
      "\n",
      " [[3147  336]\n",
      "  [ 184   45]]\n",
      "\n",
      " [[2797  890]\n",
      "  [  13   12]]\n",
      "\n",
      " [[2853  799]\n",
      "  [  29   31]]\n",
      "\n",
      " [[2915  753]\n",
      "  [  24   20]]\n",
      "\n",
      " [[3123  504]\n",
      "  [  59   26]]\n",
      "\n",
      " [[2536 1057]\n",
      "  [  77   42]]\n",
      "\n",
      " [[3143  498]\n",
      "  [  54   17]]\n",
      "\n",
      " [[2665  262]\n",
      "  [ 624  161]]\n",
      "\n",
      " [[2646  115]\n",
      "  [ 538  413]]\n",
      "\n",
      " [[2986  569]\n",
      "  [  84   73]]\n",
      "\n",
      " [[2923  768]\n",
      "  [  11   10]]\n",
      "\n",
      " [[2797   94]\n",
      "  [ 479  342]]\n",
      "\n",
      " [[2999  211]\n",
      "  [ 191  311]]\n",
      "\n",
      " [[3042  453]\n",
      "  [ 118   99]]\n",
      "\n",
      " [[2881  810]\n",
      "  [   8   13]]\n",
      "\n",
      " [[3064  519]\n",
      "  [  46   83]]\n",
      "\n",
      " [[2738  886]\n",
      "  [  46   42]]\n",
      "\n",
      " [[3255  398]\n",
      "  [  19   40]]\n",
      "\n",
      " [[2236 1420]\n",
      "  [   9   47]]]\n",
      "outputs: [[0. 0. 1. ... 1. 0. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 1. 0. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "targets: [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "for i, v in eval_metrics.items():\n",
    "    print(f\"{i}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'../models/val_history_{model_name}_{dataset_name}_{num_epochs}_{batch_size}_{lr_start}_{lr_end}_.pickle', 'wb') as handle:\n",
    "    pickle.dump(val_history, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open(f'../models/train_history_{model_name}_{dataset_name}_{num_epochs}_{batch_size}_{lr_start}_{lr_end}_.pickle', 'wb') as handle:\n",
    "    pickle.dump(train_history, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open(f'../models/eval_metrics_{model_name}_{dataset_name}_{num_epochs}_{batch_size}_{lr_start}_{lr_end}_.pickle', 'wb') as handle:\n",
    "    pickle.dump(eval_metrics, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "#with open('filename.pickle', 'rb') as handle:\n",
    "#    b = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WvFygat_aiDN"
   },
   "outputs": [],
   "source": [
    "#print(prof.key_averages(group_by_stack_n=5).table(sort_by='self_cpu_time_total', row_limit=50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "EQ6hb3iO2mXv"
   },
   "outputs": [],
   "source": [
    "# Plot the training curves of validation accuracy vs. number\n",
    "#  of training epochs for the transfer learning method and\n",
    "#  the model trained from scratch\n",
    "# vhist = []\n",
    "# vhist = [h.cpu().numpy() for h in val_acc_history]\n",
    "# thist = []\n",
    "# thist = [h.cpu().numpy() for h in train_acc_history]\n",
    "\n",
    "# plt.title(\"Accuracy vs. Number of Training Epochs\")\n",
    "# plt.xlabel(\"Training Epochs\")\n",
    "# plt.ylabel(\"Accuracy\")\n",
    "# #plt.plot(range(1,num_epochs+1),ohist,label=\"Pretrained\")\n",
    "# plt.plot(range(1,num_epochs+1),vhist,label=\"Validation\")\n",
    "# plt.plot(range(1,num_epochs+1),thist,label=\"Training\")\n",
    "# plt.ylim((0,1.))\n",
    "# plt.xticks(np.arange(1, num_epochs+1, 1.0))\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "aXpHASjTUE_Q"
   },
   "outputs": [],
   "source": [
    "# Plot the training curves of validation accuracy vs. number\n",
    "#  of training epochs for the transfer learning method and\n",
    "#  the model trained from scratch\n",
    "# vhist = []\n",
    "# vhist = [h for h in val_loss_history]\n",
    "# thist = []\n",
    "# thist = [h for h in train_loss_history]\n",
    "\n",
    "# plt.title(\"Loss vs. Number of Training Epochs\")\n",
    "# plt.xlabel(\"Training Epochs\")\n",
    "# plt.ylabel(\"Loss\")\n",
    "# #plt.plot(range(1,num_epochs+1),ohist,label=\"Pretrained\")\n",
    "# plt.plot(range(1,num_epochs+1),vhist,label=\"Validation\")\n",
    "# plt.plot(range(1,num_epochs+1),thist,label=\"Training\")\n",
    "# plt.ylim((0,1.))\n",
    "# plt.xticks(np.arange(1, num_epochs+1, 1.0))\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3.9.13 ('dl')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "8663be1127523d7121742bbf948a8b1c8dd9a63c15e224e5108ff87b090569d5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
