{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train for 50 epochs. First use only fine tuning on last layer\n",
    "## Then compare with fine-tuning entire network\n",
    "## TODO: \n",
    "## 0. Pre-process images\n",
    "##      Resize images\n",
    "##      Other pre-processing\n",
    "## 0.1. Check image colors\n",
    "## 1. Get mean and std of dataset - done\n",
    "## 2. Train on Resnet-34\n",
    "## 3. Train on efficient net b3\n",
    "## 4. Train on mobilenet v3 large\n",
    "## 5. Write a script to plot loss + accuracy graph\n",
    "## 6. Get FLOPs\n",
    "## 7. Get num layers\n",
    "## 8. Add class weights - done\n",
    "## 9. Implement gradcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from multilabel.train import train_model\n",
    "from model import initialize_model\n",
    "from utils import set_requires_grad, save_model\n",
    "from multilabel.data import load_data\n",
    "from plotting import plot_data_loader\n",
    "from multilabel.eval import eval_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "0w24yf-Tj47H"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import time\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "from numpy.random import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.io import read_image\n",
    "import torchvision.transforms as T\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, models, transforms\n",
    "import torch.autograd.profiler as tprofiler\n",
    "import torch.utils.data as td\n",
    "\n",
    "plt.rcParams[\"savefig.bbox\"] = 'tight'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "O7W8BTtF3BN1"
   },
   "outputs": [],
   "source": [
    "seed = 42\n",
    "\n",
    "random.seed(seed)\n",
    "\n",
    "# pytorch RNGs\n",
    "torch.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "if torch.cuda.is_available(): torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "# numpy RNG\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "21_bts2Wj47M",
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_dir = \"../data\"\n",
    "images_dir = \"../data/processed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "nr7fQfkuj47u"
   },
   "outputs": [],
   "source": [
    "# Get best num_workers\n",
    "# for i in range(97):\n",
    "#     start = time.time()\n",
    "#     data_loader = load_data(images_dir,\n",
    "#                                                                    batch_size = 96, \n",
    "#                                                                    input_size = 299, \n",
    "#                                                                    norm_arr = ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "#                                                                    num_workers = i)\n",
    "#     iter(data_loader['train']).next()[0].shape\n",
    "#     print(f\"{i}: {time.time()-start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "96wB0P9Gj47u"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k-vpcOXE1pmg",
    "outputId": "25752964-a425-490c-d154-0cc8baab3b61"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Check if GPU is available.\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "# Models options: resnet50, resnet34, inceptionv3, vgg16, mobile_net_v3_large, efficient_net_b1, efficient_net_b0, efficient_net_b3.\n",
    "model_name = \"efficient_net_b3\"\n",
    "\n",
    "# Number of classes.\n",
    "num_classes = 20\n",
    "\n",
    "# Batch Size.\n",
    "batch_size = 32\n",
    "\n",
    "# Epochs to train for.\n",
    "num_epochs = 10\n",
    "\n",
    "# Number of workers for data loader.\n",
    "num_workers = 12\n",
    "\n",
    "# Imagenet norm array passed as default value.\n",
    "# norm_arr=([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "# Chest x-ray8 training dataset metrics \n",
    "norm_arr=((0.5989, 0.5510, 0.5175), (0.3358, 0.3330, 0.3377))\n",
    "\n",
    "# Feature extract flag: False - Tune the whole model,\n",
    "#                       True - Update only the reshaped layer parameters.\n",
    "feature_extract = True\n",
    "\n",
    "# Use pretrained flag: None - Use random weights\n",
    "#                      String - Use pretrained weights given by String\n",
    "use_pretrained = models.EfficientNet_B3_Weights.IMAGENET1K_V1\n",
    "\n",
    "# Initialize the model for this run.\n",
    "model_pyt, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=use_pretrained)\n",
    "\n",
    "# lr start and end points for training.\n",
    "lr_start = 0.01\n",
    "lr_end = 0.001\n",
    "\n",
    "# Print the model we just instantiated\n",
    "#print(model_ft)\n",
    "\n",
    "# Positive class weights.\n",
    "pos_weight=torch.as_tensor([ 2.3509,  6.4782, 76.3264, 23.6350, 46.7897, 18.5694, 14.4224, 24.4805,\n",
    "         1.1795,  0.6394,  9.1227, 80.2774,  0.8743,  2.1217,  7.2973, 87.3730,\n",
    "        12.8151, 23.7444, 28.1492, 29.6749], dtype=torch.float)\n",
    "pos_weight = pos_weight.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "e9FOwaso3LAc"
   },
   "outputs": [],
   "source": [
    "data_loaders = load_data(images_dir,\n",
    "                         batch_size = batch_size, \n",
    "                         input_size = input_size, \n",
    "                         norm_arr = norm_arr,\n",
    "                         num_workers = num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Active',\n",
       " 'Alert',\n",
       " 'Amazed',\n",
       " 'Amused',\n",
       " 'Calm',\n",
       " 'Cheerful',\n",
       " 'Confident',\n",
       " 'Conscious',\n",
       " 'Creative',\n",
       " 'Eager',\n",
       " 'Educated',\n",
       " 'Emotional',\n",
       " 'Fashionable',\n",
       " 'Feminine',\n",
       " 'Inspired',\n",
       " 'Loving',\n",
       " 'Manly',\n",
       " 'Persuaded',\n",
       " 'Thrifty',\n",
       " 'Youthful']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_loaders['train'].dataset.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_data_loader(data_loaders['train'], (2,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 392
    },
    "id": "vacZgHSCj47u",
    "outputId": "35a65cef-1d6d-4657-ff01-be15854ca24b"
   },
   "source": [
    "plot_data_loader(data_loader['train'], (2,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zRIOYWbV1cnS"
   },
   "source": [
    "plot_data_loader(data_loader['test'], (2,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "znBg5tkd1dXF"
   },
   "source": [
    "plot_data_loader(data_loader['val'], (2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "0rj7Qeg41wLm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params to learn:\n",
      "\t classifier.1.weight\n",
      "\t classifier.1.bias\n"
     ]
    }
   ],
   "source": [
    "#model_pyt = torch.compile(model_pyt)\n",
    "# Send model to GPU\n",
    "model_pyt = model_pyt.to(device)\n",
    "\n",
    "# Find parameters to be updated in this run.\n",
    "# parameters with requires_grad = True.\n",
    "params_to_update = model_pyt.parameters()\n",
    "print(\"Params to learn:\")\n",
    "if feature_extract:\n",
    "    params_to_update = []\n",
    "    for name,param in model_pyt.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            params_to_update.append(param)\n",
    "            print(\"\\t\",name)\n",
    "else:\n",
    "    for name,param in model_pyt.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            print(\"\\t\",name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "A4B1-pfYm0Ea"
   },
   "outputs": [],
   "source": [
    "# 17 min 1 epoch - 128 batch size - inception\n",
    "# Efficientnet b0 - batch 96 - epoch 50 - num_workers 2 - flip, auto cont, sharp - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8wBR8vcG2jcd",
    "outputId": "7d01aa07-d235-4cb6-dfaf-53ce0c5a577d",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "----------\n",
      "Epoch [1/10], Step [100/348], Loss: 0.7574, Accuracy: 83.44%\n",
      "Epoch [1/10], Step [200/348], Loss: 0.7917, Accuracy: 86.72%\n",
      "Epoch [1/10], Step [300/348], Loss: 0.7396, Accuracy: 85.94%\n",
      "train Loss: 0.9514 Acc: 84.04%\n",
      "Epoch [1/10], Step [100/348], Loss: 0.6606, Accuracy: 82.19%\n",
      "val Loss: 0.8480 Acc: 80.47%\n",
      "\n",
      "Epoch 2/10\n",
      "----------\n",
      "Epoch [2/10], Step [100/348], Loss: 0.5354, Accuracy: 80.31%\n",
      "Epoch [2/10], Step [200/348], Loss: 0.8962, Accuracy: 83.59%\n",
      "Epoch [2/10], Step [300/348], Loss: 1.0052, Accuracy: 83.12%\n",
      "train Loss: 0.7994 Acc: 84.59%\n",
      "Epoch [2/10], Step [100/348], Loss: 0.6987, Accuracy: 85.31%\n",
      "val Loss: 0.8680 Acc: 83.71%\n",
      "\n",
      "Epoch 3/10\n",
      "----------\n",
      "Epoch [3/10], Step [100/348], Loss: 0.5917, Accuracy: 86.56%\n",
      "Epoch [3/10], Step [200/348], Loss: 0.9824, Accuracy: 83.91%\n",
      "Epoch [3/10], Step [300/348], Loss: 0.7653, Accuracy: 80.62%\n",
      "train Loss: 0.7882 Acc: 84.66%\n",
      "Epoch [3/10], Step [100/348], Loss: 0.5442, Accuracy: 85.94%\n",
      "val Loss: 0.9042 Acc: 83.50%\n",
      "\n",
      "Epoch 4/10\n",
      "----------\n",
      "Epoch [4/10], Step [100/348], Loss: 0.6651, Accuracy: 85.78%\n",
      "Epoch [4/10], Step [200/348], Loss: 0.5854, Accuracy: 86.88%\n",
      "Epoch [4/10], Step [300/348], Loss: 0.8185, Accuracy: 86.41%\n",
      "train Loss: 0.7561 Acc: 85.43%\n",
      "Epoch [4/10], Step [100/348], Loss: 0.5555, Accuracy: 86.41%\n",
      "val Loss: 0.9368 Acc: 84.19%\n",
      "\n",
      "Epoch 5/10\n",
      "----------\n",
      "Epoch [5/10], Step [100/348], Loss: 0.5144, Accuracy: 87.66%\n",
      "Epoch [5/10], Step [200/348], Loss: 0.6285, Accuracy: 84.53%\n",
      "Epoch [5/10], Step [300/348], Loss: 0.8231, Accuracy: 85.78%\n",
      "train Loss: 0.6988 Acc: 86.06%\n",
      "Epoch [5/10], Step [100/348], Loss: 0.5084, Accuracy: 87.03%\n",
      "val Loss: 0.9580 Acc: 85.75%\n",
      "\n",
      "Epoch 6/10\n",
      "----------\n",
      "Epoch [6/10], Step [100/348], Loss: 0.5679, Accuracy: 83.91%\n",
      "Epoch [6/10], Step [200/348], Loss: 0.5638, Accuracy: 87.81%\n",
      "Epoch [6/10], Step [300/348], Loss: 0.6302, Accuracy: 86.88%\n",
      "train Loss: 0.6773 Acc: 86.53%\n",
      "Epoch [6/10], Step [100/348], Loss: 0.5451, Accuracy: 87.03%\n",
      "val Loss: 0.9249 Acc: 86.57%\n",
      "\n",
      "Epoch 7/10\n",
      "----------\n",
      "Epoch [7/10], Step [100/348], Loss: 0.5491, Accuracy: 89.06%\n",
      "Epoch [7/10], Step [200/348], Loss: 0.6054, Accuracy: 85.62%\n",
      "Epoch [7/10], Step [300/348], Loss: 0.4795, Accuracy: 87.81%\n",
      "train Loss: 0.6269 Acc: 87.23%\n",
      "Epoch [7/10], Step [100/348], Loss: 0.5174, Accuracy: 89.53%\n",
      "val Loss: 0.9015 Acc: 87.02%\n",
      "\n",
      "Epoch 8/10\n",
      "----------\n",
      "Epoch [8/10], Step [100/348], Loss: 0.6261, Accuracy: 86.41%\n",
      "Epoch [8/10], Step [200/348], Loss: 0.5210, Accuracy: 86.56%\n",
      "Epoch [8/10], Step [300/348], Loss: 0.5441, Accuracy: 89.22%\n",
      "train Loss: 0.5909 Acc: 87.81%\n",
      "Epoch [8/10], Step [100/348], Loss: 0.5220, Accuracy: 90.31%\n",
      "val Loss: 0.9149 Acc: 88.28%\n",
      "\n",
      "Epoch 9/10\n",
      "----------\n",
      "Epoch [9/10], Step [100/348], Loss: 0.4931, Accuracy: 86.72%\n",
      "Epoch [9/10], Step [200/348], Loss: 0.6648, Accuracy: 85.62%\n",
      "Epoch [9/10], Step [300/348], Loss: 0.5406, Accuracy: 88.12%\n",
      "train Loss: 0.5764 Acc: 88.44%\n",
      "Epoch [9/10], Step [100/348], Loss: 0.4799, Accuracy: 90.62%\n",
      "val Loss: 0.9030 Acc: 88.53%\n",
      "\n",
      "Epoch 10/10\n",
      "----------\n",
      "Epoch [10/10], Step [100/348], Loss: 0.6397, Accuracy: 90.62%\n",
      "Epoch [10/10], Step [200/348], Loss: 0.5204, Accuracy: 88.12%\n",
      "Epoch [10/10], Step [300/348], Loss: 0.5311, Accuracy: 88.59%\n",
      "train Loss: 0.5561 Acc: 88.59%\n",
      "Epoch [10/10], Step [100/348], Loss: 0.4959, Accuracy: 90.16%\n",
      "val Loss: 0.9129 Acc: 88.48%\n",
      "\n",
      "Training complete in 15m 45s\n",
      "Best val Acc: 0.804688\n",
      "Best loss: 0.848011\n"
     ]
    }
   ],
   "source": [
    "# Observe that all parameters are being optimized\n",
    "optimizer = optim.Adam(params_to_update, lr=lr_start)\n",
    "\n",
    "# Learning rate scheduler.\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs, eta_min=lr_end,\n",
    "                                                 last_epoch=-1)\n",
    "\n",
    "\n",
    "# Setup the loss fxn\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "\n",
    "# Train and evaluate\n",
    "model_pyt, prof, val_history, train_history = train_model(device, model_pyt, data_loaders, \n",
    "                                                            optimizer, scheduler,\n",
    "                                                            criterion, \n",
    "                                                            num_epochs=num_epochs,\n",
    "                                                            num_classes=num_classes,\n",
    "                                                            is_inception=(model_name==\"inceptionv3\"),\n",
    "                                                            profiler=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'ads'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "zM-dorQBJAZb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_model(model_pyt.state_dict(), '../models/', \n",
    "           f'{model_name}_{dataset_name}_{num_epochs}_{batch_size}_{lr_start}_{lr_end}_model_weights.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_metrics = eval_model(device=device, model=model_pyt, test_loader=data_loaders['test'], is_inception=(model_name==\"inceptionv3\"), num_classes=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 2.294411945812808\n",
      "f1: 0.19441178208659088\n",
      "cm: [[[2841  358]\n",
      "  [ 309  204]]\n",
      "\n",
      " [[3147  336]\n",
      "  [ 184   45]]\n",
      "\n",
      " [[2797  890]\n",
      "  [  13   12]]\n",
      "\n",
      " [[2853  799]\n",
      "  [  29   31]]\n",
      "\n",
      " [[2915  753]\n",
      "  [  24   20]]\n",
      "\n",
      " [[3123  504]\n",
      "  [  59   26]]\n",
      "\n",
      " [[2536 1057]\n",
      "  [  77   42]]\n",
      "\n",
      " [[3143  498]\n",
      "  [  54   17]]\n",
      "\n",
      " [[2665  262]\n",
      "  [ 624  161]]\n",
      "\n",
      " [[2646  115]\n",
      "  [ 538  413]]\n",
      "\n",
      " [[2986  569]\n",
      "  [  84   73]]\n",
      "\n",
      " [[2923  768]\n",
      "  [  11   10]]\n",
      "\n",
      " [[2797   94]\n",
      "  [ 479  342]]\n",
      "\n",
      " [[2999  211]\n",
      "  [ 191  311]]\n",
      "\n",
      " [[3042  453]\n",
      "  [ 118   99]]\n",
      "\n",
      " [[2881  810]\n",
      "  [   8   13]]\n",
      "\n",
      " [[3064  519]\n",
      "  [  46   83]]\n",
      "\n",
      " [[2738  886]\n",
      "  [  46   42]]\n",
      "\n",
      " [[3255  398]\n",
      "  [  19   40]]\n",
      "\n",
      " [[2236 1420]\n",
      "  [   9   47]]]\n",
      "outputs: [[0. 0. 1. ... 1. 0. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 1. 0. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "targets: [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "for i, v in eval_metrics.items():\n",
    "    print(f\"{i}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'../models/val_history_{model_name}_{dataset_name}_{num_epochs}_{batch_size}_{lr_start}_{lr_end}_.pickle', 'wb') as handle:\n",
    "    pickle.dump(val_history, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open(f'../models/train_history_{model_name}_{dataset_name}_{num_epochs}_{batch_size}_{lr_start}_{lr_end}_.pickle', 'wb') as handle:\n",
    "    pickle.dump(train_history, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open(f'../models/eval_metrics_{model_name}_{dataset_name}_{num_epochs}_{batch_size}_{lr_start}_{lr_end}_.pickle', 'wb') as handle:\n",
    "    pickle.dump(eval_metrics, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "#with open('filename.pickle', 'rb') as handle:\n",
    "#    b = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WvFygat_aiDN"
   },
   "outputs": [],
   "source": [
    "#print(prof.key_averages(group_by_stack_n=5).table(sort_by='self_cpu_time_total', row_limit=50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "EQ6hb3iO2mXv"
   },
   "outputs": [],
   "source": [
    "# Plot the training curves of validation accuracy vs. number\n",
    "#  of training epochs for the transfer learning method and\n",
    "#  the model trained from scratch\n",
    "# vhist = []\n",
    "# vhist = [h.cpu().numpy() for h in val_acc_history]\n",
    "# thist = []\n",
    "# thist = [h.cpu().numpy() for h in train_acc_history]\n",
    "\n",
    "# plt.title(\"Accuracy vs. Number of Training Epochs\")\n",
    "# plt.xlabel(\"Training Epochs\")\n",
    "# plt.ylabel(\"Accuracy\")\n",
    "# #plt.plot(range(1,num_epochs+1),ohist,label=\"Pretrained\")\n",
    "# plt.plot(range(1,num_epochs+1),vhist,label=\"Validation\")\n",
    "# plt.plot(range(1,num_epochs+1),thist,label=\"Training\")\n",
    "# plt.ylim((0,1.))\n",
    "# plt.xticks(np.arange(1, num_epochs+1, 1.0))\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "aXpHASjTUE_Q"
   },
   "outputs": [],
   "source": [
    "# Plot the training curves of validation accuracy vs. number\n",
    "#  of training epochs for the transfer learning method and\n",
    "#  the model trained from scratch\n",
    "# vhist = []\n",
    "# vhist = [h for h in val_loss_history]\n",
    "# thist = []\n",
    "# thist = [h for h in train_loss_history]\n",
    "\n",
    "# plt.title(\"Loss vs. Number of Training Epochs\")\n",
    "# plt.xlabel(\"Training Epochs\")\n",
    "# plt.ylabel(\"Loss\")\n",
    "# #plt.plot(range(1,num_epochs+1),ohist,label=\"Pretrained\")\n",
    "# plt.plot(range(1,num_epochs+1),vhist,label=\"Validation\")\n",
    "# plt.plot(range(1,num_epochs+1),thist,label=\"Training\")\n",
    "# plt.ylim((0,1.))\n",
    "# plt.xticks(np.arange(1, num_epochs+1, 1.0))\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3.9.13 ('dl')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "8663be1127523d7121742bbf948a8b1c8dd9a63c15e224e5108ff87b090569d5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
